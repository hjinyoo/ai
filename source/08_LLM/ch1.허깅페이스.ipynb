{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39644b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ad24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c19cf",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1. 허깅페이스</span>\n",
    "- Inference API 이용 : 모델의 결과를 server에서\n",
    "- pipeline() 이용 : 모델을 다운로드 받아 모델의 결과를 local에서\n",
    "    * raw text -> tokenizer -> model -> [0.11, 0.55, 0.xx, ~] logits값으로 prediction결과 출력\n",
    "```\n",
    "허깅페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-classification\"의 별칭(감정분석 전용으로 사용)\n",
    "\"text-classification\" : 감정분석, 뉴스분류, 리뷰분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification\" : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-classification\" : 개체명 인식(NER ; Named Entity Recognition) 등 단위 라벨링\n",
    "\"ner\" : \"token-classification\"의 별칭\n",
    "\"fill-mask\" : 빈칸 채우기\n",
    "\"text-generation\" : 텍스트 생성 (GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약, 등 입력 -> 출력 변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트 요약\n",
    "\"question-answering\" : 주어진 context를 보고 질문에 답하기\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\" : 이미지 분류\n",
    "```\n",
    "\n",
    "##  1. 텍스트 기반 감정분석(긍정/부정)\n",
    "- c:/사용자/내컴퓨터명/.cache/huggingface/hub 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421116d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302aad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995144605636597}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\",\n",
    "                      model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 감정 분석시 내용이 많으면 list로\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac5a1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.857815682888031},\n",
       " {'label': 'POSITIVE', 'score': 0.9998821020126343}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\",\n",
    "           \"This movie was the best. It's touching, and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543c340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8786237239837646}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 물건 사고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac5b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "texts = [\"나는 너가 좋아\", \"당신이 싫어요\", \"힘들어요\", \"오늘 기분이 최고야\"]\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b2eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 => 긍정 : 0.9558\n",
      "당신이 싫어요 => 부정 : 0.9093\n",
      "힘들어요 => 부정 : 0.9140\n",
      "오늘 기분이 최고야 => 긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in  zip(texts, classifier(texts)):\n",
    "    label = \"긍정\" if result['label']=='LABEL_1' else \"부정\"\n",
    "    print(f\"{text} => {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ee394",
   "metadata": {},
   "source": [
    "## 2. 제로샷분류(Zero-shot분류)\n",
    "- 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육 없이 작업을 수행할 수 있는 모형(비지도 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7476b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my phone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'not urgent', 'computer', 'tablet'],\n",
       " 'scores': [0.6228813529014587,\n",
       "  0.37086236476898193,\n",
       "  0.0029875338077545166,\n",
       "  0.001735040219500661,\n",
       "  0.0015337676741182804]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"I have a problem with my phone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b0403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9938651919364929, 0.0032737581059336662, 0.0028610501904040575]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1758294",
   "metadata": {},
   "source": [
    "## 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b90775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to build your own tools to solve your own problems. We will teach you how to create code that works for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build new tools to solve problems for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease.\\n\\n\\nWe will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "set_seed(2)\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스없음\n",
    "generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id\n",
    ") # pad_token_id 경고를 없애려고 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b80c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to create virtual objects, how to use virtual controllers to implement your application, and how to create classes, functions, and properties. We will cover the basics of creating virtual objects, how to create virtual controllers, and how to use virtual services. We'll discuss the fundamentals of virtual objects and how to use services to create virtual objects. We'll also cover the various ways to use virtual services to create virtual objects and how to use virtual services. We'll discuss the concepts of virtual methods, virtual objects, and virtual virtual functions. We'll also learn how to use virtual functions to create virtual functions and how to use virtual services. We'll also learn how to use virtual functions with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Objects\n",
      "\n",
      "In this course, we'll learn how to create virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We will cover the basics of creating virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We'll also cover the various ways to use virtual services with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Functions\n",
      "\n",
      "In this course, we'll learn how to create\n"
     ]
    }
   ],
   "source": [
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b1bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 뭔가 좀 더 좋은 일이 있길래 그냥 집에 가서 일하시거든요? 저는 일단 요리를 하게 됩니다. 그러면 그거를 먹을 때도 제가 맛을 좀 보시잖아요. 그렇게 하면 어떨 것 같아요. 어~ 햄을 조금 먹으면 좀 맵습니다. 땡겨져 있는 요리가 훨씬 더 맛있을 거 같아요 뭘.\"\n",
      "'안 돼! 정말 못하겠다. 안 돼. 그런 것 같아서 너무 심란해서 그래? 아니면 정말 너무 먹으라\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\")\n",
    "result = generation(\"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "                    pad_token_id = generation.tokenizer.eos_token_id,\n",
    "                    max_new_tokens = 100, # 생성할 최대 길이(생성할 토큰 수)\n",
    "                    # num_return_sequence=1, # 생성할 문장 갯수\n",
    "                    do_sample=True,        # 다양한 샘플 사용\n",
    "                    top_k=50,           # top_k 샘플링(확률 높은 상위 50개 토큰만 사용)\n",
    "                    top_p=0.95,         # 확률이 높은 순서대로 95%가 될 때까지의 단어들로만 후보 사용\n",
    "                    temperature=1.2,    # 창의성 조절(낮을수록 보수적)\n",
    "                    no_repeat_ngram_size=2 # 반복 방지\n",
    "                   )\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deab70c",
   "metadata": {},
   "source": [
    "# 4. 마스크(빈칸) 채우기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17467892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275707006454468,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794589757919312,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask',\n",
    "                    model='distilbert/distilroberta-base') # 마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\", top_k=2) # top_k 기본값 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2f02632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmasker(\"병원에 가서 <mask>를 만날 거에요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f061d0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0629730075597763,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model.\"},\n",
       " {'score': 0.038101598620414734,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model.\"},\n",
       " {'score': 0.03764132782816887,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': \"Hello, I'm a role model.\"},\n",
       " {'score': 0.037326786667108536,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello, I'm a fashion model.\"},\n",
       " {'score': 0.026023676618933678,\n",
       "  'token': 24526,\n",
       "  'token_str': ' Playboy',\n",
       "  'sequence': \"Hello, I'm a Playboy model.\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0912cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c48a49fba49d98d791d8932667eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e5b325967b44169c11a703a47dc182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913539a734cc49a9863b88bf4c3d9f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba27ea7800aa43c8a028cf58b0d2e5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5971011e6e5c47d1942fd54a7d8a9726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1441437155008316,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i ' m a role model.\"},\n",
       " {'score': 0.14175789058208466,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model.\"},\n",
       " {'score': 0.062214579433202744,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model.\"},\n",
       " {'score': 0.041028350591659546,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello, i ' m a super model.\"},\n",
       " {'score': 0.025911200791597366,\n",
       "  'token': 2449,\n",
       "  'token_str': 'business',\n",
       "  'sequence': \"hello, i ' m a business model.\"}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task=\"fill-mask\",\n",
    "                    model=\"google-bert/bert-base-uncased\")\n",
    "unmasker(\"Hello, I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74310c",
   "metadata": {},
   "source": [
    "### ※ InferenceAPI 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f599a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.environ['HF_TOKEN']\n",
    "# 허깅페이스 토큰을 READ권한으로 생성하여 .env에 추가 (.git ignore파일 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea5e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5810cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f40d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805655a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b713b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36117182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5af86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.431px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
