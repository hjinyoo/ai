{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f710ebf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2bc66",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2. Ollama_LLM활용의기본개념(LangChain)</span>\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용\n",
    "성능은 GPT, Claude 같은 모델보다 떨어지나, 개념설명을 위해 open source 모델 사용\n",
    "\n",
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- cmd창이나 powershell 창에 ollama pull deepseek-r1:1.5b\n",
    "- https://docs.langchain.com/oss/python/integrations/chat/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b65cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Korea, South Korea, is首尔 (Gyeongju).', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-12-09T02:05:28.0991212Z', 'done': True, 'done_reason': 'stop', 'total_duration': 820767300, 'load_duration': 87335400, 'prompt_eval_count': 11, 'prompt_eval_duration': 74415200, 'eval_count': 22, 'eval_duration': 555465700, 'logprobs': None, 'model_name': 'deepseek-r1:1.5b', 'model_provider': 'ollama'}, id='lc_run--019b00db-3f68-7010-8e23-aac03c8eb481-0', usage_metadata={'input_tokens': 11, 'output_tokens': 22, 'total_tokens': 33})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "lim = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = lim.invoke(\"What is the capital of korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a823049",
   "metadata": {},
   "source": [
    "### 모델 pull\n",
    "- cmd창이나 powershell창(window키+R에서 powershell)에서 ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82657789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T02:18:44.2244317Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1829748600, 'load_duration': 1259168500, 'prompt_eval_count': 33, 'prompt_eval_duration': 292793800, 'eval_count': 9, 'eval_duration': 196534800, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b00e7-6159-7b63-8af7-e8884a48b0e1-0', usage_metadata={'input_tokens': 33, 'output_tokens': 9, 'total_tokens': 42})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "result = llm.invoke(\"What is the capital of korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3875f1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65479682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한국의 수도는 Seoul입니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(\"한국 수도가 어디에요?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3c04",
   "metadata": {},
   "source": [
    "## 2) openAI 활용\n",
    "- pip install langchain-openai\n",
    "- https://auth.openai.com/log-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531dbe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8b552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seoul', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 203, 'prompt_tokens': 21, 'total_tokens': 224, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CkkVnOQu9UCcvfuxQ0QHy3qXFqSz5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b0192-223d-7651-96ba-8918925747c4-0', usage_metadata={'input_tokens': 21, 'output_tokens': 203, 'total_tokens': 224, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\",\n",
    "                 # api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "result = llm.invoke(\"What is the capital of korea? Return the name of the city only.\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fbd18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure : OPENAI_API_VERSION 키값\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "# llm = AzureChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38787327",
   "metadata": {},
   "source": [
    "# 2. 랭체인 스타일로 프롬프트 작성\n",
    "- 프롬프트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f47303d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "# llm.invoke(0)\n",
    "# PromptValue, str, BaseMessages 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b82f5",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d57d216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of korea?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:21:03.1163968Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1796647400, 'load_duration': 1292417300, 'prompt_eval_count': 33, 'prompt_eval_duration': 258639400, 'eval_count': 8, 'eval_duration': 225950100, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01c5-3a06-72e2-b465-92016517cd8a-0', usage_metadata={'input_tokens': 33, 'output_tokens': 8, 'total_tokens': 41})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# country = input('어느 나라의 수도를 알고 싶으신가요?')\n",
    "prompt = prompt_template.invoke({\"country\":\"korea\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0429139",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "- vscode에서 ctrl+shift+p : python:select interpreter입력 -> python 환경 선택\n",
    "- vscode에서 커널 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15495c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:07:13.527022Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2363354400, 'load_duration': 1296962200, 'prompt_eval_count': 87, 'prompt_eval_duration': 778038700, 'eval_count': 9, 'eval_duration': 262655400, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01b8-8f39-76c1-a7a1-848a723cc38d-0', usage_metadata={'input_tokens': 87, 'output_tokens': 9, 'total_tokens': 96})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범 질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),    # 모범 답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범 질문\n",
    "    AIMessage(content=\"The capital of Italy is Paris.\"),    # 모범 답안\n",
    "    HumanMessage(content=\"What is the capital of korea?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba903a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"If you're referring to a specific country, I'd be happy to help. Please specify the name of the country, and I'll do my best to provide the correct capital.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:21:11.2974054Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1972007400, 'load_duration': 110547800, 'prompt_eval_count': 87, 'prompt_eval_duration': 588827200, 'eval_count': 37, 'eval_duration': 1112868000, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01c5-594b-7741-ad91-1901fc917106-0', usage_metadata={'input_tokens': 87, 'output_tokens': 37, 'total_tokens': 124})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범 질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),    # 모범 답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범 질문\n",
    "    AIMessage(content=\"The capital of Italy is Paris.\"),    # 모범 답안\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad3cab",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage리스트->튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d24066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요korea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul, and the capital of North Korea is Pyongyang.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage리스트를 수정\n",
    "# PromptTemplate : 프롬프트에 변수 포함\n",
    "# ChatPromptTemplate : SystemPrompt설정(페르소나), few shot설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant!\"),\n",
    "    (\"human\", \"What is the capital of Italy?\"), # 모범 질문\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),    # 모범 답안\n",
    "    (\"human\", \"What is the capital of France?\"), # 모범 질문\n",
    "    (\"ai\", \"The capital of Italy is Paris.\"),    # 모범 답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "# print(\"프롬프트 : \", prompt, type(prompt))\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8255d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요korea\n",
      " korea의 수도는 Seoul입니다!\n"
     ]
    }
   ],
   "source": [
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"당신은 대한민국 정보 전문 도우미입니다\"),\n",
    "    ('human', \"{country}의 수도가 어디에요!\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "# print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a7db6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' korea의 수도는 Seoul입니다!', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:39:41.0494634Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2003045100, 'load_duration': 1377801900, 'prompt_eval_count': 44, 'prompt_eval_duration': 349438900, 'eval_count': 9, 'eval_duration': 242851300, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01d6-4824-7ea3-a329-377579419669-0', usage_metadata={'input_tokens': 44, 'output_tokens': 9, 'total_tokens': 53})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95022f",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤 하기\n",
    "- llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72a904c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\":\"korea\"})\n",
    "# print(prompt)\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message)\n",
    "# 문자열 출력 파서를 이용하요 llm응답(AIMessage)을 단순 문자열로 변환\n",
    "output_parser = StrOutputParser()\n",
    "result = output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ffe4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165d0a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in south korea.\"),\n",
    "    (\"human\", \"What is the capital of Italy?\"), # 모범 질문\n",
    "    (\"ai\", \"Rome.\"),    # 모범 답안\n",
    "    (\"human\", \"What is the capital of France?\"), # 모범 질문\n",
    "    (\"ai\", \"Paris.\"),    # 모범 답안\n",
    "    (\"human\", \"What is the capital of {country}? Return the name of the city only\")\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018c11b",
   "metadata": {},
   "source": [
    "## 2) Json 출력 파서 이용\n",
    "- {'name' : '홍길동', 'age' : 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd80b394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51.83, 'language': 'Korean', 'currency': 'Won'} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result, type(json_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0559f4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Tokyo',\n",
       " 'population': 128843811,\n",
       " 'language': 'Japanese',\n",
       " 'currency': ' Yen'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"japan\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720912bb",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : 데이터유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ede6943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x0000021CCF7DAD10>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name,\n",
    "        self.is_active = is_active\n",
    "user = User(\"1\", \"홍길동\", False)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d214daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>=0 / ge=0:id>=0 / lt=0:id<0 / ie=0:id<=0\n",
    "    id:int = Field(gt=0, description=\"id\")\n",
    "    name:str = Field(min_length=2, description=\"name\")\n",
    "    is_active:bool = Field(default=True, description=\"id활성화 여부\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "faa1c240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='South Korean won')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "class CountryDetail(BaseModel): # description : 더 정확한 출력 유도\n",
    "    capital:str = Field(description=\"the Capital of the country\")\n",
    "    population:int = Field(description=\"the Population of the country\")\n",
    "    language:str = Field(description=\"the Language of the country\")\n",
    "    currency:str = Field(description=\"the Currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"korea\"}))\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbc5fc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e01d9740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51, 'Korean', 'South Korean won')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9834df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json으로 : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"South Korean won\"}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'South Korean won'}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json으로 :\", info.model_dump_json())\n",
    "print(\"info를 dict로 :\", info.model_dump())\n",
    "print(\"info를 dict로 :\", info.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b043686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290665c9",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 랭체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke : Runnable에 있는 함수\n",
    "- StrOutputParser, ChatOllama, PromptTemplate등은 모두 Runnable로 상속 받음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73529b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",\n",
    "                temperature=0) # 일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() # AIMessage()를 Str변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a0a06",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0f5ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0172aa",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    "- 여러 단계의 추론이 필요한 경우(체인연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b57c4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"Guess the name of the country based on the following informat:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=['information']\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\"This country is very famous for its wine\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6009f12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f3e4456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인 : 나라설명 -> 나라명(country_chain)\n",
    "#                     나라명 -> 수도(capital_chain)\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2570dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\":RunnablePassthrough()} | \\\n",
    "                 {\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47714bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09af02",
   "metadata": {},
   "source": [
    "- 한글 지원이 안되는 모델은 랭체인 연결이 잘 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04e59180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 나라는 와인으로 유명해\\n\\n1. 프랑스 - burgundy, merlot, cabernet sauvignon\\n2. 이탈리아 - chianti, pinot noir, vermentino\\n3. 스타일러 - merlot, shiraz, syrah\\n4. 이스라엘 - merlot, cabernet sauvignon, pinot noir\\n5. 미국 - merlot, cabernet sauvignon, pinot noir'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"다음의 {information} 설명을 보고 나라이름을 맞춰봐:\n",
    "    {information}\n",
    "    나라 이름만 한국어로 return 해 줘\"\"\",\n",
    "    input_variables=['information']\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\"이 나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7b381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.434px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
