{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7e4f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('C:/ai/source/10_1stProject/수원시 한식 동별 데이터백업.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e580f59",
   "metadata": {},
   "outputs": [],
   "source": [
    " # -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "[C] 날씨 + 요일 + 시간대 + 동 기반 머신러닝 (수원 한식 동별)\n",
    "- Feature: DONG, DAY(1~7), HOUR(1~10), TEMP, RAIN\n",
    "- Target: AMT / CNT / UNIT 중 선택\n",
    "- Split: 최근 test_days일을 테스트로 time-based split (데이터 누수 방지)\n",
    "- Save/Load: joblib\n",
    "- Flask 연동용 함수 제공: load_model(), predict_one(), predict_many(), predict_3days_slots()\n",
    "\n",
    "주의:\n",
    "- DAY: 1~7 (월~일)\n",
    "- HOUR: 1~10 (항목요약 슬롯 기준)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 경로 설정\n",
    "# =========================\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "MODEL_DIR  = r\"C:/ai/source/10_1stProject/ml_models_weather\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "FEATURE_CAT = [\"DONG\", \"DAY\", \"HOUR\"]\n",
    "FEATURE_NUM = [\"TEMP\", \"RAIN\"]\n",
    "FEATURES = FEATURE_CAT + FEATURE_NUM\n",
    "TARGETS = [\"AMT\", \"CNT\", \"UNIT\"]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 유틸\n",
    "# =========================\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred) -> float:\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), 1.0)  # 0 분모 방지\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "def ensure_columns(df: pd.DataFrame, cols: list[str]):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"필수 컬럼 누락: {miss}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 데이터 로드/정리\n",
    "# =========================\n",
    "def load_and_clean(csv_path: str = DATA_CSV) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    ensure_columns(df, [\"TA_YMD\", \"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"])\n",
    "    for t in TARGETS:\n",
    "        if t not in df.columns:\n",
    "            # 타겟 일부가 없는 데이터도 있을 수 있어, 학습 시점에 체크\n",
    "            pass\n",
    "\n",
    "    # 날짜\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    # 숫자 변환\n",
    "    df[\"TEMP\"] = pd.to_numeric(df[\"TEMP\"], errors=\"coerce\")\n",
    "    df[\"RAIN\"] = pd.to_numeric(df[\"RAIN\"], errors=\"coerce\")\n",
    "    df[\"DAY\"]  = pd.to_numeric(df[\"DAY\"], errors=\"coerce\")\n",
    "    df[\"HOUR\"] = pd.to_numeric(df[\"HOUR\"], errors=\"coerce\")\n",
    "\n",
    "    # 결측 제거(핵심 피처 + DATE)\n",
    "    df = df.dropna(subset=[\"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\", \"DATE\"]).copy()\n",
    "\n",
    "    # 범위 방어\n",
    "    df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "    df = df[df[\"DAY\"].between(1, 7)]\n",
    "    df = df[df[\"HOUR\"].between(1, 10)]\n",
    "\n",
    "    # 문자열 정리\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_time_based(df: pd.DataFrame, test_days: int = 30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "\n",
    "    train_df = df[df[\"DATE\"] <= cutoff].copy()\n",
    "    test_df  = df[df[\"DATE\"] >  cutoff].copy()\n",
    "\n",
    "    if len(train_df) < 200:\n",
    "        raise ValueError(f\"학습 데이터 부족(train={len(train_df)}). test_days를 줄이거나 데이터 확인.\")\n",
    "    if len(test_df) < 30:\n",
    "        raise ValueError(f\"테스트 데이터 부족(test={len(test_df)}). test_days를 줄이거나 데이터 확인.\")\n",
    "\n",
    "    return train_df, test_df, cutoff, max_date\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 모델 파이프라인\n",
    "# =========================\n",
    "def build_pipeline(random_state: int = 42) -> Pipeline:\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), FEATURE_CAT),\n",
    "            (\"num\", \"passthrough\", FEATURE_NUM),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=700,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf=2,\n",
    "        # max_depth=None  # 필요하면 제한 가능\n",
    "    )\n",
    "\n",
    "    return Pipeline([(\"preprocess\", pre), (\"model\", model)])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 학습/평가/저장\n",
    "# =========================\n",
    "def train(target: str = \"UNIT\", test_days: int = 30, random_state: int = 42):\n",
    "    if target not in TARGETS:\n",
    "        raise ValueError(f\"target은 {TARGETS} 중 하나여야 합니다.\")\n",
    "\n",
    "    df = load_and_clean(DATA_CSV)\n",
    "    ensure_columns(df, [target])\n",
    "\n",
    "    df[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[target]).copy()\n",
    "\n",
    "    train_df, test_df, cutoff, max_date = split_time_based(df, test_days=test_days)\n",
    "\n",
    "    X_train = train_df[FEATURES]\n",
    "    y_train = train_df[target].astype(float)\n",
    "\n",
    "    X_test  = test_df[FEATURES]\n",
    "    y_test  = test_df[target].astype(float)\n",
    "\n",
    "    pipe = build_pipeline(random_state=random_state)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"target\": target,\n",
    "        \"train_rows\": int(len(train_df)),\n",
    "        \"test_rows\": int(len(test_df)),\n",
    "        \"train_until\": str(cutoff.date()),\n",
    "        \"test_range\": f\"{str((cutoff + pd.Timedelta(days=1)).date())} ~ {str(max_date.date())}\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test, pred)),\n",
    "        \"RMSE\": rmse(y_test, pred),\n",
    "        \"MAPE(%)\": mape(y_test, pred),\n",
    "    }\n",
    "\n",
    "    model_path = os.path.join(MODEL_DIR, f\"rf_{target.lower()}.joblib\")\n",
    "    joblib.dump(pipe, model_path)\n",
    "\n",
    "    return model_path, metrics\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 로드/예측 (Flask에서 그대로 사용)\n",
    "# =========================\n",
    "def model_path(target: str) -> str:\n",
    "    return os.path.join(MODEL_DIR, f\"rf_{target.lower()}.joblib\")\n",
    "\n",
    "def load_model(target: str) -> Pipeline:\n",
    "    p = model_path(target)\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"모델이 없습니다: {p} (먼저 train() 실행)\")\n",
    "    return joblib.load(p)\n",
    "\n",
    "def predict_one(target: str, dong: str, day: int, hour: int, temp: float, rain: float) -> float:\n",
    "    pipe = load_model(target)\n",
    "    X = pd.DataFrame([{\n",
    "        \"DONG\": str(dong).strip(),\n",
    "        \"DAY\": int(day),\n",
    "        \"HOUR\": int(hour),\n",
    "        \"TEMP\": float(temp),\n",
    "        \"RAIN\": float(rain),\n",
    "    }])\n",
    "    return float(pipe.predict(X)[0])\n",
    "\n",
    "def predict_many(target: str, rows: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    rows 예시:\n",
    "    [\n",
    "      {\"DONG\":\"파장동\",\"DAY\":3,\"HOUR\":4,\"TEMP\":5.3,\"RAIN\":0.0},\n",
    "      ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pipe = load_model(target)\n",
    "    X = pd.DataFrame(rows).copy()\n",
    "    ensure_columns(X, FEATURES)\n",
    "\n",
    "    # 타입 정리\n",
    "    X[\"DONG\"] = X[\"DONG\"].astype(str).str.strip()\n",
    "    X[\"DAY\"]  = pd.to_numeric(X[\"DAY\"], errors=\"coerce\").astype(int)\n",
    "    X[\"HOUR\"] = pd.to_numeric(X[\"HOUR\"], errors=\"coerce\").astype(int)\n",
    "    X[\"TEMP\"] = pd.to_numeric(X[\"TEMP\"], errors=\"coerce\").astype(float)\n",
    "    X[\"RAIN\"] = pd.to_numeric(X[\"RAIN\"], errors=\"coerce\").astype(float)\n",
    "\n",
    "    X = X[FEATURES]\n",
    "    yhat = pipe.predict(X)\n",
    "\n",
    "    out = X.copy()\n",
    "    out[f\"PRED_{target}\"] = yhat\n",
    "    return out\n",
    "\n",
    "def predict_3days_slots(target: str, dong: str, start_date_yyyymmdd: str, weather_provider_func):\n",
    "    \"\"\"\n",
    "    Flask에서 자주 쓰는 형태:\n",
    "    - start_date_yyyymmdd 기준으로 3일치(오늘~+2일) * HOUR 1~10 예측\n",
    "    - weather_provider_func(date_yyyymmdd, hour_slot) -> (temp, rain)\n",
    "      * 여기만 기상청 연동으로 바꿔 끼우면 됨.\n",
    "    \"\"\"\n",
    "    base = datetime.strptime(start_date_yyyymmdd, \"%Y%m%d\")\n",
    "    rows = []\n",
    "    for d in range(3):\n",
    "        dt = base + timedelta(days=d)\n",
    "        date_str = dt.strftime(\"%Y%m%d\")\n",
    "        # 요일: 월=1 ... 일=7\n",
    "        day = (dt.weekday() + 1)\n",
    "\n",
    "        for hour in range(1, 11):\n",
    "            temp, rain = weather_provider_func(date_str, hour)\n",
    "            rows.append({\n",
    "                \"DONG\": dong,\n",
    "                \"DAY\": day,\n",
    "                \"HOUR\": hour,\n",
    "                \"TEMP\": float(temp),\n",
    "                \"RAIN\": float(rain),\n",
    "            })\n",
    "\n",
    "    pred_df = predict_many(target, rows)\n",
    "    pred_df.insert(0, \"DATE\", [ (base + timedelta(days=i//10)).strftime(\"%Y%m%d\") for i in range(len(pred_df)) ])\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 실행 예시\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 학습\n",
    "    p, m = train(target=\"UNIT\", test_days=30)\n",
    "    print(\"Saved:\", p)\n",
    "    print(\"Metrics:\", m)\n",
    "\n",
    "    # 2) 단건 예측\n",
    "    y = predict_one(\"UNIT\", dong=\"파장동\", day=3, hour=4, temp=5.3, rain=0.0)\n",
    "    print(\"PRED_UNIT:\", y)\n",
    "\n",
    "    # 3) 3일치 예측 (날씨함수 예시: 임시로 고정값)\n",
    "    def dummy_weather(date_yyyymmdd, hour_slot):\n",
    "        return 5.3, 0.0\n",
    "\n",
    "    df3 = predict_3days_slots(\"UNIT\", \"파장동\", \"20251231\", dummy_weather)\n",
    "    print(df3.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943f3415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/ai/source/10_1stProject/ml_models_weather\\hgb_unit.joblib\n",
      "Metrics: {'target': 'UNIT', 'train_rows': 430697, 'test_rows': 12826, 'train_until': '2025-10-01', 'test_to': '2025-10-31', 'MAE': 10984.93262733055, 'RMSE': 40849.3860485607}\n",
      "PRED_UNIT: 27440.276018547054\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "[C-FAST] 동 + 요일 + 시간대 + 날씨 기반 초경량 ML\n",
    "- 모델: HistGradientBoostingRegressor (빠름, 대용량 친화)\n",
    "- 인코딩: OrdinalEncoder(카테고리 -> 숫자) (원핫보다 훨씬 가벼움)\n",
    "- 저장/로드: joblib\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "MODEL_DIR  = r\"C:/ai/source/10_1stProject/ml_models_weather\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "FEATURE_CAT = [\"DONG\", \"DAY\", \"HOUR\"]\n",
    "FEATURE_NUM = [\"TEMP\", \"RAIN\"]\n",
    "FEATURES = FEATURE_CAT + FEATURE_NUM\n",
    "TARGETS = [\"AMT\", \"CNT\", \"UNIT\"]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def load_clean():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "    # 날짜\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    # 타입 정리\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "    for c in [\"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"DATE\", \"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"]).copy()\n",
    "\n",
    "    # 범위 방어\n",
    "    df[\"DAY\"] = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "    df = df[df[\"DAY\"].between(1, 7)]\n",
    "    df = df[df[\"HOUR\"].between(1, 10)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def time_split(df, test_days=30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "    train_df = df[df[\"DATE\"] <= cutoff].copy()\n",
    "    test_df  = df[df[\"DATE\"] >  cutoff].copy()\n",
    "    return train_df, test_df, cutoff, max_date\n",
    "\n",
    "def build_pipe():\n",
    "    # 카테고리: 결측 채우고 -> Ordinal encoding\n",
    "    cat_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ])\n",
    "\n",
    "    # 숫자: 결측 0으로\n",
    "    num_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_tf, FEATURE_CAT),\n",
    "            (\"num\", num_tf, FEATURE_NUM),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # 초경량 모델\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_depth=8,\n",
    "        learning_rate=0.08,\n",
    "        max_iter=300,        # 반복 수(많을수록 성능↑, 시간↑)\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "def train(target=\"UNIT\", test_days=30):\n",
    "    if target not in TARGETS:\n",
    "        raise ValueError(f\"target은 {TARGETS} 중 하나\")\n",
    "\n",
    "    df = load_clean()\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"데이터에 {target} 컬럼이 없습니다.\")\n",
    "\n",
    "    df[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[target]).copy()\n",
    "\n",
    "    train_df, test_df, cutoff, max_date = time_split(df, test_days=test_days)\n",
    "\n",
    "    X_train, y_train = train_df[FEATURES], train_df[target].astype(float)\n",
    "    X_test,  y_test  = test_df[FEATURES],  test_df[target].astype(float)\n",
    "\n",
    "    pipe = build_pipe()\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"target\": target,\n",
    "        \"train_rows\": int(len(train_df)),\n",
    "        \"test_rows\": int(len(test_df)),\n",
    "        \"train_until\": str(cutoff.date()),\n",
    "        \"test_to\": str(max_date.date()),\n",
    "        \"MAE\": float(mean_absolute_error(y_test, pred)),\n",
    "        \"RMSE\": rmse(y_test, pred),\n",
    "    }\n",
    "\n",
    "    path = os.path.join(MODEL_DIR, f\"hgb_{target.lower()}.joblib\")\n",
    "    joblib.dump(pipe, path)\n",
    "    return path, metrics\n",
    "\n",
    "def load_model(target=\"UNIT\"):\n",
    "    path = os.path.join(MODEL_DIR, f\"hgb_{target.lower()}.joblib\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"모델 없음: {path} (train 먼저)\")\n",
    "    return joblib.load(path)\n",
    "\n",
    "def predict_one(target, dong, day, hour, temp, rain):\n",
    "    pipe = load_model(target)\n",
    "    X = pd.DataFrame([{\n",
    "        \"DONG\": str(dong).strip(),\n",
    "        \"DAY\": int(day),\n",
    "        \"HOUR\": int(hour),\n",
    "        \"TEMP\": float(temp),\n",
    "        \"RAIN\": float(rain),\n",
    "    }])\n",
    "    return float(pipe.predict(X)[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path, metrics = train(target=\"UNIT\", test_days=30)\n",
    "    print(\"Saved:\", model_path)\n",
    "    print(\"Metrics:\", metrics)\n",
    "\n",
    "    y = predict_one(\"UNIT\", \"파장동\", 3, 4, 5.3, 0.0)\n",
    "    print(\"PRED_UNIT:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e67d0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DONE ===\n",
      "Test range: 2025-10-02 ~ 2025-10-31\n",
      "Overall: {'N': 12826, 'MAE': 5501451.001779406, 'RMSE': 15244490.83434509, 'MAPE(%)': 99.26763149395299, 'sMAPE(%)': 181.62628573390563, 'Accuracy%(=100-MAPE)': 0.7323685060470098, 'R2': -0.14931998705896832}\n",
      "Saved: C:/ai/source/10_1stProject/eval_amt_weather_combo\n",
      "Combo rows: 8\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "DATA_CSV   = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "MODEL_PATH = r\"C:/ai/source/10_1stProject/ml_models_weather/hgb_unit.joblib\"  # <- 네 AMT 모델 경로로 수정\n",
    "OUT_DIR    = r\"C:/ai/source/10_1stProject/eval_amt_weather_combo\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET   = \"AMT\"\n",
    "FEATURES = [\"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"]\n",
    "\n",
    "# 비 기준: 0 초과면 비로 간주 (필요시 0.1로 올려도 됨)\n",
    "RAIN_THRESHOLD = 0.0\n",
    "\n",
    "# 온도 구간(원하면 여기만 바꾸면 끝)\n",
    "TEMP_BINS = [-50, 0, 5, 10, 15, 20, 25, 30, 50]\n",
    "\n",
    "# 조합별 표본이 너무 적으면 제외\n",
    "MIN_N = 80\n",
    "\n",
    "# 테스트 분리(최근 N일)\n",
    "TEST_DAYS = 30\n",
    "\n",
    "\n",
    "# =========================\n",
    "# metrics\n",
    "# =========================\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), 1.0)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum((np.abs(y_true) + np.abs(y_pred)) / 2.0, 1.0)\n",
    "    return float(np.mean(np.abs(y_true - y_pred) / denom) * 100.0)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    _mape = mape(y_true, y_pred)\n",
    "    return {\n",
    "        \"N\": int(len(y_true)),\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"RMSE\": rmse(y_true, y_pred),\n",
    "        \"MAPE(%)\": _mape,\n",
    "        \"sMAPE(%)\": smape(y_true, y_pred),\n",
    "        \"Accuracy%(=100-MAPE)\": float(max(0.0, 100.0 - _mape)),\n",
    "        \"R2\": float(r2_score(y_true, y_pred)) if len(y_true) >= 2 else np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# data\n",
    "# =========================\n",
    "def load_clean():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "    for c in [\"DAY\", \"HOUR\", \"TEMP\", \"RAIN\", TARGET]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "    df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "\n",
    "    df = df[df[\"DAY\"].between(1,7)]\n",
    "    df = df[df[\"HOUR\"].between(1,10)]\n",
    "    return df\n",
    "\n",
    "def time_split(df, test_days=30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "    test_df = df[df[\"DATE\"] > cutoff].copy()\n",
    "    return test_df, cutoff, max_date\n",
    "\n",
    "\n",
    "# =========================\n",
    "# labels + group eval\n",
    "# =========================\n",
    "def add_weather_combo(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"RAIN_FLAG\"] = np.where(out[\"RAIN\"] > RAIN_THRESHOLD, \"RAINY\", \"NO_RAIN\")\n",
    "    out[\"TEMP_BIN\"] = pd.cut(out[\"TEMP\"], bins=TEMP_BINS, include_lowest=True)\n",
    "    out[\"TEMP_BIN\"] = out[\"TEMP_BIN\"].astype(str)\n",
    "\n",
    "    out[\"WEATHER_COMBO\"] = out[\"TEMP_BIN\"] + \"_\" + out[\"RAIN_FLAG\"]\n",
    "    return out\n",
    "\n",
    "def eval_by_combo(df: pd.DataFrame, min_n=80) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for k, g in df.groupby(\"WEATHER_COMBO\"):\n",
    "        if len(g) < min_n:\n",
    "            continue\n",
    "        met = compute_metrics(g[TARGET].values, g[\"PRED\"].values)\n",
    "        met[\"WEATHER_COMBO\"] = k\n",
    "        rows.append(met)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    if len(out) == 0:\n",
    "        return out\n",
    "\n",
    "    out = out.sort_values(\"Accuracy%(=100-MAPE)\", ascending=False).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# plot\n",
    "# =========================\n",
    "def save_bar_rank(df, path, title, top_n=25, ascending=False):\n",
    "    \"\"\"\n",
    "    ascending=False => 상위(Accuracy 높은) 랭킹\n",
    "    ascending=True  => 하위(Accuracy 낮은) 랭킹\n",
    "    \"\"\"\n",
    "    d = df.sort_values(\"Accuracy%(=100-MAPE)\", ascending=ascending).head(top_n).copy()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(d[\"WEATHER_COMBO\"].astype(str), d[\"Accuracy%(=100-MAPE)\"].astype(float))\n",
    "    plt.xticks(rotation=70, ha=\"right\")\n",
    "    plt.xlabel(\"WEATHER_COMBO (TEMP bin x RAIN)\")\n",
    "    plt.ylabel(\"Accuracy% (100 - MAPE)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# main\n",
    "# =========================\n",
    "def run():\n",
    "    df = load_clean()\n",
    "    test_df, cutoff, max_date = time_split(df, test_days=TEST_DAYS)\n",
    "\n",
    "    pipe = joblib.load(MODEL_PATH)\n",
    "\n",
    "    X = test_df[FEATURES]\n",
    "    y_pred = pipe.predict(X)\n",
    "\n",
    "    out = test_df[[\"DATE\",\"TA_YMD\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]].copy()\n",
    "    out[\"PRED\"] = y_pred\n",
    "\n",
    "    out = add_weather_combo(out)\n",
    "\n",
    "    overall = compute_metrics(out[TARGET].values, out[\"PRED\"].values)\n",
    "    by_combo = eval_by_combo(out, min_n=MIN_N)\n",
    "\n",
    "    # 저장\n",
    "    pd.DataFrame([overall]).to_csv(os.path.join(OUT_DIR, \"overall_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    out.to_csv(os.path.join(OUT_DIR, \"pred_table_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    by_combo.to_csv(os.path.join(OUT_DIR, \"by_weather_combo_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 그래프(상위/하위)\n",
    "    if len(by_combo) > 0:\n",
    "        save_bar_rank(by_combo, os.path.join(OUT_DIR, \"top_accuracy_weather_combo.png\"),\n",
    "                      title=\"TOP Weather Combo Accuracy% (AMT) [100-MAPE]\", top_n=25, ascending=False)\n",
    "        save_bar_rank(by_combo, os.path.join(OUT_DIR, \"worst_accuracy_weather_combo.png\"),\n",
    "                      title=\"WORST Weather Combo Accuracy% (AMT) [100-MAPE]\", top_n=25, ascending=True)\n",
    "\n",
    "    print(\"=== DONE ===\")\n",
    "    print(\"Test range:\", str((cutoff + pd.Timedelta(days=1)).date()), \"~\", str(max_date.date()))\n",
    "    print(\"Overall:\", overall)\n",
    "    print(\"Saved:\", OUT_DIR)\n",
    "    print(\"Combo rows:\", len(by_combo))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade94bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc100': 0.0, 'mape': 215.48902203710415, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 203.11862406228295, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 204.97233111423694, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 180.01732824880952, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 259.31642828487344, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 249.33020016091888, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 259.31642828487344, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 249.33020016091888, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 233.9226335299315, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 236.5439031531341, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 230.40529863772275, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 225.87426148148708, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 255.0247661891662, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 249.82544895962468, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 212.6227652609827, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 213.45681103203123, 'l2_regularization': 0.0, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 250.22193793793105, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 204.41399962202297, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 250.22193793793105, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 195.42447994819264, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 214.03233563469595, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 213.97608283362604, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 214.03233563469595, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 195.68346727969333, 'l2_regularization': 0.1, 'learning_rate': 0.08, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 231.50650155140627, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 238.14813340857032, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 231.50650155140627, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 238.14813340857032, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 8, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 269.7381630916994, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 242.9841407779004, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 300, 'min_samples_leaf': 40}\n",
      "{'acc100': 0.0, 'mape': 269.7381630916994, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 20}\n",
      "{'acc100': 0.0, 'mape': 201.9478681447349, 'l2_regularization': 0.1, 'learning_rate': 0.06, 'max_depth': 10, 'max_iter': 500, 'min_samples_leaf': 40}\n",
      "=== BEST ===\n",
      "{'acc100': 0.0, 'mape': 215.48902203710415, 'l2_regularization': 0.0, 'learning_rate': 0.08, 'max_depth': 8, 'max_iter': 300, 'min_samples_leaf': 20}\n"
     ]
    }
   ],
   "source": [
    "import os, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "OUT_DIR  = r\"C:/ai/source/10_1stProject/models_weather_C_fast_v2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET = \"AMT\"\n",
    "CAT = [\"DONG\",\"DAY\",\"HOUR\"]\n",
    "NUM = [\"TEMP\",\"RAIN\",\"RAIN_FLAG\",\"TEMP2\",\"HOUR_SIN\",\"HOUR_COS\"]\n",
    "FEATURES = CAT + NUM\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    denom = np.maximum(np.abs(y_true), 1.0)\n",
    "    return float(np.mean(np.abs((y_true-y_pred)/denom))*100)\n",
    "\n",
    "def acc100(y_true, y_pred):\n",
    "    return max(0.0, 100.0 - mape(y_true, y_pred))\n",
    "\n",
    "def load_clean():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "\n",
    "    for c in [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "    df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "    df = df[df[\"DAY\"].between(1,7)]\n",
    "    df = df[df[\"HOUR\"].between(1,10)]\n",
    "\n",
    "    # 가벼운 피처 엔지니어링\n",
    "    df[\"RAIN_FLAG\"] = (df[\"RAIN\"] > 0).astype(int)\n",
    "    df[\"TEMP2\"] = df[\"TEMP\"] ** 2\n",
    "    df[\"HOUR_SIN\"] = np.sin(2*np.pi*df[\"HOUR\"]/10)\n",
    "    df[\"HOUR_COS\"] = np.cos(2*np.pi*df[\"HOUR\"]/10)\n",
    "\n",
    "    return df\n",
    "\n",
    "def time_split(df, test_days=30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "    train = df[df[\"DATE\"] <= cutoff].copy()\n",
    "    test  = df[df[\"DATE\"] >  cutoff].copy()\n",
    "    return train, test\n",
    "\n",
    "def build_pipe(model):\n",
    "    cat_tf = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ])\n",
    "    num_tf = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
    "    ])\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", cat_tf, CAT),\n",
    "        (\"num\", num_tf, NUM),\n",
    "    ])\n",
    "    return Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "def tune_small():\n",
    "    df = load_clean()\n",
    "    train_df, test_df = time_split(df, test_days=30)\n",
    "\n",
    "    X_train, y_train = train_df[FEATURES], train_df[TARGET].astype(float)\n",
    "    X_test,  y_test  = test_df[FEATURES],  test_df[TARGET].astype(float)\n",
    "\n",
    "    grid = ParameterGrid({\n",
    "        \"max_depth\": [8, 10],\n",
    "        \"learning_rate\": [0.08, 0.06],\n",
    "        \"max_iter\": [300, 500],\n",
    "        \"min_samples_leaf\": [20, 40],\n",
    "        \"l2_regularization\": [0.0, 0.1],\n",
    "    })\n",
    "\n",
    "    best = None\n",
    "    for params in grid:\n",
    "        model = HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            **params\n",
    "        )\n",
    "        pipe = build_pipe(model)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        pred = pipe.predict(X_test)\n",
    "        acc = acc100(y_test, pred)\n",
    "        row = {\"acc100\": acc, \"mape\": mape(y_test, pred), **params}\n",
    "        print(row)\n",
    "\n",
    "        if (best is None) or (acc > best[\"acc100\"]):\n",
    "            best = row\n",
    "            joblib.dump(pipe, os.path.join(OUT_DIR, \"best_hgb_amt.joblib\"))\n",
    "\n",
    "    print(\"=== BEST ===\")\n",
    "    print(best)\n",
    "    return best\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tune_small()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd298c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (310466, 48) X_test shape: (133057, 48)\n",
      "Epoch 1/200\n",
      "971/971 - 2s - loss: 125849923747840.0000 - mae: 4639729.0000 - val_loss: 110771694469120.0000 - val_mae: 4488249.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 2/200\n",
      "971/971 - 2s - loss: 87777580417024.0000 - mae: 4067550.7500 - val_loss: 84871137460224.0000 - val_mae: 3737268.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "971/971 - 2s - loss: 72903211089920.0000 - mae: 3704553.2500 - val_loss: 78965783920640.0000 - val_mae: 3621848.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "971/971 - 2s - loss: 70968814862336.0000 - mae: 3659270.2500 - val_loss: 78180475994112.0000 - val_mae: 3589714.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "971/971 - 2s - loss: 70444526862336.0000 - mae: 3643949.2500 - val_loss: 77563149942784.0000 - val_mae: 3571935.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "971/971 - 2s - loss: 69925662097408.0000 - mae: 3626372.0000 - val_loss: 76962726936576.0000 - val_mae: 3560110.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "971/971 - 2s - loss: 69373658136576.0000 - mae: 3610560.5000 - val_loss: 76387956293632.0000 - val_mae: 3547838.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "971/971 - 2s - loss: 68851274350592.0000 - mae: 3598231.0000 - val_loss: 75862972039168.0000 - val_mae: 3530390.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "971/971 - 2s - loss: 68383907250176.0000 - mae: 3585848.0000 - val_loss: 75342408581120.0000 - val_mae: 3527736.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "971/971 - 2s - loss: 67978359996416.0000 - mae: 3576367.2500 - val_loss: 74968964530176.0000 - val_mae: 3525531.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "971/971 - 2s - loss: 67636494860288.0000 - mae: 3569063.5000 - val_loss: 74709077065728.0000 - val_mae: 3501312.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "971/971 - 2s - loss: 67341622706176.0000 - mae: 3560221.5000 - val_loss: 74363114094592.0000 - val_mae: 3511908.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "971/971 - 2s - loss: 67099561033728.0000 - mae: 3558055.7500 - val_loss: 74191659335680.0000 - val_mae: 3493235.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "971/971 - 2s - loss: 66895428452352.0000 - mae: 3551821.0000 - val_loss: 74048600014848.0000 - val_mae: 3488438.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "971/971 - 2s - loss: 66731636686848.0000 - mae: 3545710.2500 - val_loss: 73699826860032.0000 - val_mae: 3520511.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "971/971 - 2s - loss: 66618780549120.0000 - mae: 3547217.2500 - val_loss: 73629781983232.0000 - val_mae: 3501782.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "971/971 - 2s - loss: 66456737808384.0000 - mae: 3539521.2500 - val_loss: 73486420672512.0000 - val_mae: 3532953.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "971/971 - 2s - loss: 66391654793216.0000 - mae: 3543312.0000 - val_loss: 73359433924608.0000 - val_mae: 3509918.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "971/971 - 2s - loss: 66278790266880.0000 - mae: 3541370.7500 - val_loss: 73296292872192.0000 - val_mae: 3499300.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "971/971 - 2s - loss: 66169461538816.0000 - mae: 3538942.0000 - val_loss: 73173173272576.0000 - val_mae: 3489505.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "971/971 - 2s - loss: 66074942898176.0000 - mae: 3534508.2500 - val_loss: 73007909306368.0000 - val_mae: 3514909.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "971/971 - 2s - loss: 65952636993536.0000 - mae: 3536287.5000 - val_loss: 72909057949696.0000 - val_mae: 3487423.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "971/971 - 2s - loss: 65799251296256.0000 - mae: 3530717.7500 - val_loss: 72712907128832.0000 - val_mae: 3498772.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "971/971 - 2s - loss: 65627544879104.0000 - mae: 3528812.2500 - val_loss: 72585500950528.0000 - val_mae: 3477805.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "971/971 - 2s - loss: 65393418829824.0000 - mae: 3519425.5000 - val_loss: 72237180780544.0000 - val_mae: 3488504.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "971/971 - 2s - loss: 65029172887552.0000 - mae: 3510829.5000 - val_loss: 71866614022144.0000 - val_mae: 3453632.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "971/971 - 2s - loss: 64508571680768.0000 - mae: 3488263.0000 - val_loss: 71303713259520.0000 - val_mae: 3412287.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "971/971 - 2s - loss: 63740355543040.0000 - mae: 3446165.5000 - val_loss: 70349681065984.0000 - val_mae: 3363349.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "971/971 - 2s - loss: 62654496374784.0000 - mae: 3379957.2500 - val_loss: 69023618301952.0000 - val_mae: 3298325.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "971/971 - 2s - loss: 61266508906496.0000 - mae: 3290838.2500 - val_loss: 67425374568448.0000 - val_mae: 3222117.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "971/971 - 2s - loss: 59712351502336.0000 - mae: 3190518.5000 - val_loss: 65878485893120.0000 - val_mae: 3117419.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "971/971 - 2s - loss: 58223432302592.0000 - mae: 3103585.7500 - val_loss: 64419606298624.0000 - val_mae: 3036503.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "971/971 - 2s - loss: 56927077793792.0000 - mae: 3033409.2500 - val_loss: 63228457517056.0000 - val_mae: 2976821.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "971/971 - 2s - loss: 55924131627008.0000 - mae: 2984417.7500 - val_loss: 62349125877760.0000 - val_mae: 2921309.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "971/971 - 2s - loss: 55200081510400.0000 - mae: 2947862.7500 - val_loss: 61790427807744.0000 - val_mae: 2896150.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "971/971 - 2s - loss: 54665249030144.0000 - mae: 2926281.5000 - val_loss: 61257122054144.0000 - val_mae: 2880504.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "971/971 - 2s - loss: 54161890607104.0000 - mae: 2909769.2500 - val_loss: 60710646185984.0000 - val_mae: 2868245.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "971/971 - 2s - loss: 53644963610624.0000 - mae: 2892406.2500 - val_loss: 60163574726656.0000 - val_mae: 2869815.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 39/200\n",
      "971/971 - 2s - loss: 53106901516288.0000 - mae: 2871552.5000 - val_loss: 59646219911168.0000 - val_mae: 2854384.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "971/971 - 2s - loss: 52606953062400.0000 - mae: 2853362.0000 - val_loss: 59203632758784.0000 - val_mae: 2805068.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "971/971 - 2s - loss: 52144082255872.0000 - mae: 2834357.2500 - val_loss: 58800606281728.0000 - val_mae: 2769982.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "971/971 - 2s - loss: 51696533241856.0000 - mae: 2816083.5000 - val_loss: 58337769029632.0000 - val_mae: 2755953.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "971/971 - 2s - loss: 51257444139008.0000 - mae: 2799907.5000 - val_loss: 57943751917568.0000 - val_mae: 2732330.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "971/971 - 2s - loss: 50858570022912.0000 - mae: 2782129.2500 - val_loss: 57394906267648.0000 - val_mae: 2763750.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "971/971 - 2s - loss: 50458584416256.0000 - mae: 2768614.2500 - val_loss: 56975064825856.0000 - val_mae: 2734818.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "971/971 - 2s - loss: 50068967129088.0000 - mae: 2753078.2500 - val_loss: 56637788258304.0000 - val_mae: 2729596.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "971/971 - 2s - loss: 49679614083072.0000 - mae: 2737497.7500 - val_loss: 56226675163136.0000 - val_mae: 2700903.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "971/971 - 2s - loss: 49246287953920.0000 - mae: 2718669.0000 - val_loss: 55749778604032.0000 - val_mae: 2719831.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "971/971 - 2s - loss: 48798877351936.0000 - mae: 2700919.2500 - val_loss: 55244876677120.0000 - val_mae: 2657693.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "971/971 - 2s - loss: 48363152080896.0000 - mae: 2680577.0000 - val_loss: 54774523232256.0000 - val_mae: 2643718.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "971/971 - 2s - loss: 47890919587840.0000 - mae: 2661313.2500 - val_loss: 54321517428736.0000 - val_mae: 2616478.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "971/971 - 2s - loss: 47404149637120.0000 - mae: 2636488.5000 - val_loss: 53829089361920.0000 - val_mae: 2606223.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "971/971 - 2s - loss: 46889160409088.0000 - mae: 2614507.7500 - val_loss: 53153839972352.0000 - val_mae: 2566248.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "971/971 - 2s - loss: 46334509842432.0000 - mae: 2588610.2500 - val_loss: 52574069719040.0000 - val_mae: 2552385.5000 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "971/971 - 2s - loss: 45740617367552.0000 - mae: 2562985.5000 - val_loss: 51995268349952.0000 - val_mae: 2519247.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "971/971 - 2s - loss: 45141708505088.0000 - mae: 2534228.0000 - val_loss: 51349165178880.0000 - val_mae: 2478483.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "971/971 - 2s - loss: 44557337100288.0000 - mae: 2505646.0000 - val_loss: 50714671841280.0000 - val_mae: 2449621.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "971/971 - 2s - loss: 43958747004928.0000 - mae: 2473893.0000 - val_loss: 50179453485056.0000 - val_mae: 2403343.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "971/971 - 2s - loss: 43318889152512.0000 - mae: 2441181.0000 - val_loss: 49397408727040.0000 - val_mae: 2387874.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "971/971 - 2s - loss: 42617102401536.0000 - mae: 2404191.2500 - val_loss: 48667419475968.0000 - val_mae: 2369169.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "971/971 - 2s - loss: 41862664552448.0000 - mae: 2365442.2500 - val_loss: 47897726943232.0000 - val_mae: 2312768.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "971/971 - 2s - loss: 41022750982144.0000 - mae: 2322837.0000 - val_loss: 46934022684672.0000 - val_mae: 2281008.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "971/971 - 2s - loss: 40166345408512.0000 - mae: 2278624.7500 - val_loss: 45974663725056.0000 - val_mae: 2219731.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "971/971 - 2s - loss: 39282836242432.0000 - mae: 2232643.7500 - val_loss: 45137124130816.0000 - val_mae: 2180611.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 65/200\n",
      "971/971 - 2s - loss: 38532143906816.0000 - mae: 2194069.2500 - val_loss: 44457395224576.0000 - val_mae: 2145588.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 66/200\n",
      "971/971 - 2s - loss: 37895075266560.0000 - mae: 2155953.2500 - val_loss: 43818816634880.0000 - val_mae: 2141066.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 67/200\n",
      "971/971 - 2s - loss: 37309420404736.0000 - mae: 2126417.0000 - val_loss: 43263155240960.0000 - val_mae: 2081867.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "971/971 - 2s - loss: 36774608896000.0000 - mae: 2094734.0000 - val_loss: 42703572172800.0000 - val_mae: 2066397.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "971/971 - 2s - loss: 36286328995840.0000 - mae: 2068823.7500 - val_loss: 42237857628160.0000 - val_mae: 2010099.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "971/971 - 2s - loss: 35839228772352.0000 - mae: 2043807.6250 - val_loss: 41731911319552.0000 - val_mae: 2021746.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "971/971 - 2s - loss: 35458436300800.0000 - mae: 2024194.0000 - val_loss: 41262044413952.0000 - val_mae: 1995771.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "971/971 - 2s - loss: 35087225716736.0000 - mae: 2003938.3750 - val_loss: 40909349584896.0000 - val_mae: 1983214.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "971/971 - 2s - loss: 34734782545920.0000 - mae: 1985734.8750 - val_loss: 40576372178944.0000 - val_mae: 1940140.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "971/971 - 2s - loss: 34434908684288.0000 - mae: 1971736.5000 - val_loss: 40301745930240.0000 - val_mae: 1956413.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "971/971 - 2s - loss: 34118062571520.0000 - mae: 1957413.5000 - val_loss: 40074192355328.0000 - val_mae: 1945778.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "971/971 - 2s - loss: 33861299863552.0000 - mae: 1941506.5000 - val_loss: 39665843306496.0000 - val_mae: 1909484.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "971/971 - 2s - loss: 33609935224832.0000 - mae: 1932673.2500 - val_loss: 39472997597184.0000 - val_mae: 1920541.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "971/971 - 2s - loss: 33351838728192.0000 - mae: 1918031.3750 - val_loss: 39270186221568.0000 - val_mae: 1901555.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "971/971 - 2s - loss: 33134668152832.0000 - mae: 1907077.7500 - val_loss: 38982771539968.0000 - val_mae: 1896216.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "971/971 - 2s - loss: 32891497086976.0000 - mae: 1893192.3750 - val_loss: 38746342817792.0000 - val_mae: 1865425.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "971/971 - 2s - loss: 32679242235904.0000 - mae: 1880539.5000 - val_loss: 38517593866240.0000 - val_mae: 1852661.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "971/971 - 2s - loss: 32456640036864.0000 - mae: 1871971.7500 - val_loss: 38342439731200.0000 - val_mae: 1821280.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "971/971 - 2s - loss: 32260457758720.0000 - mae: 1857847.0000 - val_loss: 38132519010304.0000 - val_mae: 1838530.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "971/971 - 2s - loss: 32043555618816.0000 - mae: 1845402.7500 - val_loss: 37880621694976.0000 - val_mae: 1815745.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 85/200\n",
      "971/971 - 2s - loss: 31846884704256.0000 - mae: 1836028.3750 - val_loss: 37675067244544.0000 - val_mae: 1825939.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 86/200\n",
      "971/971 - 2s - loss: 31680605716480.0000 - mae: 1827522.3750 - val_loss: 37557328936960.0000 - val_mae: 1831637.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 87/200\n",
      "971/971 - 2s - loss: 31504048586752.0000 - mae: 1816962.5000 - val_loss: 37263043985408.0000 - val_mae: 1805443.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 88/200\n",
      "971/971 - 2s - loss: 31313914494976.0000 - mae: 1806739.5000 - val_loss: 37241254576128.0000 - val_mae: 1775526.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 89/200\n",
      "971/971 - 2s - loss: 31163458519040.0000 - mae: 1796897.7500 - val_loss: 36976807903232.0000 - val_mae: 1776663.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 90/200\n",
      "971/971 - 2s - loss: 30998895001600.0000 - mae: 1789558.6250 - val_loss: 36892313649152.0000 - val_mae: 1757478.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "971/971 - 2s - loss: 30834799149056.0000 - mae: 1780960.0000 - val_loss: 36665104007168.0000 - val_mae: 1770173.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "971/971 - 2s - loss: 30687830736896.0000 - mae: 1768543.6250 - val_loss: 36508975235072.0000 - val_mae: 1746235.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "971/971 - 2s - loss: 30549456453632.0000 - mae: 1761235.3750 - val_loss: 36366981267456.0000 - val_mae: 1744745.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "971/971 - 2s - loss: 30388630061056.0000 - mae: 1752595.7500 - val_loss: 36304209313792.0000 - val_mae: 1710002.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "971/971 - 2s - loss: 30260083032064.0000 - mae: 1742441.8750 - val_loss: 36108251430912.0000 - val_mae: 1720623.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 96/200\n",
      "971/971 - 2s - loss: 30122159636480.0000 - mae: 1737599.3750 - val_loss: 36044611256320.0000 - val_mae: 1721797.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "971/971 - 2s - loss: 29992905867264.0000 - mae: 1727455.1250 - val_loss: 35828952727552.0000 - val_mae: 1702528.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "971/971 - 2s - loss: 29865325625344.0000 - mae: 1719347.8750 - val_loss: 35681355169792.0000 - val_mae: 1694452.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "971/971 - 2s - loss: 29749887893504.0000 - mae: 1713175.7500 - val_loss: 35610492403712.0000 - val_mae: 1734790.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "971/971 - 2s - loss: 29606434308096.0000 - mae: 1705901.7500 - val_loss: 35515642413056.0000 - val_mae: 1695883.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 101/200\n",
      "971/971 - 2s - loss: 29477952290816.0000 - mae: 1699284.7500 - val_loss: 35455957467136.0000 - val_mae: 1676464.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "971/971 - 2s - loss: 29371716861952.0000 - mae: 1691709.7500 - val_loss: 35220359217152.0000 - val_mae: 1684522.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "971/971 - 2s - loss: 29268562149376.0000 - mae: 1688479.2500 - val_loss: 35132838772736.0000 - val_mae: 1654581.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "971/971 - 2s - loss: 29158763659264.0000 - mae: 1682183.8750 - val_loss: 35073124466688.0000 - val_mae: 1656217.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 105/200\n",
      "971/971 - 2s - loss: 29056819003392.0000 - mae: 1677318.3750 - val_loss: 35174387548160.0000 - val_mae: 1665372.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "971/971 - 2s - loss: 28947112787968.0000 - mae: 1670434.3750 - val_loss: 34780934569984.0000 - val_mae: 1663993.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "971/971 - 2s - loss: 28835661742080.0000 - mae: 1664908.1250 - val_loss: 34773890236416.0000 - val_mae: 1634418.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "971/971 - 2s - loss: 28744343355392.0000 - mae: 1659920.1250 - val_loss: 34783151259648.0000 - val_mae: 1620970.2500 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "971/971 - 2s - loss: 28634777649152.0000 - mae: 1653925.8750 - val_loss: 34479244574720.0000 - val_mae: 1645031.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "971/971 - 2s - loss: 28536471552000.0000 - mae: 1647323.0000 - val_loss: 34487090020352.0000 - val_mae: 1644902.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "971/971 - 2s - loss: 28434537381888.0000 - mae: 1645647.7500 - val_loss: 34387194281984.0000 - val_mae: 1617136.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "971/971 - 2s - loss: 28348971483136.0000 - mae: 1640768.1250 - val_loss: 34257546248192.0000 - val_mae: 1646268.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "971/971 - 2s - loss: 28244889829376.0000 - mae: 1636960.0000 - val_loss: 34092036915200.0000 - val_mae: 1626472.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "971/971 - 2s - loss: 28156822028288.0000 - mae: 1631840.3750 - val_loss: 34097229463552.0000 - val_mae: 1599771.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "971/971 - 2s - loss: 28082767396864.0000 - mae: 1625993.6250 - val_loss: 33983735791616.0000 - val_mae: 1620385.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "971/971 - 2s - loss: 27976750071808.0000 - mae: 1621966.8750 - val_loss: 33840223485952.0000 - val_mae: 1597876.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "971/971 - 2s - loss: 27897234456576.0000 - mae: 1618926.3750 - val_loss: 33892010557440.0000 - val_mae: 1591213.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "971/971 - 2s - loss: 27819090378752.0000 - mae: 1612762.2500 - val_loss: 33683822084096.0000 - val_mae: 1584780.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "971/971 - 2s - loss: 27722938056704.0000 - mae: 1609294.7500 - val_loss: 33661674061824.0000 - val_mae: 1598019.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 120/200\n",
      "971/971 - 2s - loss: 27644777201664.0000 - mae: 1607598.1250 - val_loss: 33713094131712.0000 - val_mae: 1581672.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "971/971 - 2s - loss: 27579044069376.0000 - mae: 1601294.0000 - val_loss: 33708235030528.0000 - val_mae: 1682783.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "971/971 - 2s - loss: 27495415939072.0000 - mae: 1599135.0000 - val_loss: 33533351428096.0000 - val_mae: 1560060.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "971/971 - 2s - loss: 27450060832768.0000 - mae: 1596285.1250 - val_loss: 33383256162304.0000 - val_mae: 1585007.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "971/971 - 2s - loss: 27328774144000.0000 - mae: 1593830.6250 - val_loss: 33503177605120.0000 - val_mae: 1608431.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "971/971 - 2s - loss: 27294160650240.0000 - mae: 1588524.7500 - val_loss: 33212376023040.0000 - val_mae: 1573364.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "971/971 - 2s - loss: 27220085047296.0000 - mae: 1586923.6250 - val_loss: 33146749845504.0000 - val_mae: 1566001.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "971/971 - 2s - loss: 27165175316480.0000 - mae: 1583559.5000 - val_loss: 33138673713152.0000 - val_mae: 1552618.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "971/971 - 2s - loss: 27102596300800.0000 - mae: 1579236.0000 - val_loss: 33088023298048.0000 - val_mae: 1552000.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 129/200\n",
      "971/971 - 2s - loss: 27036911403008.0000 - mae: 1577021.0000 - val_loss: 32948342489088.0000 - val_mae: 1562316.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "971/971 - 2s - loss: 26980890181632.0000 - mae: 1575408.8750 - val_loss: 32958949883904.0000 - val_mae: 1556105.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "971/971 - 2s - loss: 26931783270400.0000 - mae: 1573974.3750 - val_loss: 32780643729408.0000 - val_mae: 1556758.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "971/971 - 2s - loss: 26858554916864.0000 - mae: 1567823.2500 - val_loss: 32820542046208.0000 - val_mae: 1600596.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "971/971 - 2s - loss: 26801302667264.0000 - mae: 1566151.3750 - val_loss: 32701602070528.0000 - val_mae: 1557137.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "971/971 - 2s - loss: 26730345529344.0000 - mae: 1561695.6250 - val_loss: 32632461066240.0000 - val_mae: 1539605.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "971/971 - 2s - loss: 26685938335744.0000 - mae: 1560729.2500 - val_loss: 32626222039040.0000 - val_mae: 1532491.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "971/971 - 2s - loss: 26605147652096.0000 - mae: 1557854.3750 - val_loss: 32530889703424.0000 - val_mae: 1534934.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "971/971 - 2s - loss: 26572792791040.0000 - mae: 1556480.1250 - val_loss: 32609381908480.0000 - val_mae: 1560684.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "971/971 - 2s - loss: 26522027032576.0000 - mae: 1554022.1250 - val_loss: 32527437791232.0000 - val_mae: 1528843.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "971/971 - 2s - loss: 26455052386304.0000 - mae: 1551291.6250 - val_loss: 32484934811648.0000 - val_mae: 1534173.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "971/971 - 2s - loss: 26391370268672.0000 - mae: 1545858.3750 - val_loss: 32370220597248.0000 - val_mae: 1529847.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 141/200\n",
      "971/971 - 2s - loss: 26350152843264.0000 - mae: 1545232.0000 - val_loss: 32349888708608.0000 - val_mae: 1565504.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "971/971 - 2s - loss: 26314436247552.0000 - mae: 1544707.2500 - val_loss: 32208578412544.0000 - val_mae: 1527770.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 143/200\n",
      "971/971 - 2s - loss: 26274105917440.0000 - mae: 1542622.8750 - val_loss: 32205267009536.0000 - val_mae: 1550678.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 144/200\n",
      "971/971 - 2s - loss: 26198792994816.0000 - mae: 1536429.1250 - val_loss: 32223099092992.0000 - val_mae: 1556461.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "971/971 - 2s - loss: 26149451202560.0000 - mae: 1540835.6250 - val_loss: 32068367024128.0000 - val_mae: 1517178.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "971/971 - 2s - loss: 26094709243904.0000 - mae: 1531631.7500 - val_loss: 32345713278976.0000 - val_mae: 1633580.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "971/971 - 2s - loss: 26060823461888.0000 - mae: 1534563.6250 - val_loss: 32017045520384.0000 - val_mae: 1506451.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 148/200\n",
      "971/971 - 2s - loss: 26011928363008.0000 - mae: 1530416.2500 - val_loss: 32020841365504.0000 - val_mae: 1513739.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "971/971 - 2s - loss: 25967152070656.0000 - mae: 1529017.3750 - val_loss: 31917544046592.0000 - val_mae: 1540591.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "971/971 - 2s - loss: 25916547792896.0000 - mae: 1524198.7500 - val_loss: 31881277997056.0000 - val_mae: 1552070.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "971/971 - 2s - loss: 25882217414656.0000 - mae: 1525855.6250 - val_loss: 31808443908096.0000 - val_mae: 1517607.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 152/200\n",
      "971/971 - 2s - loss: 25807038709760.0000 - mae: 1520597.5000 - val_loss: 31858316279808.0000 - val_mae: 1507382.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "971/971 - 2s - loss: 25790116790272.0000 - mae: 1520438.5000 - val_loss: 31727688876032.0000 - val_mae: 1503938.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "971/971 - 2s - loss: 25726669553664.0000 - mae: 1518926.8750 - val_loss: 31659739054080.0000 - val_mae: 1509083.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 155/200\n",
      "971/971 - 2s - loss: 25680490266624.0000 - mae: 1516210.0000 - val_loss: 31628002852864.0000 - val_mae: 1501967.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "971/971 - 2s - loss: 25618664128512.0000 - mae: 1513221.0000 - val_loss: 31711777783808.0000 - val_mae: 1505272.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "971/971 - 2s - loss: 25584098869248.0000 - mae: 1509030.8750 - val_loss: 31592162525184.0000 - val_mae: 1503056.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "971/971 - 2s - loss: 25538219474944.0000 - mae: 1509850.8750 - val_loss: 31628093030400.0000 - val_mae: 1514425.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "971/971 - 2s - loss: 25492012924928.0000 - mae: 1508745.0000 - val_loss: 31596558155776.0000 - val_mae: 1477528.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "971/971 - 2s - loss: 25463160307712.0000 - mae: 1507593.8750 - val_loss: 31495687241728.0000 - val_mae: 1481464.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "971/971 - 2s - loss: 25430935470080.0000 - mae: 1504627.1250 - val_loss: 31449560383488.0000 - val_mae: 1485126.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "971/971 - 2s - loss: 25374866014208.0000 - mae: 1501160.2500 - val_loss: 31400375877632.0000 - val_mae: 1516000.2500 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "971/971 - 2s - loss: 25311173410816.0000 - mae: 1500577.3750 - val_loss: 31391999852544.0000 - val_mae: 1480722.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "971/971 - 2s - loss: 25291504222208.0000 - mae: 1497412.2500 - val_loss: 31306486382592.0000 - val_mae: 1479519.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "971/971 - 2s - loss: 25268278263808.0000 - mae: 1497599.1250 - val_loss: 31298691268608.0000 - val_mae: 1517694.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "971/971 - 2s - loss: 25229749387264.0000 - mae: 1495221.7500 - val_loss: 31228593963008.0000 - val_mae: 1512428.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 167/200\n",
      "971/971 - 2s - loss: 25199571369984.0000 - mae: 1492856.1250 - val_loss: 31242311434240.0000 - val_mae: 1492811.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "971/971 - 2s - loss: 25146777665536.0000 - mae: 1489183.3750 - val_loss: 31193384878080.0000 - val_mae: 1471614.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "971/971 - 2s - loss: 25117270736896.0000 - mae: 1492723.3750 - val_loss: 31112569028608.0000 - val_mae: 1480388.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "971/971 - 2s - loss: 25067301896192.0000 - mae: 1487215.7500 - val_loss: 31056264691712.0000 - val_mae: 1475788.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "971/971 - 2s - loss: 25027244195840.0000 - mae: 1485906.8750 - val_loss: 31041070825472.0000 - val_mae: 1457504.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "971/971 - 2s - loss: 25021906944000.0000 - mae: 1485536.0000 - val_loss: 31013778489344.0000 - val_mae: 1466500.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "971/971 - 2s - loss: 24957530669056.0000 - mae: 1480825.2500 - val_loss: 31033602867200.0000 - val_mae: 1458937.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "971/971 - 2s - loss: 24926215995392.0000 - mae: 1482036.8750 - val_loss: 31044459823104.0000 - val_mae: 1488219.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "971/971 - 2s - loss: 24911517057024.0000 - mae: 1479159.3750 - val_loss: 30985565503488.0000 - val_mae: 1469972.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 176/200\n",
      "971/971 - 2s - loss: 24855453892608.0000 - mae: 1475166.6250 - val_loss: 30956551405568.0000 - val_mae: 1474621.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "971/971 - 2s - loss: 24833500905472.0000 - mae: 1476520.8750 - val_loss: 30813078945792.0000 - val_mae: 1449080.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "971/971 - 2s - loss: 24790301671424.0000 - mae: 1471923.7500 - val_loss: 30883073490944.0000 - val_mae: 1444085.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "971/971 - 2s - loss: 24755514114048.0000 - mae: 1469672.0000 - val_loss: 30772637466624.0000 - val_mae: 1479105.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "971/971 - 2s - loss: 24693948022784.0000 - mae: 1468865.2500 - val_loss: 30775026122752.0000 - val_mae: 1468406.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 181/200\n",
      "971/971 - 2s - loss: 24674715041792.0000 - mae: 1468833.0000 - val_loss: 30719485149184.0000 - val_mae: 1467610.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "971/971 - 2s - loss: 24629118763008.0000 - mae: 1466948.3750 - val_loss: 30718923112448.0000 - val_mae: 1504836.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "971/971 - 2s - loss: 24638417534976.0000 - mae: 1468314.8750 - val_loss: 30626019278848.0000 - val_mae: 1435565.6250 - 2s/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "971/971 - 2s - loss: 24569605783552.0000 - mae: 1461024.2500 - val_loss: 30732974030848.0000 - val_mae: 1441273.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 185/200\n",
      "971/971 - 2s - loss: 24558375534592.0000 - mae: 1461816.0000 - val_loss: 30696393408512.0000 - val_mae: 1517070.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 186/200\n",
      "971/971 - 2s - loss: 24524319883264.0000 - mae: 1460172.1250 - val_loss: 30656520257536.0000 - val_mae: 1464477.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 187/200\n",
      "971/971 - 2s - loss: 24511135088640.0000 - mae: 1461010.7500 - val_loss: 30484182597632.0000 - val_mae: 1436253.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "971/971 - 2s - loss: 24472323096576.0000 - mae: 1454459.1250 - val_loss: 30500336959488.0000 - val_mae: 1443653.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "971/971 - 2s - loss: 24453870256128.0000 - mae: 1456012.3750 - val_loss: 30467663331328.0000 - val_mae: 1443422.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "971/971 - 2s - loss: 24371682869248.0000 - mae: 1454133.7500 - val_loss: 30683363803136.0000 - val_mae: 1425633.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "971/971 - 2s - loss: 24388797726720.0000 - mae: 1453806.1250 - val_loss: 30434536718336.0000 - val_mae: 1431606.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "971/971 - 2s - loss: 24376707645440.0000 - mae: 1454666.0000 - val_loss: 30377011838976.0000 - val_mae: 1455114.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "971/971 - 2s - loss: 24348928770048.0000 - mae: 1451160.8750 - val_loss: 30326575333376.0000 - val_mae: 1454685.8750 - 2s/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "971/971 - 2s - loss: 24330704519168.0000 - mae: 1450133.3750 - val_loss: 30311746371584.0000 - val_mae: 1428994.1250 - 2s/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "971/971 - 2s - loss: 24285745774592.0000 - mae: 1446458.8750 - val_loss: 30310005735424.0000 - val_mae: 1444196.5000 - 2s/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "971/971 - 2s - loss: 24268429590528.0000 - mae: 1449585.7500 - val_loss: 30393277349888.0000 - val_mae: 1425410.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "971/971 - 2s - loss: 24229768593408.0000 - mae: 1444278.2500 - val_loss: 30283401265152.0000 - val_mae: 1438058.3750 - 2s/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "971/971 - 2s - loss: 24205382909952.0000 - mae: 1445402.1250 - val_loss: 30450118557696.0000 - val_mae: 1432445.7500 - 2s/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "971/971 - 2s - loss: 24189293559808.0000 - mae: 1442788.5000 - val_loss: 30298075037696.0000 - val_mae: 1475543.2500 - 2s/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "971/971 - 2s - loss: 24179223035904.0000 - mae: 1442351.5000 - val_loss: 30262517825536.0000 - val_mae: 1423088.1250 - 2s/epoch - 2ms/step\n",
      "[TEST] loss(mse)=25478060572672.0000  mae=1437699.7500\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABwr0lEQVR4nO3dCZyM9R8H8M/e91q7y7qt+75vCqFckU6kUKRDVChUqFS6U1HUP7oIKTqI5Mp9CzmXPcSuxdr7npn/6/tbM82utXbXXPvM5+31vGbmmeuZZ8bMZ7+/43ExGAwGEBEREVGZ52rvDSAiIiIiy2CwIyIiItIIBjsiIiIijWCwIyIiItIIBjsiIiIijWCwIyIiItIIBjsiIiIijWCwIyIiItIIBjsiIiIijWCwI3JSI0eORHh4eKnu+8orr8DFxcXi20TAO++8g4YNG0Kv15t2h+xr2edkGZcvX4afnx9Wr17NXUqaw2BH5GDkR7w4y6ZNm+DM5PXfc889qFSpEjw9PVGxYkUMGDAAP/30E8qq5ORkvP3225g8eTJcXcvG1/OVK1fg7u6OZcuWoawICQnB6NGjMW3aNHtvCpHFufBYsUSO5bvvvst3+ZtvvsG6devw7bff5lt/++23IywsrNTPk5OTo6pCXl5eJb5vbm6uWry9vWEPM2bMwGuvvYZ69eph6NChqFmzpqrCSAVGAt+iRYvw4IMPoqyZPXu2em0XLlzIt28lyMt6R6zaLVmyBA8//DAuXryIoKAglBXHjh1D48aNsX79evTo0cPem0NkMe6WeygisoSHHnoo3+WdO3eqYFdwfUHp6enw9fUt9vN4eHiUehulQiOLPSxfvlyFuvvuuw+LFy/O9zqef/55rF27VoVWSyjpPr1ZCxcuxMCBA+0WmEtDwnSXLl3KVKgTjRo1QtOmTfHVV18x2JGmlI1aPxHl0717d/WjtG/fPnTt2lWFjxdffFFd9/PPP6N///6oUqWKqsbVqVMHM2fOhE6nK7KPXVRUlKoMvffee/j888/V/eT+7dq1w549e27Yx04uP/3001i5cqXaNrlvkyZNsGbNmmvePamqtW3bVgUYeZ758+cXu9+eNJ8FBwdjwYIFhYbT3r17484771Tn5UdbHlNeW8HnL9icfb19Ko9Vu3btQrelU6dO6nUUrLi2adMGPj4+ajuHDBmCs2fP3vB1RUZG4tChQ+jVqxeK48CBA+jbty8CAwPh7++Pnj17qj8CzEnAffXVV1VlU/a1NEHecsst6g8Fo7i4ODzyyCOoVq2aes8qV66Mu+6665p9Vhip+Mr7K5+3ohj3rby+bt26qX1bt25dFdLF5s2b0aFDB7XPGjRogD///DPf/aOjo/HUU0+p6+Q28jruv//+QrcxMTERzz77LKpXr65ejzyPNG+b91k0r3r/+uuvMBgMN3ytRGUFK3ZEZZQ0PcoPuwQHqeYZm2UlzMgP/YQJE9Tphg0bMH36dNV/6913373h40oVLCUlBY8//rgKP9KZX/qynTlz5oZVvq1bt6o+bvIjHBAQgI8//hj33nsvYmJi1I+xMZD06dNHBQgJHRI4pQJXoUKFG27bqVOncPz4cTz66KPq8W2xTyWkDR8+XIVbCbnmYUOClPk+feONN1TwfOCBB1QfLmme/OSTT1RQlNddVFVr+/bt6rR169Y33M5//vkHt956qwp1L7zwgnpfJBxLgDKGJCFhedasWWpb2rdvrz4De/fuxf79+1WoEfL+yOONGzdOBf34+HgV/OQ9u9HgGtkn8hr79etXrL54EpJl30oo++yzz9R5aTaXIPbEE0+o5nPZn1KNlTBsfI/leWT/yO0lgEqgk/vL6z169KipqioVVgmO586dU5/fGjVqqPtNnToVsbGxqqnbnLy3H374oXr9EjyJNEH62BGR4xo7dqyUE/Kt69atm1o3b968a26fnp5+zbrHH3/c4Ovra8jMzDStGzFihKFmzZqmy5GRkeoxQ0JCDAkJCab1P//8s1r/66+/mtbNmDHjmm2Sy56enoaIiAjTur///lut/+STT0zrBgwYoLbl3LlzpnWnTp0yuLu7X/OYBRm35cMPPzQUx8KFC9Xt5bWZ27hxo1ovpzfap0lJSQYvLy/DxIkT861/5513DC4uLobo6Gh1OSoqyuDm5mZ444038t3u8OHD6rUVXF/Qyy+/rJ4/JSXlmutkvexzo0GDBql9ffr0adO68+fPGwICAgxdu3Y1rWvRooWhf//+133OK1euqMd+9913DaUxbdq0fJ+h6zHu28WLF5vWHT9+XK1zdXU17Ny507R+7dq1ar28d0V9pnfs2KFu980335jWzZw50+Dn52c4efJkvttOmTJFvTcxMTH51m/fvl09xtKlS0vwqokcG5tiicooaWaSJrSCpKnKSCpvly5dUtUdqWZItetGBg8ejPLly5suy32FVOxuRJoRpWnVqHnz5qqqZLyvVOekmW3QoEGqqdhImsukUnYjUnES1qjWXW+fyvbLtsmoT/Mmu6VLl6Jjx46qKiSkUinNfVKtk31uXGTUrjSFbty48YbVQum3KFXWosg+/OOPP9Q+NG8ilgqoVLykamrcT1IhlGqUVDoLI58VGVEsTdJSUStN/7obNcMayeuSipuRNKvK9klfN2OFURjPm3/ezD/T0rws+0o+M3J/qT4a/fDDD+rzKp9f8/dAPpey3/76669822T8nMttiLTCqYOd/CeX6RHkB0aanKRvUElkZmaqfkrNmjVTX8jyRVuUbdu2qdu1bNnyJrecCKhatar6US5IfsjvvvtulCtXToUSaeI0DrxISkq64a4zBpWCP37F+eEveF/j/Y33lWa+jIwM9aNcUGHrCpLXYwysttynEnalaXDHjh3q8unTp1VfPFlvJOFJgp+EONnn5ouMwJTXbgnS9CkhXYJRQRKSJFwa+/RJE7f0Oatfv776npLBJdLPzTzISv+z33//XTU7S5OxNL1Lv7sbkdtIqCpusJMm1IJ9KOUzKn3hCq4r+HmTz4x0JzD2mwsNDVX7VV6b+Wda3gPp81dw/xv7LRZ8D4xBnXMykpY4dR+7tLQ0tGjRQvXXkT5EJSV/AcpfkuPHj8ePP/5Y5G3lC0j66UgHZ5nKgOhmmVcxzD9n0sdIApD8qEv1TDrNyw+wzI1WWAfygtzc3ApdX5wO5jdz3+KQiXvF4cOHi3X76/1gFxxIUtQ+FfIHoPTjkqpd586d1anMMyd9xYxk38rzSUgqbD/cqBInfRBlChkJrZaqSEpQkxAqA2qkyve///1P9SmbN2+e6ncnpH+bvD75w1ZGFEsfQemXJ30zW7Vqdd3Hltcpn63bbrutWNtyvc9GcT4z0v9PRgzLtsqAFQl/sq+lAmj+mZbz0ndQ+h0WRgKuOWN4lKBIpBVOHeykeaWo5p+srCy89NJL+P7779UPpnSulb9upcOukJnLpQOvsRont7keY8dg+RIraWWQqLikSU2aqaRZUH7UzUdcOgKZRFjCQERExDXXFbausB9mqVRJUPnoo49uGJaM1caC/zdl4ENJyP916fgvTX0ffPCBaoaVJj/z5mQJ0RJGatWqdU2AKElolfdKmrCvRypQEjJPnDhxzXXS1C6B07wKJiNzpXlZltTUVPW5kEEVxmBn3PaJEyeqRape0qrw/vvvXzOnorlVq1apUHe9MGxJMnp2xIgRapvMW0wKvq/yOuQ1FndksfH/hVQ6ibTCqZtib0SmbpCmF5mAU5ov5K9zGc13vf4q1yN/aUp/EZlglMiajNUP82pHdnY2Pv30U4fZPvnRlT9uzp8/ny/USQWoOGQkrYRXCSZS4SpIKlO//fabOm/s72fet0qqdTKdS0lJs6tss1S9/v7773zNsEKq/vL6ZPsKVijlsmxzUaQSJWTUalHkOe644w4Vbs2n+5CWABnRLNOZGJusCz6nBGFp8pY/WoU06UpAMif7TCqGxtsURvq5ycjZ4jbD3ix5zQX3qYw2Llh5lf6N8p0tlceCJAQW/LxIc7pU/2RaHiKtcOqKXVFkqL8EMjk1/lU+adIk1X9D1r/55pvFehwJgVOmTMGWLVvsNqErOQ9pJpQqlVQ3pIuANFfJESscaZ4uqRZJ+JJJbZ988kn14zxnzhxVET948OAN7y+BSppiZWoRmULE/MgT8v9TjiQgAUfID7YMcJDpLhISElT1Sv5QKywQ3ohM6SGBR74HJGjINCEFA9Hrr7+unksCl/S5ldtLVWjFihUYM2aMuu/1yEAI2QcyuES6hxRFnkeClYQ4mVpGvltkuhMJY9JHzkiOrCAtDDKth7x2CY1S/ZI/WsXJkydV9xAJRHJbeRzZVgmJ5gMdCjIO0LBVsJNqqXyOJYTJdkp4k/1knELHSPoQ/vLLL+r20v9ZXrd0uZHPi7xueV/Mm11lH0ozNPvYkZYwaVyHfBHID07BJhX54iz4ZXI9cn9pfpW/4EvTNENUUvLZlGqVNKm9/PLLKuTJwAn58ZaJex2B/NhKdU5CjvTnkmZD6Q8oAwyKM2rXGGzkMFAyT550h5DQJq9VQpxUsuToDUYyT5rMafbWW2+pUZSjRo1STYjGedyKS5qQ5XHl8aTqKM3KBckfcfJ/Xfqxyf97Ia9PKmzm23Q9EuhkkIAMFiiqiVMCq/yxKCFS+sNJ3zIZTSpNp+YjTCXcS9CRIC3fXRKAZd9JADJumwRjCcMSnCTYSZOw9CEsGFwLjoaVgCWPZwvS7C5hWva9VBjljwIJdgU/09JELfP4yR/e0mwuh+OT6qW8J/J+GAdmCPmsHTly5Jq57YjKOh4r1rgjXFzUX6rGka3Sh2bYsGFqhGHBzr3SnCFTGJiTvw6l1G/ef04uy4+N+f3lC1iqJ7JOvmx5jEKiPPJ/r6ipOZyBjPCUyp1U3SSAOioJdVIVM68OljUyEEOa6KU5lhU70hJW7K5DRoNJxU2Gxxvn8Sop+Uux4Og96esko82kWUA6WRM5o4IVKQlzUgWSJmRnJhUlGdEpR1+QwQ4yEMLRSJ9NaQ6X5tuySprtpa+kVCYZ6khrnLpiJ6OnjCPxJMjJaDdpopG+KDIflzRhyWhXGYkl18v8UdJkISPWjH1L5HA28kUnzScyTYE0wYjrzVUn/YukqlecvkREWiWT6UqVW6pTMkJVmlOlqVD6zMk8cEREVDpOXbGTjsTmczDJsTWFVA3keJsySEL6o0h/JTn2oHS6lT48xgOMGztUm0+dYJz3yYnzMtENyehymUZIJrmVCWdlRKj0i2KoIyK6OU5dsSMiIiLSEsfrwEFEREREpcJgR0RERKQRTtfHTqYbkdnjZeJQjoYiIiIiRye95mSAphww4Uaj5Z0u2EmoMz+OIhEREVFZcPbsWVSrVq3I2zhdsJNKnXHnGI+nSEREROSo5BB+UpQyZpiiOF2wMza/SqhjsCMiIqKyojhdyDh4goiIiEgjGOyIiIiINILBjoiIiEgjnK6PHRERkbNN8yXHNCfH5eHhATc3N4s8FoMdERGRRkmgi4yMVOGOHFtQUBAqVap003PsMtgRERFpdFLb2NhYVQmSqTJuNLEt2e99Sk9PR3x8vLpcuXLlm3o8BjsiIiINys3NVYFBjlbg6+tr782hIvj4+KhTCXcVK1a8qWZZxnciIiIN0ul06tTT09Pem0LFYAzfOTk5uBkMdkRERBrG46I71/vEYEdERESkEQx2RERE5DC6d++OZ5991t6bUWYx2BERERFpBIMdERERkUYw2FnBpdQs7IlKwLHYZGs8PBERkVO4cuUKhg8fjvLly6tRo3379sWpU6dM10dHR2PAgAHqej8/PzRp0gSrV6823XfYsGGoUKGCmk6kXr16WLhwIbSO89hZwcbj8Xh++SHc1qACFj7S3hpPQUREVOKJcDNy8qZAsTUfD7dSjfocOXKkCnK//PILAgMDMXnyZPTr1w9Hjx5Vh+EaO3asOrrGX3/9pYLd0aNH4e/vr+47bdo0dfn3339HaGgoIiIikJGRAa1jsLMCT/e8QmiOzmCNhyciIioxCXWNp6+1y547+lpv+HqWLHIYA922bdvQuXNntW7RokXqKBorV67E/fffj5iYGNx7771o1qyZur527dqm+8t1rVq1Qtu2bdXl8PBwOAM2xVqBh1vebs3O5bH5iIiISuPYsWNwd3dHhw4dTOtCQkLQoEEDdZ0YP348Xn/9dXTp0gUzZszAoUOHTLd98sknsWTJErRs2RIvvPACtm/f7hRvBCt21gx2OgY7IiJyDNIcKpUzez23NYwePRq9e/fGqlWr8Mcff2DWrFl4//33MW7cONUfT/rgSZ+7devWoWfPnqrp9r333oOWsWJn1aZYBjsiInIM0sdNmkPtsZSmf12jRo3U8W537dplWnf58mWcOHECjRs3Nq2TptknnngCP/30EyZOnIgvvvjCdJ0MnBgxYgS+++47zJ49G59//jm0jhU7K/Bwy/sAM9gRERGVjoxiveuuu/DYY49h/vz5CAgIwJQpU1C1alW1XshExlKZq1+/vhoFu3HjRhUIxfTp09GmTRs1UjYrKwu//fab6TotY8XOCjyvNsVy8AQREVHpyfQkEs7uvPNOdOrUSY3slaZVGRErdDqdal6VwNanTx8V8D799NO832JPT0ydOhXNmzdH165d4ebmpvrcaZ2LQfaSE0lOTka5cuWQlJSkhk5bw99nE3HX3G2oGuSDbVN6WOU5iIiIipKZmYnIyEjUqlUL3t7e3Fll+P0qSXZhxc4KOHiCiIiI7IHBzgo83dnHjoiIiGyPwc4KPN3yhnXncB47IiIisiEGOyvwMFXsnKr7IhEREdkZg52V+9g52dgUIiIictZgJwftHTBgAKpUqaImL5RjvxVFJh+8/fbb1YSDMipEhj6vXWuf494VJ9gJVu2IiIjIKYJdWloaWrRogblz5xY7CEqwkzls9u3bh9tuu00FwwMHDsAR57ETnKSYiIiInOLIEzJbtCzFJYcDMffmm2/i559/xq+//opWrVrB0Q4pJhjsiIiIyFbK9CHF9Ho9UlJSEBwcfN3byGFEZDGf5M/a3Fxd4OoC6A15/eyIiIiIbKFMD5547733kJqaigceeOC6t5k1a5aardm4yMGCbdnPjn3siIiIyFbKbLBbvHgxXn31VSxbtgwVK1a87u3kOHFyCA7jcvbsWdseL5Zz2REREZGNlMmmWDmI7+jRo/HDDz+gV69eRd7Wy8tLLbbmIf3sstgUS0RERLZT5ip233//PR555BF12r9/fzgqD7e8SYqzWbEjIiIqtu7du2PcuHF49tlnUb58eYSFheGLL75QM2nI739AQADq1q2L33//Xd1ep9Nh1KhRqFWrFnx8fNCgQQN89NFH1zzu//73PzRq1Aje3t5o2LAhPv30U02+K3at2En/uIiICNPlyMhIHDx4UA2GqFGjhmpGPXfuHL755htT8+uIESPUG9ahQwfExcWp9fJGSv85R2IcGctRsURE5BBkwvycdPs8t4cv4JJX8CiOr7/+Gi+88AJ2796NpUuX4sknn8SKFStw991348UXX8SHH36Ihx9+GDExMfDw8EC1atVUK15ISAi2b9+OMWPGoHLlyqY++IsWLcL06dMxZ84cNYuGTJP22GOPwc/PT+UKLXEx2PHQCJs2bVJz0RUkO/mrr77CyJEjERUVpW5nTPGbN2++7u2LQ0bFSgiU/nYyybG19Hh/E85cTMOyxzuhfa3rj9olIiKyhszMTFUwkUqWVKmQnQa8WcU+O/vF84CnX7FuKr/1UoXbsmWLuizn5Xf7nnvuMRV6pLAjwW3Hjh3o2LHjNY/x9NNPq9ssX75cXZYK38yZMzF06FDTbV5//XU1L64EQYd8v0qZXexasZM3r6hcWTCsGQNeWWAaPMHpToiIiEqkefPmpvNubm6qEtesWTPTOmmeFfHx8epUDnSwYMECVcHLyMhAdnY2WrZsqa6TJtzTp0+r5lqp0hnl5uY6XGuf0w6eKGvHiyUiIrI7aQ6Vypm9nrskN/fwyHdZDjtqvk4uG+ezlQGVkyZNwvvvv68ONSp98N59913s2rXL1O1LSD896cZlTkKj1jDYWQkHTxARkUORMFTM5tCyZNu2bejcuTOeeuop0zqp0JlX9+SY9GfOnMGwYcOgdQx2VsLBE0RERNZXr1491fdu7dq1qn/at99+iz179qjzRjLv7fjx41XTa58+fdQRqfbu3YsrV65gwoQJmnqbytx0J2XFf0eeYFMsERGRtTz++ONqYMXgwYNVU+vly5fzVe+EzH0r050sXLhQ9dXr1q2b6sdvHv60wq6jYu3BVqNiR321B+uPx+Ode5vjgXa2OYwZERFRcUZZkuOx1KhYVuyshIMniIiIyNYY7Kx5SDEeeYKIiIhsiMHOyqNi2ceOiIiIbIXBzkq8eEgxIiIisjEGO6v3sXOqsSlERERkRwx2VsLpToiIiMjWGOysHexyOY8dERER2QaDnZV4Xh08wWPFEhERka0w2FkJDylGREREtsZgZ+3BE7kcPEFERGRL4eHhmD17drFu6+LigpUrV0IrGOyshIMniIiIyNYY7Kx85AlOUExERES2wmBnBWeTz+J4yga4+Z1ksCMiIiqBzz//HFWqVIFen39WibvuuguPPvooTp8+rc6HhYXB398f7dq1w59//mmxfXz48GH06NEDPj4+CAkJwZgxY5Cammq6ftOmTWjfvj38/PwQFBSELl26IDo6Wl33999/47bbbkNAQAACAwPRpk0b7N27F7bEYGcF++L34ZfzH8AzeBuyON0JERE5AIPBgPScdLss8tzFdf/99+Py5cvYuHGjaV1CQgLWrFmDYcOGqZDVr18/rF+/HgcOHECfPn0wYMAAxMTE3PQ+SktLQ+/evVG+fHns2bMHP/zwgwqNTz/9tLo+NzcXgwYNQrdu3XDo0CHs2LFDBT/ppydk+6pVq6buu2/fPkyZMgUeHh6wJXebPpuT8HbzzjvjksOKHREROYSM3Ax0WNzBLs+968Fd8PXwLdZtJVT17dsXixcvRs+ePdW65cuXIzQ0VFXDXF1d0aJFC9PtZ86ciRUrVuCXX34xBbDSkufMzMzEN998oypyYs6cOSo4vv322yqkJSUl4c4770SdOnXU9Y0aNTLdX8Ll888/j4YNG6rL9erVg62xYmcFXm5e6tTFVYIdR8USERGVhFS+fvzxR2RlZanLixYtwpAhQ1Sok4rdpEmTVKCSplBpjj127JhFKnbHjh1TodEY6oQ0tUqz8IkTJxAcHIyRI0eqqp6EvY8++gixsbGm206YMAGjR49Gr1698NZbb6lmY1tjxc4KvNy9/qvYsSmWiIgcgI+7j6qc2eu5S0JCkzTfrlq1SvWh27JlCz788EN1nYS6devW4b333kPdunVVX7j77rsP2dnZsIWFCxdi/Pjxqml46dKlePnll9X2dOzYEa+88goefPBBtd2///47ZsyYgSVLluDuu++GrTDYWbEpVip22Qx2RETkAKQfWHGbQ+3N29sb99xzj6rURUREoEGDBmjdurW6btu2bapqZgxLUsGLioqyyPM2atQIX331leprZ6zayfNJpVC2wahVq1ZqmTp1Kjp16qSacCXYifr166vlueeew9ChQ1UQtGWwY1OstSt2Oh4rloiIqDTNsVL5WrBggTpvJP3WfvrpJxw8eFCNQpUKWcERtKUlzyOhcsSIEThy5IgawDFu3Dg8/PDDahRuZGSkCnMyaEJGwv7xxx84deqUCoQZGRmqj5+MmpXrJBDKIArzPni2wIqdNSt2Lrk8ViwREVEpyJQj0qdN+rZJeDP64IMP1LQnnTt3VgMqJk+ejOTkZIvsY19fX6xduxbPPPOMagKWy/fee696TuP1x48fx9dff61G7lauXBljx47F448/rkbMyrrhw4fjwoULatuk6vjqq6/a9P13MZRkDLIGyJtfrlw5NapF5pixhn9T/kXfn/rCoPeAf+y72Pli3qgeIiIiW5HRnVJhqlWrlqpCUdl9v0qSXdgUawXe7mZ97HQ6azwFERER0TUY7Kw43YnI0dtmlA4RERHlJ4MvZDqUwpYmTZpAi9jHzpoTFKtglzcHDxEREdnWwIED0aFD4ZMy2/qIELbCYGeNnerqDlcXN+gNOlbsiIiI7CQgIEAtzoRNsVaaK8jYHKtHDnR6pxqfQkRERHbCYGcl3vkOK8a57IiIiMj6GOysxMvYz85FRsYy2BEREZH1MdhZiffVo0+48HixREREZCMMdlaeyw6uucjRsY8dERERWR+DnZUYB0+4uGYjO5dNsURERLYSHh6O2bNnO+UOZ7Cz9lx2PF4sERER2QiDnZV4mfex4+AJIiIisgEGO2sfVozTnRARERXb559/jipVqkCvz9+N6a677sKjjz6K06dPq/NhYWHq0GDt2rXDn3/+eVNzz86fPx933nknfH190ahRI+zYsQMRERHo3r07/Pz80LlzZ/W8RsXZhqysLEyaNAlVq1ZVjyFHwNi0aZPVPwkMdlZvimXFjoiI7M9gMECfnm6XRZ67uO6//35cvnwZGzduNK1LSEjAmjVrMGzYMKSmpqJfv35Yv349Dhw4gD59+mDAgAGIiYkp9b6ZOXMmhg8fjoMHD6Jhw4Z48MEH8fjjj2Pq1KnYu3ev2v6nn37adPvibIPcXgLikiVLcOjQIfW65HanTp2CNfGQYlYeFSsTFGfnclQsERHZlyEjAydat7HLczfYvw8uvr7Fum358uXRt29fLF68GD179lTrli9fjtDQUNx2221wdXVFixYt8oWyFStW4JdffskXvkrikUcewQMPPKDOT548GZ06dcK0adPQu3dvte6ZZ55RtzGS5y9qGyTgLVy4UJ1K9VFI9U7Cqax/8803YS2s2Fm7KZaDJ4iIiEpEKnM//vijas4UixYtwpAhQ1Sok2qZhCRpMg0KClJNoceOHbupil3z5s1N56V5VTRr1izfuszMTCQnJ6vLN9qGw4cPQ6fToX79+uo647J58+Z8TbrWwIqdDSp2OZzuhIiI7MzFx0dVzuz13CUhzZrS/Llq1SrVf23Lli348MMP1XUSqNatW4f33nsPdevWhY+PD+677z5kZ2eXevs8PDz+21YXl+uuM/b7u9E2SPBzc3PDvn371Kk5CXjWxGBn9Yod+9gREZH9STgpbnOovXl7e+Oee+5RlToZxNCgQQO0bt1aXbdt2zaMHDkSd999tylERUVF2XT7tt1gG1q1aqUqdvHx8bj11lttum12bYr966+/VCqX9mf5wK1cufKG95ERJfLmenl5qZT81VdfwZEHT8h0JzxWLBERUcmbY6Vit2DBAnXeqF69evjpp5/UQIe///5bDXQoOILW2m60DdIEK9ssAzLkdpGRkdi9ezdmzZqlXpNmg11aWprqfDh37txi3V52TP/+/VXnSdmZzz77LEaPHo21a9fCUeex4yHFiIiISq5Hjx4IDg7GiRMnVHAy+uCDD9QAC5mCRIpDMsDBWM2zleJsgwySkGA3ceJEVXEcNGgQ9uzZgxo1alh121wMJRmDbEVSsZMRJfLCr0dGqkjSPXLkiGmddKZMTExUI02KQzo+litXDklJSQgMDIS1rDi1AtO3T0duSkNMb/8+hra37htJRERkTjr7S0GkVq1aqmmTyu77VZLsUqZGxcp8ML169cq3TlKyrHfcCYp5rFgiIiKyjTIV7OLi4kzDkI3ksiTZjIyMQu8jQ6XlevPFtocUy+UhxYiIiOxg0aJF+aYbMV+aNGmiyfdE86NipaPiq6++ar8jT8gExTxWLBERkc0NHDhQHcqrMObTmWhJmQp2lSpVwoULF/Ktk8vS3ixzyBRGDgcyYcIE02Wp2FWvXt1mTbEyKjaHR54gIiKyuYCAALU4kzIV7OQQH6tXr863TiYIlPXXI9OiyGKvCYqlYpfDih0RERFpvY+dTOgn05bIImQ0iJw3HpJDqm0yVNjoiSeewJkzZ/DCCy/g+PHj+PTTT7Fs2TI899xzcDSmplgeUoyIiOzIQSa/IBu9T3YNdnv37lWzM8sipMlUzk+fPl1djo2NzXfsNxkCLNOdSJVO5r97//338b///c90kF5HYho8IX3seEgxIiKyMeOhrG7mUFtkO+np6Rbp+2fXptju3bsXmVALO6qE3OfAgQNwdP9V7CTY6ey9OURE5GTc3d3h6+uLixcvqrDg6lqmJsJwGgaDQYU6OfxYUFDQNceW1XQfu7Lkv+lODMjW5dh7c4iIyMnIxP+VK1dW3Zyio6PtvTl0AxLqZJDozWKws3bFTubS02VZ62mIiIiuy9PTUx3XlM2xjk0qqjdbqTNisLMSD1dpI3eRIisydZnWehoiIqIiSRMsDynmPNjgbsUSuIeLpzqfmcuKHREREVkfg50Vubvm9bPL1rNiR0RERNbHYGdFHq55FbtsPSt2REREZH0MdlbkebVil6PjHEJERERkfQx2Ngh2rNgRERGRLTDYWZHX1SlPctgUS0RERDbAYGdFnm5Xm2IZ7IiIiMgGGOysyOtqsMs1sI8dERERWR+DnQ2CnY7BjoiIiGyAwc6KvN3z+tixYkdERES2wGBng2CnA5tiiYiIyPoY7KzIxz2vKVbPplgiIiKyAQY7K/JhxY6IiIhsiMHOBsFOjxwYDAZrPhURERERg501+XrkBTsXlxzk6BjsiIiIyLpYsbMiXw+fq3tZgp3emk9FRERExGBnu4odgx0RERFZFyt2NqnY5SI7l8GOiIiIrIvBzoq83f6r2GWzYkdERERWxmBnRV5X57HL62PHwRNERERkXQx2NjhWLNjHjoiIiGyAwc5WTbHsY0dERERWxmBnk6bYXI6KJSIiIqtjsLMiVuyIiIjIlhjsbNHHzjUHWWyKJSIiIitjsLMi76vHinVx0SMpM9OaT0VERETEYGeTih2AhLQ0ftyIiIjIqlixs1GwS8xMt+ZTERERETHYWZOLiwvc4KnOX8lgxY6IiIisixU7K3N3yQt2SazYERERkZUx2FmZu2tec2xyVoa1n4qIiIicHIOdlXle7WeXksU+dkRERGRdDHY2mqQ4JTvV2k9FRERETo7Bzsoq+lRWpym6OGs/FRERETk5BjsrqxEQrk7TDbHWfioiIiJycgx2Vla7XC11mu1ywdpPRURERE6Owc7KGoTUVacGj3jk6vTWfjoiIiJyYgx2VtY4tE7ejvZIQnxqkrWfjoiIiJwYg52VhfgGwZDrr84fv3zG2k9HRERETozBzgbcdGHq9GQCgx0RERFZD4OdDXgZKqnTyORIWzwdEREROSkGOxvwd62iTv9NibLF0xEREZGTsnuwmzt3LsLDw+Ht7Y0OHTpg9+7dRd5+9uzZaNCgAXx8fFC9enU899xzyMzMhCMLcq+qTmMzYuy9KURERKRhdg12S5cuxYQJEzBjxgzs378fLVq0QO/evREfH1/o7RcvXowpU6ao2x87dgxffvmleowXX3wRjizUu5o6Tcg+D51eZ+/NISIiIo2ya7D74IMP8Nhjj+GRRx5B48aNMW/ePPj6+mLBggWF3n779u3o0qULHnzwQVXlu+OOOzB06NAbVvnsrYJ3JRj07tAZcnA+7by9N4eIiIg0ym7BLjs7G/v27UOvXr3+2xhXV3V5x44dhd6nc+fO6j7GIHfmzBmsXr0a/fr1u+7zZGVlITk5Od9ia+V8vKDPDlXnI5M4gIKIiIg0FuwuXboEnU6HsLC8qUCM5HJcXFyh95FK3WuvvYZbbrkFHh4eqFOnDrp3715kU+ysWbNQrlw50yL98mwt0McD+uwK6jyDHREREWl28ERJbNq0CW+++SY+/fRT1Sfvp59+wqpVqzBz5szr3mfq1KlISkoyLWfPnoWtBXp7QJ/FYEdERETW5Q47CQ0NhZubGy5cuJBvvVyuVClv3reCpk2bhocffhijR49Wl5s1a4a0tDSMGTMGL730kmrKLcjLy0st9hTo4w59dkV1ft+FfUjKSkI5r3J23SYiIiLSHrtV7Dw9PdGmTRusX7/etE6v16vLnTp1KvQ+6enp14Q3CYfCYDDAUQV4e0CXXhsuBm9EJUfhodUPISaZU58QERGRhppiZaqTL774Al9//bWavuTJJ59UFTgZJSuGDx+umlKNBgwYgM8++wxLlixBZGQk1q1bp6p4st4Y8BxRoLc7DLmB8Ls8HpX8KqlwN2z1MGyI2WDvTSMiIiINsVtTrBg8eDAuXryI6dOnqwETLVu2xJo1a0wDKmJiYvJV6F5++WW4uLio03PnzqFChQoq1L3xxhtwZDJ4QqSlVMQv/RZj/IbxOHL5CJ7Z+Az61uqLqe2norx3eXtvJhEREZVxLgZHbsO0ApnuREbHykCKwMBAmzznxZQstHvjT7i4AKff6IccQzY+O/gZFv6zEHqDHsHewXi548u4vebtNtkeIiIi0mZ2KVOjYsuqAO+8wqhE6NTsXHi5eeHZNs9iUb9FqBtUFwmZCZiwaQImbZ6EyxmX7b25REREVEYx2NmAt4cbPN3zdnVyRo5pfdPQplh651I81uwxuLm4YW3UWgxcORA/nvxRVfKIiIiISoLBzoZz2YmUzNx86z3dPDG+9Xgs6r8IjYIbITk7Ga/seAUjfh+Bfy79Y6vNIyIiIg1gsLPhXHYFK3bmmoQ0weL+izGp7ST4uPvg4MWDGLJqCF7a+hIupOWf64+IiIioMAx2Nq7YJReo2Jlzd3XHiCYj8MugXzCg9gC17pfTv2DAygGY9/c8ZORm2GpziYiIqAxisLPxlCfXq9iZk7nu3rz1TSzutxgtKrRQgW7uwbno91M/zDkwB3FphR9Ll4iIiJwbg52NR8YmZ9442Bk1q9AM3/b9Fu92fReV/SrjUsYlzD80H71/7K364H1x6AucSDjh0EfdICIiIieZoNgpm2Izrt8UWxiZkLlPrT7oWaMn1p9djx9O/IDdcbuxP36/Wj4+8DHql6+Pu+rchS5Vu6BGYA14uOY9FxERETkXBjsbD55IKUHFzpyHmwf6hPdRy7nUc9h2bhu2nNuC7ee24+SVk3h377tqkX56tcrVQt1ydVG3fF20r9ReNedKQCQiIiJtY7Cz+eCJ0gU7c1X9q+KBBg+oJSkrCWsi12B15GocTziO9Nx0nLpySi2Iyrt9eGA4+tXuh+oB1VHeqzwq+lZU573dvW96W4iIiMhxMNjZfPBEyZpib6ScVzkMbjhYLTKpsQysiEiMUMFOgt7mfzcjKjkKnx78NN/9XOCi+u1J023NwJqo4l8FgZ6B6vFkvQQ/ucxKHxERUdnBYGcjgaUYPFFSri6uKqDJ0rVaV7UuPSddHdFi+/ntuJJ5BVeyriA2NRYpOSk4n3ZeLTtjdxb6eBLy6gXVU334qgVUQ5hvmHpsuSwTKxMREZFjYbCzcVNsXHKmGsVqq0qYr4cv7q53t1qM5Pkl4EUnR5uW+PR4JGclq/XnU8/jYsZF1cy798JetZiTfnwNyzdE/eD6qrJXK7AWOlftrCZWJiIiIvthsLOR5tXKwcvdFWcupmHHmcvoXCcU9iKhMtg7WC2tKrYq9DYyd15UUhROJeb114tNi1VHwJBm3cSsRBy5fEQtRv4e/uhfuz/uqXcPGoc0tuGrISIiIiMXg5NNgpacnIxy5cohKSkJgYGBNn3u6T8fwTc7onFrvVB8O6oDyiL5uMio3COXjiAyORJnk8+qaVdknZEc81YC3qC6gzhAg4iIyIbZhcHOhs4mpKP7e5ug0xvw89guaFE9CFoggzb2xO3Bj6d+xJ/RfyJHn2MavftihxdN/f2IiIjIusGOR56woerBvrirZRV1/tNNEdAKGbTRoXIHvNP1HWy4fwMmt5usBlpIFW/s+rF4fvPzyNZl23sziYiINI/Bzsae6l4HMm5i7T8X8NP+fzV3OLAg7yA81Pgh/DLoF4xoPAJuLm5YE7UGEzdPNFXyiIiIyDoY7GysbsUADGieV7WbsOxv3P3pduyLToDWyGjcSe0mYf7t8+Hl5oVNZzdhyl9TkKu37Dx+RERE9B8GOzt4577mmHRHffh6uuHg2UTc+9kOjF28X/XB0xppop1922w1Rcof0X/gvb3v2XuTiIiINIuDJ+woPjkTH6w7iaV7z0JaZD3dXPHILeEYe1td07x3WiGDKp7b9Jw6L1W8zlU623uTiIiIygQOnigjKgZ64617m2PVuFvRpW4IsnV6zN98Bt3f3YRvd0YjV6eHVvSq2QtDGgxR56dtm6YmPyYiIiLLYlOsA2hcJRDfjeqABSPbonYFPySkZWPayiPo+9EWbDwRD62Y0HYCwgPD1VEu3tj1hr03h4iISHMY7ByEHA2iR8MwrH22K167qwnK+3rgVHwqHlm4B8MX7MaJuBSUdXLIsTdveVONlP098nf89e9f9t4kIiIiTSl1sIuIiMDatWuRkZGhLmtt2g578XBzxfBO4dj0/G0Y07U2PNxc8NfJi+j70V+YvPwQIuJTUZY1q9AMwxsPV+ff2fMO57cjIiKyZ7C7fPkyevXqhfr166Nfv36IjY1V60eNGoWJEydactucWjkfD7zYrxH+nNAN/ZpVgt4ANcii1webMXLhbvx59AJyymgfvDHNxyDUJxTRydH47th39t4cIiIi5w12zz33HNzd3RETEwNfX1/T+sGDB2PNmjWW3j6nVzPED58Oa4Mfn+yEXo3C1OTGm05cxOhv9qLTrPV49dd/sCcqAXpJfmWEv6c/nmtzdYTs3/NxMf2ivTeJiIjIOac7qVSpkmqCbdGiBQICAvD333+jdu3aOHPmDJo3b47U1FTNDBl2RFGX0vDdzmisPHgOl1L/O0xXhQAvdK1XAR1qBaN9rWDUDPFV/fYc+fiyD69+GIcuHcLAOgPxxi0cTEFERHSz2cUdJZSWlpavUmeUkJAALy+vkj4clVB4qB9evrMxJvdtqPrerToUi3XHLuBiShZ+3P+vWkTFAC8V8FpWD0LDSoGoX8kfFfy9HCbsyfFlp3aYiqGrhuKX07/g/vr3o2XFlvbeLCIiIueq2Em/ujZt2mDmzJmqYnfo0CHUrFkTQ4YMgV6vx/Lly+HIynrFrjDZuXrsjkzAzjOX1akczULmxCvI28MV1cr7IjzEDw0rBaBemL+q9AX5eCLU31Odt3XwkzntVkasRJOQJljcf7EKfERERFS67FLiYHfkyBH07NkTrVu3xoYNGzBw4ED8888/qmK3bds21KlTB45Mi8GuoMwcnQp3EvKOnk/GiQspiLqcpo5uURQvdwl+Pqge7Ivq5X1RPdjn6mne5XK+lj8axqWMSxiwYgBSc1LxWufXcHe9uy3+HERERGWZVYOdkAeeM2eO6l8nfeok5I0dOxaVK1eGo3OGYFeYrFwdYhMz8e+VDJy+mIrjcSk4HZ+KhPRsJKbnICEtS428LUqAt3u+wFe3or+aXLl+WAC8PdxKvW1f//O1OoZssHcwfr37VwR6Os/7QkREZPdgV5Y5a7C7EZk65XxiBs4mZODslXScTUjH2StyOR3/XknPN1CjIHdXF7SoHoROtUPQo1FFtKoeVKIm3RxdDu799V5EJkVicIPBeLnjyxZ6VURERGWfVYPdX38VfbSArl27wpEx2JVOenauqvapwJeQjpiEDJy8kIJ/zifhSnpOvtvWD/PHkHY1MLhddfh5FW98zu7Y3Rj1xyi4wAXf9P2GAymIiIhsEexcXa/t3G5endHpdHBkDHaWJR8fqfLtOHMJWyMuY93ROGTm6E0jc5/v3QD3tq4GV1eXYg+kqBtUF8vuXAYPN8v36SMiIiprSpJdSjwE8cqVK/mW+Ph4NTFxu3bt8Mcff9zMdlMZJKG+RogvBrergU+GtsKuF3th5l1NVD+8+JQsPL/8EO75bDvikjJv+FgT20xEea/yiEiMwMJ/Ftpk+4mIiLTEYn3sNm/ejAkTJmDfvn1wZKzY2W6wxlfbojBnQwRSsnJV9e6L4W1VX7yi/Hr6V7y49UW4u7hjQZ8FaFWxlY22mIiIyAkrdtcTFhaGEydOWOrhqIzzcnfD493qYPUzt6JBWICq3j0wfwfWH7tQ5P3urH0n+oT3Qa4hF5M2TcLljMs222YiIiKnq9jJhMTm5O6xsbF46623kJubi61bt8KRsWJneymZOXhmyUFsOB4PHw83/PBEJzStWu66t0/PSVdHpDiTdAbtK7XH/Nvnw921xAdJISIi0gSrD56QflUF79axY0csWLAADRs2hCNjsLOPXJ0ej369Vx0GLSzQCz+PvQWVynlf9/ZnEs9gyKohyMjNQN9afdWxZD1cOZiCiIicT7I1g110dPQ1Qa9ChQrw9r7+j7QjYbCz477PzMG9n27HqfhUNKkSiB+f7FzkxMYbYjZg4qaJqlm2R/UeeLfbu/B087TpNhMREWm6j50cF9Z8qV69epkJdWRfgd4eWDCyHUL8PPHP+WR8uO5kkbfvUaMHPurxETxdPbHh7AY89sdjqpJHREREN1Gx+/jjj1Fc48ePhyNjxc7+/jx6AaO/2QuZ2k6qdq1qlC/y9jtjd2L8hvGqWVZGyz7U+CE80eIJ+Hn42WybiYiINNMUW6tWrWI9sfS9O3PGsSsqDHaO4dklB7Dy4Hl1vNnfxt1yw2PNnk05i3f2vINNZzepyxV8KmBC2wnoX6t/iQ5fRkREBGdvio2MjCzWUppQN3fuXISHh6vm3A4dOmD37t1F3j4xMRFjx45F5cqV4eXlhfr162P16tUlfl6yrxkDmiDU3wsR8an4ZMOpG96+ekB1fNLjE8ztORc1AmrgYsZFTN0yFSPXjMSJBE6zQ0REZNF57Epj6dKlalLjGTNmYP/+/WjRogV69+6tjmZRmOzsbNx+++2IiorC8uXL1bx5X3zxBapWrWrzbaebU97PE68PaqLOf/7XGRXwiqNrta5YcdcKPNP6Gfi4+2B//H488NsDeHPXm0jKSuLbQkRETq1UR574999/8csvvyAmJkaFLXMffPBBsR9HKnRyKLI5c+aoy3q9Xg3GGDduHKZMmXLN7efNm4d3330Xx48fh4dH6aa+YFOs45CP3qiv96r57TrXCcGi0R1K1KwalxaH9/a+h7VRa9XlIK8gjGs1DvfWuxdurkU37RIREZUVVp3uZP369Rg4cCBq166tAlbTpk1VBU0epnXr1tiwYUOxHkcCoa+vr6q8DRo0yLR+xIgRqrn1559/vuY+/fr1Q3BwsLqfXC/TrDz44IOYPHky3NyK90POYOdYYi6n4/YPNyMrV6+ONTugRZUSP8au2F2YtWsWTiedVpfrl6+Pye0mo33l9lbYYiIiIg1NdzJ16lRMmjQJhw8fVv3ifvzxR5w9exbdunXD/fffX+zHuXTpEnQ6nToUmTm5HBcXV+h9pA+fBEG5n/SrmzZtGt5//328/vrr132erKwstUPMF3IcNUJ88VT3uur866uOIjUrt8SP0aFyBywfuBxT209FoGcgTl45iVF/jMKETRMQnZx/3kUiIiItK3GwO3bsGIYPH67Ou7u7IyMjA/7+/njttdfw9ttvw5qkqbZixYr4/PPP0aZNGwwePBgvvfSSaqK9nlmzZqmUa1ykqZccy+PdaqNmiC8uJGdh9g3mtrseOeTYg40exKq7V2Fwg8FwdXHFuuh1GLhyIF7Y/AIHWBARkVMocbDz8/Mz9auTkamnT+c1fxmrcMUVGhqqmk8vXMh/UHi5XKlSpULvI88no2DNm10bNWqkKnwF+/qZVxildGlcpLpIjkWmOnllYN5AioXbo3AiLqXUjxXkHYSXO76MHwb8gFur3gq9QY/fo37Hfb/eh7Hrx+JA/AELbjkREVEZD3ZyTNitW7ea+rxNnDgRb7zxBh599FF1XXF5enqqqpv02TOvyMnlTp06FXqfLl26ICIiQt3O6OTJkyrwyeMVRqZEkfZo84Ucz20NKqJ3kzDo9AZM+/nINcciLinpZ/dpr09VwOsT3kdV8P769y8M/324miJl27ltN/0cREREjqbEgyekn1tqaiqaN2+OtLQ0Fey2b9+OevXqqRGxcpixkkx3IoMl5s+fj/bt22P27NlYtmyZGpQhfe2kyVemMpHmVCHVtiZNmqj7yMjZU6dOqUApR7uQJtni4OAJx3UuMQM939+EzBw9PnigBe5pXc1ijy197RYeWYifT/+MXH1eP75GwY3wcOOH0Tu8N49BS0REzjkqdvTo0XjooYfQvXt3WIJMdSJTmEhzasuWLdXhy2QaFCHPIZMXf/XVV6bb79ixA8899xwOHjyoQt+oUaM4KlZD5m6MwLtrT6C8rwfWPNsVYYGWPQ6xTJHyzdFvsPzkcnWIMhHsHawCnixebl4WfT4iIiKHDnZ33XUX1q5dq6YaGTJkiAp5MrFwWcGKnWPLztVj0NxtOBqbjFvrheLrR9rDVQ4qa2GJmYlYfmo5lhxfggvpF0xHt5jSfoqaBJmIiMgpgp24cuUKfvjhByxevBhbtmxBw4YNMWzYMDWnnFTYHBmDneOLiE9B/4+3qrntpt/ZGI/eUrxjFZeGNMv+Hvk7Ptz3oTpMmWhRoQUeafIIulfvzomOiYhI+8Gu4FEovv/+eyxYsED1ecvNLfk8ZLbEYFc2fLsjCtN+/geebq748cnOaFatnFWfLy0nDfP+nodFxxYhR5+j1lX1r4oBdQZgQO0BqBFYw6rPT0REZJcJis3l5ORg79692LVrlzr6RMHJholK66GONdGzYUVk6/QYuXA3Ii+lWXVn+nn4YWLbifjjvj/wWLPH1ETH51LPqbDXf0V/jPljDEfSEhGRwytVxW7jxo2qGVaOOiFTj9xzzz2qKbZHjx4lOtanPbBiV3akZOZgyOc78c/5ZFQr76Mqd5YeTHE9MrBiY8xG/HLmF+w4v0PNhyfqla+HsS3Hokd1x/+sExGRNli1KVZGoiYkJKBPnz4qzA0YMEDNFVdWMNiVLRdTsnD/vO2IupyO2qF++Hx4W9St6G/TbZDK3XdHv8NPp35Cem66Wtc0pCnGtR6HTpU7MeAREVHZDXZffPGFOiZsUFAQyiIGu7LnbEI6Hpi/A7FJmfDzdMP7D7RAn6aVbb4dSVlJ+Pqfr/Hdse9MU6W0DWuL8a3Ho1XFVjbfHiIicg7Jthw8UdYw2JXdyt3Ti/djV2SCunxPq6p4vk8DVC7nY/NtuZRxCV8e/hJLTyw1DbSQKVLGtRqHhsENbb49RESkbckMdpbZOeRYcnR6vP37cfxva6S67O3hijFd6+CJbrXh6+lu8+2JTY3F/EPzsTJiJXQGnVonR7GQPni1yllvihYiInIuyQx2ltk55JgO/ZuImb8dxZ6oK+pyWKAXnu/dUFXxrDGZcXEOVzb34Fw1H56Q49IOrDMQT7Z4ElX8q9h8e4iISFsY7Cy0c8hxSQ+CNUfi8Obvx3A2Ia+/W9OqgXi5f2N0rB1il206kXACcw7Owaazm9Rld1d33F//foxpPgahPqF22SYiIir7GOwstHPI8WXl6vD19ih8sj4CKVl5k2P3bhKGqX0bITzUzy7b9PfFv/HJ/k+wK26XulzOqxxe7/K6OpIFERFRSTHYWWjnUNlxOTULH/55Eot3xUBvADzcXDC8UzjG96iHcr4edtmmXbG78N7e93A84bi6/FCjh/Bsm2fh5VZ2pgciIiL7Y7Cz0M6hsufkhRS8ufoYNp3IO+5rkK8Hnu1ZD8M61oSH200daKVUsnXZ6ji0MkWKqBlYE9M7Tkf7yu1tvi1ERFQ2MdhZaOdQ2bX55EW8seooTl5IVZdlcuNxPetiQPMqcLdDwNt8djNe3fEqLmbkBc5BdQdhYpuJCPIum/NBEhGR7TDYWWjnUNmWq9NjyZ6z+HDdSVxOy1brwkN88dRtdXF3q6o2r+ClZKfgo/0fYdmJZTDAgPJe5fF8u+dxZ+07efQKIiK6Lga7IjDYOecxZ7/ZEY3/bTmDK+l5EwrLsWef6l4X97apCi93N5tuz8H4g6p6F5EYoS53q9YNr3R+hSNniYioUAx2RWCwc15pWblYtCsan/91BpdS8yp4lct544ludTC4XXV4e9gu4OXocvDVP1/hs78/U0evCPYOxiudXsFtNW6z2TYQEVHZwGBnoZ1D2pSRrcP3u2Mw/6/TuJCcpdaF+ntiWIeaGNaxBioGeNtsW05eOYmpW6aqU3FPvXvwQrsX4Odhn6laiIjI8TDYWWjnkLZl5ujww96zmLf5DM4l5k1y7OnmigEtquCRLuFoWrWczUbOzjkwR1XwpO9dNf9qqmm2Q+UONnl+IiJybAx2Fto55DzHoF37TxwWbI3E/phE0/r2tYLxaJdauL1xGNxscKiyPXF78NLWlxCbFqsu96rRC5PaTUJV/6pWf24iInJcDHYW2jnkfA7EXMHCbVFYfTgWuTLTMYDqwT4Y0SkcD7SrjkBvD6uPnP14/8dYdnIZ9AY9vN28MfOWmegT3seqz0tERI6Lwc5CO4ecV2xSBr7dEY3Fu2OQeHUkrZ+nG+5vWx0jO4db/XBl0udu1q5Z2Hthr7r8ePPH8VTLp+DqYvs5+IiIyL4Y7Cy0c4hkoMXKg+dUM+2p+LzJjl1cgJ4Nw/BEt9poGx5stZ2k0+vUUSu+Pvq1utyzRk+8ecub8PXw5RtDROREkkuQXVwMBkNee5OTYLCj0pD/JltOXcKCbZGmw5WJznVCML5nPXSsHWK1HftzxM9q3juZFqV++fr4uMfH7HdHROREkhnsLLNziAoTEZ+qJjv+cf+/yNEZTAMtnulZTwU9FynpWWFS42c3PovLmZfVEStm3zYbrcNa8w0iInICyQx2ltk5REWRKVLmbTqNpXvOIlunV+ta1whSFbxu9StYPODFpcVh/IbxOJZwDO6u7pjRaYY65iwREWlbMoOdZXYOUXHEJWVi3ubTatLjrNy8gNeiehAm926AznVDLboTM3Iz1JQo66LXqcuPNXsM41qN47FmiYg0LJnBzjI7h6gk4pMz1eHKvtsVjcycvIAnlbspfRuiUWXLfdZkGpRPD36K+Yfmq8syWvbJFk/yzSIi0igGOwvtHKLSuJiShbkbI/Ddzmg1F560yN7Tqhom3FEfVYN8LLZTvzv6Hd7e87Y6P6ntJIxoMoJvGBGRBjHYWWjnEN2MqEtpePePE1h1KO9IEp7urhjbvS6e6F4bXu5uFtm5nx/6HJ8c+ESdf7nDyxjccLBFHpeIiBwHg52Fdg6RJRw8m4hZq49hV2SCulyngh/evLsZOlhoipSP9n+E/x3+nzr/epfXcVfduyzyuEREVPayC6exJ7KyltWDsGRMR3w8tBVC/b1w+mIaBn++Ey8s/xtX0rJv+vHHtxqPYY2GqfPTt0/Hmqg1FthqIiIqixjsiGxApj4Z2KIK1k/ohgc71FDrlu39Fz0/2IyfD55TEyDfzGNPbjcZ99a7Vw2smPzXZKw4tcKCW09ERGUFjzxBZAf7ohMw9afDOHkh7zBlvRqF4c27m6JioPdNHYJMjlCxIiIv1D3T+hmMajqKU6EQEZVx7GNnoZ1DZE3ZuXo1/90nG06pI1gEertj2p2NcV+baqUOY1L5m71/NhYcWaAuD6g9AC91fAl+Hn4W3noiIrIVBjsL7RwiWzgel4wXlh/CoX+TTHPfzbqnGarcxNQo3x79Fu/tfU81zVbzr4a3u76N5hWaW3CriYjIVhjsLLRziGwlV6fHF1si8eGfJ1Ulz9/LHS/2a4Sh7auXunq3/8J+TNkyBbFpsXBzcVMTGUvTrJurZaZaISIi22Cws9DOIbK1iPhUNVp2f0yiutylbgjeuqc5qgf7lurxkrOT8fqO1/F71O/qcpuwNnjjljdQ1b+qRbebiIish8HOQjuHyB50egMWbovEe3+cUIcm8/V0w+Q+DfFwx5pwdXUpVb+7X8/8ijd2voH03HR4u3ljTPMx6kgVnm6eVnkNRERkOQx2Fto5RPY+csULPx7C7qsTG0v17qMheXPhlUZMcgxe2fEK9sTtUZfDA8PxYocX0alKJ4tuNxERWRaDnYV2DpG96fUGLNoVjTdXH0dGjg4VA7ww58HWaF8ruFSPJ9W7VZGr8N6e93A587Ja1ye8Dya2nYhKfpUsvPVERGQJDHYW2jlEjuLUhRQ8uWi/6oPn5uqC6Xc2xvBONUs9sCIlOwVzD87F98e/VyNnPV09MaThEIxqNgrB3qULjUREZB0MdhbaOUSOJC0rFy+uOIyfD55Xl2XE7KsDm8LTvfQHkDl2+Rje3vM29l3Ypy77uvvi4cYPq/53AZ4BFtt2IiIqPQY7C+0cIkcjTamf/3UGb605DjkKWcfawfhieFsEeHvc1GNuP78dHx/4GEcvH1XrAj0DVfVuaMOh8HEv/Xx6RER08xjsLLRziBzVxuPxGPf9AaRm5aJp1UB89Uj7Ug+qMA9462PW45MDn+BM0hm1LtQnFI81ewyD6g6Cr0fpplwhIiLbZZfSt+FY0Ny5cxEeHg5vb2906NABu3fvLtb9lixZovoYDRo0yOrbSORIbmtYEUvGdESInyeOnEvG/fN24N8r6Tf1mPJ/qVfNXvhp4E+mue4uZVzCrN2z0H1Zd7y09SXsit2l+uQREZFjcjHIn+l2tHTpUgwfPhzz5s1ToW727Nn44YcfcOLECVSsWPG694uKisItt9yC2rVrIzg4GCtXrizW87FiR1py5mIqHv5yN84lZqBSoDe+HdUe9cIs0zcuR5eDH0/9iEXHFiEqOcq0vrJfZdxZ+07cXvN2NAxuWOoBHEREpMGmWAlz7dq1w5w5c9RlvV6P6tWrY9y4cZgyZUqh99HpdOjatSseffRRbNmyBYmJiQx25LRikzIw/MvdOBWfiiBfDywc2Q6tapS32OPLV8TfF//GL6d/wZrINUjJSTFdV9G3Im6pegvahrVFu0rtOGUKEZEzB7vs7Gz4+vpi+fLl+ZpTR4wYocLazz//XOj9ZsyYgUOHDmHFihUYOXJkkcEuKytLLeY7R4Ij+9iRllxJy8YjX+3BwbOJ6kgVX45oh051Qiz+PJm5mdh0dhN+j/wdO2J3ICM3I9/1Eu6GNx6OrtW6wtXFIXp6EBE5VbBzhx1dunRJVd/CwsLyrZfLx48fL/Q+W7duxZdffomDBw8W6zlmzZqFV1991SLbS+Soyvt5YtHoDnj8233YGnEJIxfuxufD26Jb/QoWfR5vd2/0qdVHLVm6LHUUC+l3tzduL44mHFWXZQnzDUPLii3RLLQZWlRooZps5b5ERGRddg12JZWSkoKHH34YX3zxBUJDQ4t1n6lTp2LChAnXVOyItMbPyx3/G9EWTy3ajw3H4/HY13vx/gMtMKBFFas8n5ebl2qGlUXEpcVh8fHFWH5iOS6kX8DaqLVqEe4u7mgc0hjdqndDj+o9UCeoDvvmERFZQZlqipUqXatWreDm5mZaJ33yhKurqxpwUadOnSKfk4MnSOuyc/V4dukBrD4cpy6Pva0OJt7eAK6uthnkkJ6TjkOXDuHwxcOmU+Phy4zk8GXtwtqpptv2ldurEbhERFTG+9gZB0+0b98en3zyiSmo1ahRA08//fQ1gycyMzMRERGRb93LL7+sKnkfffQR6tevD09PzyKfj8GOnIFOb8A7a45j/l9589H1aFgR797XHCE3OdddachXzPm089h5fic2nN2AHed3IEefk+82EuxaV2yNJqFNVPNtg+AGqiJIREQoW8FOpjuRCt38+fNVwJPpTpYtW6b62ElfO5kKpWrVqqqvXGFuNHiiIAY7ciYrDvyLyT8eVlW8UH9PvH1vc/RslL9Pq61JRe/gxYOqX97uuN3459I/yDXk5ruNu6s76pevj5YVWqJzlc6qsscJkonIWSWXlcETYvDgwbh48SKmT5+OuLg4tGzZEmvWrDENqIiJiVHNrERUcne3qoYGYYF4bulBnLiQglFf78W9ravh5f6N1IALe5CAJmFNFmPQOxB/QDXbHrl0RC0JmQnq8GaySL896aPXKKSRGoghffWqBVRDNf9q6sgYnEePiMiBKna2xoodOaPMHB3e/+ME/rc1Uh1jVo5YMX1AYwxsUcXhgpGx6Vb65klFT45jey71XKG3rRlYEz1r9ESHSh3g4+EDT1dP1CpXi9U9ItKUMtUUa2sMduTM9kVfwdSfDuHkhVR1uX2tYMwY0BhNqpSDo5KvKAl2MknywfiD6ji2cllG4eoMumtuL824bcLaoGPljmralRCfENQNqqsmUyYiKosY7Cy0c4i0SPrbzd98GnM3RSAzRw8p2Enz7Pge9VAjxBdlRVpOGrac24L10etx6sopNSBD1hUcgWtUI6CGCnzSd692udqoHVRbBT9Hq1gSERXEYFcEBjuiPHJ82Vmrj+G3Q7HqsrurC+5vWw1jb6uLauXLTsArWN2LTo7G1nNbceTyEVzKuIT49HhEJUXBgGsbJ/w8/BAeGI5g72AEegWq4+A2DWmKpqFNUcG3Ao+eQUQOgcHOQjuHyBkciLmCD9adxJZTl9RlDzcXDGlXA493q11mA15BydnJOHDhgGrOjUyKxOmk04hJjim0KdfIBS4I8AxQc+7J6NxWYa3QKLiRqvx5uHnYdPuJyLkls4+dZXYOkTPZE5WAD9edxPbTeU2Z0kLZvX4FPNihJm5rUAHubtoanZ6jy0FMSoyq8CVlJaklKjlKjc49nXgaekPe5OcFubm4oYp/FVXlK+9dPu/Uq/x/573LqwEcnHSZiCyFwc5CO4fIGe04fRlzNp7Ctoj/+qpVCvTGA+2qY0i76qgS5AOtk9CXlJ2ExMxEFfz2x+9XAzciEiOQnpterMeQYCd9+qTiZwx+cipVwCtZV9Rh13zdfdGjRg/4uGt/nxJR6THYWWjnEDmzMxdTsWTPWSzf9y8S0rLVOjkqWfcGFTG0fQ10q18Bnu7aquIVpw+fBLJ/U/5V4exK5tUl64qae0/Oy+CNyMTIayZdvp5Az0DcW+9edfxc9RxmfQEblG+AhsENOcCDyMklsynWMjuHiICsXB3W/nMBi3dFY+eZBNMuCfB2V4cq692kkgp5fl52n+/cYciky1LlMx4nNzEr0RQAk7OSVfVOpl+RJt/rzdFnJBMx31rtVnWINWkeliAoTcFSEZTTCj4V4Ob63/GziUh7GOwstHOIqPAq3k/7z+FSapZpvZe7K26tF6pCXq9GYXY7qkVZo9Pr8Ne/f2FV5Co1VUvB5mAZ7JGpyyzyMWTevuoB1dU0LlL1MwZAaeaV9TUCa6gA6OHKAR9EZRWDnYV2DhEVTqc3qNG0a/+JU9W8mIT/+p25ubqgTc3yuLVuKLrUC0XzquU0N/DClpU/matPDrNmHKkr1b/zqedNkzQXp8lXBnzIVC4yuEMCZFpuGqr4VUHLii3VodokBMph27L12UjNSVXPK/P7ucIVQd5BqB9UH1UDqnL6FyI7YbCz0M4houL1Ozsel2IKecdik/NdH+Dljg61Q9ClbghuqRuKuhX92WfMghU/madPpnA5ceWEGtUr6ySUpWSn4GzKWbVk5Gbc9HPJAA85gke98vXU/H/nUs7hYsZF1QdQDuvWvlJ7TgNDZCUMdhbaOURUcjGX07H51EVsj7ikpk5JysjJd33FAC90kWpe3VB0rhPiFKNs7R28ZaJmmdpFqn3+Hv7wdvfGmcQzqqlXDtEmzb5SrZNj7fp7+qsQJ9VBadKVwSLSF1CuL4qri6vq/1fOq5xq9pXLUimUx5PnlD6Fxmlg5LFlDkE53Js0IXNUMFHRGOwstHOI6OabbI+eT8bWiEvYFnFJzZWXlZt/friqQT5oXbM82tQIQtvwYDSsFMCmWweTq89VEzqfTDypDt+WmZuJagHV1PQtu+N2Y+PZjSo8loYEQBkgIqOBpbIofQSlT6A0FUvwC/IKUhVCY1CU4Cgh0dfDV01HIwNS5D7SzGxcPN3Yx5O0hcHOQjuHiCwrM0eH/dFXsO30JWyNuIzD/yZCX+BIXz4ebmhZPUj105OlVY0gBPnyh9qRSWXvcsblvImes5PUcXtlnQRC6dMnzcLSJ1AO7RaXHqcqdhLUpK/g9Y7tezNkrsAQ7xAV8iQYSvCTQSYSCqVqKANKpDop2yiB0ngqYVIqinJ5z4U92B27W/VNvCP8DjWSmcheGOwstHOIyLrSsnLx99lE7Iu+gn0xV1ToS868djBAvYr+KuRJZa9V9SDUCvVjVU8jLqZfVH0DpflWmmRlAmiZJzA2LVZNESNhUcKhBC9pvpV10jwsAzyMkz5LM3FCRoKaS7C48wdej4RAqQyaT0QtA0tah7VWTdjG4BjmG6Yqh9L8LIuxyVkqiVm5WWoQirwmqWxKoCS6GQx2Fto5RGRber0BERdT84JedF7QO3Mp/zQgwtPNFXUq+qtm2waVAtRpw0qBCAv04sAMJyaVNqkOShVQgp6aQzAzUVUQZZHBHlI1/Df1X3VbY+VQFrksVcUsXd40PqE+oehcpbNqej6WcOymtkuCnQRQaVKW8Censkj4k22Upm2pDEq1UJqRpUlaqp0SDCVoyshkY5CUACmjmGWRx5AwzHkMtS+ZExRbZucQkf1dTs3C/pirVb3oBNVnLy1bV+hty/l4mIKe8bR+WAACvDmHG92YjCiWcCfBSkb/SuATxoEmRjIIRaaakaCYnJ2M1OxUFdIkVMp9vd28VeiSOQhL2/ewJCTcyWIMe1I1VItZAJTLxkErUv2U2/u55wVM032u3tb8shpIIweOJrtisLPQziEix6zqnUvMUNOqnIhLwfELKeo08lKaGqxRGBmgoap6lSXwBarz0pzrwfn1yMqkyVgqhHLEETWHYE6aCoFyKgFK+gJKlU6aniVUSuVQqnRSrZMqo1QQjc3PMrWN3E+aieVxJaRZm4RbCXiyjVJFlEWeV0Kw8PHIC5TGICjN0tKHUfoyymuQpnTZXqmASlVSrhcSFuX2xlHYah1cEOgVaJpMW55DmteFNIPL7aSvpDNKZsXOMjuHiMrWwIzTF1NVyFOB7+ppXHLhR26Q5tzaFfyuVvfywp7MsSfTr8gky0SOPo2N9C1UQS8nXZ1KtVCdz/1vnTEEyqncx9hsK7c13leuM38c433Mj1tsKxLupO+khFvpf1mwz6QEOwl4EhJlDkUJkNInUgKnhFBvd28Vjg9fOowD8QdUOGxXqR06Vu6omrolSAZ4BOT1ifT0L/SILDL9jzSRy76o4FtBhVFZJ1MDSfiW5w4vF27TaXoY7Cy0c4io7EtMzzaFvLzTZJy8kIrUrMI72Xu4uaBaeV9UD/ZFTVlCrp4P8UWNYF/4ejpnxYCci4Qj6ftnDH3ZumwVqtTi4q4CogRFFRCvBklZpMIWnRytJs2WYCijkiUASbO1jII2P3SesXopzyMKC5LG5nDZHmtxvdrPUv1zcb3mMH7SL1LWSXgsGECNzeBdq3XFc22ec4jswm8oItI0mSqlY+0QtRjJD9K/VzLyqnsX8gLf8dhkRF9OR7ZOr5p1ZSlMqL+XCnkS+oyBzxj+Kvhz8AZpg2qCvdpXT5pRbUHCmzQ7S79ECVKVfCup55ZtkWZpCZGqKpmbruZVPJ5wXIVIuV4Cp1TnsnRZqqlYJr5uXbG1avLdcX4H9sfvV48t/SFTcvL6Qpo/b8HgKOFVApvcVsKnkEqfjHKWZnPpZ2lsJhaNghvBUbgY5BvOibBiR0TXI330pOk2+nIaziakq6AXnZBuOl/wKBoFyRx8UtWrcTX4yalcrhnip/r5ebrzmLlEjiBHn4O07DTV1CsxSA0qMRigh14NKpG+fhIYpQopcy/KgBhpgjUOJJF5G40BVCqOUplsENzAatvLplgL7RwiInNJ6TmIkZCXkKaCnjHwybrzSRm40Z/JUu2rGuSNyuV8UDnIG1WunsrlKkHeqBjgzf59RHQNBrsiMNgRkTVk5epw7kqGqvDJ8XJVAFSnaep8Zs6N+wjJoI1KgRL0vFE5yAdVypmfzwt/wX6enH6CyMkks48dEZFtebm7oXYFf7UUJE08l9OyEZuYqSp7sYkZiE2S85k4L+cTM3AhJUs1BctULrIg+sp1R/NWDPRCWKC3CoFyXk7DTIsXKpXz5iAPIifFwRNERFYm/XKkGVaWZtUKP7yUhLr4FAl6mYhV4S8vBKrgpwJgJi6lZqnBHTLwQ5aiBHi5o0KAF0IDvNSpDOxQp1eXUD8vBPt7IsTPE94eeVNgEFHZx2BHROQApBlW9b0rJ3Njlb9uc298cpYKgHFJWbiQnGm25F2WwR/p2TqkZOWqpbBDshXk6+mmmngl5MlpsIQ+Pw91alp3NQTKeX8vdzYHEzkoBjsiojLU3CvTqshSlJTMHMSnZOGi+ZKa//LltCwkpGUjR2dQQTA9+8ZVQPPm4LwA6IkQf2MYNAY/LwT5eqjDuwV6553K4u8tc59x4mcia2OwIyLSGDk2rix1CunvV7Dvn0zULAFP+gAmpGb/dz5Nwl/eZbXu6nUZOTrVHCyVwesd1aMwMkuEVPoKBr5AH3ez8/lPg2Tx9USgtzvcefg3omJhsCMicuK+f8YQKHPtFUdGts5U7SssDMp5me9PluSMXHUqYVCmgknJzFULULzKoLkAb3dVCSzv62kKf36ebmqQiDQl+3nlnUpolOskDKrTq+f9PN3hyoohOQEGOyIiKjYfTzdU8/RVh10rruxcPZIzc8wC33+nyZl54U/mCDS/jXGd9BMUxlB4NqHkodBUMfR0h7cKg25qMml5LVJFDLxaHVRVQt+8iqIERT8vNxUI887/d1nub5yolsjRMNgREZFVyRE3jKOCSypHp1cBMFGW9GwkpstpjqkSmJ6di7Ss/04lHEpYTFGhMa9qKE3HqmJ4dUDJzZJM53c14EnfQQmHclnCn1QWVQD0cldBUq5X573+O80772Za58FmZrIgBjsiInJYEnpC/L3UUlqZOToVDqU/oYRBaU7OC4U6pBorhvmqiHm3laCYpgLjf+clIMoi18sig1Rulpe7qynkqXBorA5eDYHG5mapMMpp3nl3+Hq4wdcrr/lZKo0BXh7w8nBVg1vY7Oy8GOyIiEjTZJ4+WSre5OPIYBMJhKbQdzXc/Xcq10kozLsu7WqF0Hg+9er1ebfLVU3UIitXj6zcvH6KliLhTgKjVEvl1MvDzXTZ2z0vJEp4lNCo+iqqquPVy1fXS4CUkczS7Ozh5mIKn3nBk03SjorBjoiIqBgk4OQFHncg4OZ3mQQ7Uyi8WhmUfoTmoVEWqSxmZOedpl+tOErTc0aOHulZuarCeCU9xxQU1WPr9GrBzRcUiyTBTxYJjXnVRHdT/0VjddEYEo2VRr8C6/NCZt79hFRE5TGNg2W8PVzZp7EEGOyIiIjsQKpnnu6eKO/naZHHk/6IEu7yKoA6ZOX8d958fUa2XgVDCYoSKNOzCpzK+quBUm8wqKAlj21egdQb/jtiiizy+Hkjnq2TJN1dpWroCne3vFOpILq7XluR9L7mVK6Xiq3cJ28xPpZ6jKvr5LzcR8Llf6d5jyOLPI/cTz2/q2M3dTPYERERaYAxuPiVvjtisZukM6VamJ2rQl2OXi7n77torDCmmVcbr1YaJUAaQ2WG+fpsnXp8qdbJxNlJGXkTaItcvQG5eh2QA4fg4gIV8CToSeDr37wyZt3THI6AwY6IiIhK1CQtzaeyWJNxAm2pNObqDKpqKEvu1QqhnMplqUxKsJTbZRZxqu5rfBy5r3oMabLOO5+pqpn/3V6FVXWqL2TbjM3deZcLu429MNgRERGR406gbeftMBgkDOY1Oefo88JhrvFUQqFer6a7cRSOsyVEREREDhgwPd3z+tT5wLpVSktwtfcGEBEREZFlMNgRERERaQSDHREREZFGMNgRERERaYRDBLu5c+ciPDwc3t7e6NChA3bv3n3d237xxRe49dZbUb58ebX06tWryNsTEREROQu7B7ulS5diwoQJmDFjBvbv348WLVqgd+/eiI+PL/T2mzZtwtChQ7Fx40bs2LED1atXxx133IFz587ZfNuJiIiIHImLQSZosSOp0LVr1w5z5sxRl/V6vQpr48aNw5QpU254f51Opyp3cv/hw4ff8PbJyckoV64ckpKSEBgYaJHXQERERGQtJckudq3YZWdnY9++fao51bRBrq7qslTjiiM9PR05OTkIDg624pYSEREROT67TlB86dIlVXELCwvLt14uHz9+vFiPMXnyZFSpUiVfODSXlZWlFvPUS0RERKRFdu9jdzPeeustLFmyBCtWrFADLwoza9YsVb40LtLMS0RERKRFdg12oaGhcHNzw4ULF/Ktl8uVKlUq8r7vvfeeCnZ//PEHmjdvft3bTZ06VbVJG5ezZ89abPuJiIiIHIldg52npyfatGmD9evXm9bJ4Am53KlTp+ve75133sHMmTOxZs0atG3btsjn8PLyUh0NzRciIiIiLbJrHzshU52MGDFCBbT27dtj9uzZSEtLwyOPPKKul5GuVatWVU2q4u2338b06dOxePFiNfddXFycWu/v768WIiIiImdl92A3ePBgXLx4UYU1CWktW7ZUlTjjgIqYmBg1Utbos88+U6Np77vvvnyPI/PgvfLKKzbffiIiIiJHYfd57GyN89gRERFRWVJm5rEjIiIiIsthsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1gsCMiIiLSCAY7IiIiIo1wiGA3d+5chIeHw9vbGx06dMDu3buLvP0PP/yAhg0bqts3a9YMq1evttm2EhERETkquwe7pUuXYsKECZgxYwb279+PFi1aoHfv3oiPjy/09tu3b8fQoUMxatQoHDhwAIMGDVLLkSNHbL7tRERERI7ExWAwGOy5AVKha9euHebMmaMu6/V6VK9eHePGjcOUKVOuuf3gwYORlpaG3377zbSuY8eOaNmyJebNm3fD50tOTka5cuWQlJSEwMBAWINBr4chOcEqj01ERESOxyUwGC6u1qmXlSS7uMOOsrOzsW/fPkydOtW0ztXVFb169cKOHTsKvY+slwqfOanwrVy5stDbZ2VlqcV851ibhLoTHW+1+vMQERGRY2iwcwtcgkKduyn20qVL0Ol0CAsLy7deLsfFxRV6H1lfktvPmjVLpVzjItVAIiIiIi2ya8XOFqQaaF7hk4qdtcOdlGMluRMREZFzcAkMBpw92IWGhsLNzQ0XLlzIt14uV6pUqdD7yPqS3N7Ly0sttiRt7I5QjiUiIiLnYtemWE9PT7Rp0wbr1683rZPBE3K5U6dOhd5H1pvfXqxbt+66tyciIiJyFnZvipVm0hEjRqBt27Zo3749Zs+erUa9PvLII+r64cOHo2rVqqqvnHjmmWfQrVs3vP/+++jfvz+WLFmCvXv34vPPP7fzKyEiIiJy8mAn05dcvHgR06dPVwMgZNqSNWvWmAZIxMTEqJGyRp07d8bixYvx8ssv48UXX0S9evXUiNimTZva8VUQERER2Z/d57GzNVvMY0dERERkj+xi9yNPEBEREZFlMNgRERERaQSDHREREZFGMNgRERERaQSDHREREZFGMNgRERERaQSDHREREZFGMNgRERERaQSDHREREZFGMNgRERERaYTdjxVra8YjqMnhOYiIiIgcnTGzFOcosE4X7FJSUtRp9erV7b0pRERERCXKMHLM2KK4GIoT/zREr9fj/PnzCAgIgIuLi1XTtYTHs2fP3vCAvVrjzK9d8PXz/efnn///nfH7j999yVb7vy9RTUJdlSpV4OpadC86p6vYyQ6pVq2azZ5P3lxn+89t5MyvXfD18/3n55///50Rv/sCrfJ//0aVOiMOniAiIiLSCAY7IiIiIo1gsLMSLy8vzJgxQ506G2d+7YKvn+8/P//8/++M33/87vNyiP/7Tjd4goiIiEirWLEjIiIi0ggGOyIiIiKNYLAjIiIi0ggGOyuYO3cuwsPD4e3tjQ4dOmD37t3QolmzZqFdu3ZqsueKFSti0KBBOHHiRL7bdO/eXU0Ebb488cQT0IJXXnnlmtfWsGFD0/WZmZkYO3YsQkJC4O/vj3vvvRcXLlyAFsjnu+Brl0Verxbf97/++gsDBgxQk4PKa1m5cmW+66Wr8vTp01G5cmX4+PigV69eOHXqVL7bJCQkYNiwYWp+q6CgIIwaNQqpqako668/JycHkydPRrNmzeDn56duM3z4cDUR/I0+M2+99Ra08P6PHDnymtfWp08fp3j/RWHfBbK8++67Zf79n1WM37nifNfHxMSgf//+8PX1VY/z/PPPIzc31yrbzGBnYUuXLsWECRPUyJj9+/ejRYsW6N27N+Lj46E1mzdvVh/mnTt3Yt26deoL/o477kBaWlq+2z322GOIjY01Le+88w60okmTJvle29atW03XPffcc/j111/xww8/qH0lP3T33HMPtGDPnj35Xre8/+L+++/X5Psun2n5vyx/tBVGXtvHH3+MefPmYdeuXSrgyP97+cI3kh/1f/75R+2r3377Tf1YjhkzBmX99aenp6vvumnTpqnTn376Sf3wDRw48Jrbvvbaa/k+E+PGjYMW3n8hQc78tX3//ff5rtfq+y/MX7csCxYsUMFNAk5Zf/83F+N37kbf9TqdToW67OxsbN++HV9//TW++uor9cegVcioWLKc9u3bG8aOHWu6rNPpDFWqVDHMmjVL87s5Pj5eRlgbNm/ebFrXrVs3wzPPPGPQohkzZhhatGhR6HWJiYkGDw8Pww8//GBad+zYMbV/duzYYdAaeY/r1Klj0Ov1mn/f5T1csWKF6bK85kqVKhnefffdfO+/l5eX4fvvv1eXjx49qu63Z88e021+//13g4uLi+HcuXOGsvz6C7N79251u+joaNO6mjVrGj788ENDWVfY6x8xYoThrrvuuu59nO39l33Ro0ePfOu08v7HF/idK853/erVqw2urq6GuLg4020+++wzQ2BgoCErK8vi28iKnQVJGt+3b59qhjE/hJlc3rFjB7QuKSlJnQYHB+dbv2jRIoSGhqJp06aYOnWq+gtfK6S5TZonateurf4il3K7kM+B/GVn/lmQZtoaNWpo7rMgn/vvvvsOjz76aL7jL2v5fTcXGRmJuLi4fO+1HPpHumEY32s5lea3tm3bmm4jt5fvB6nwafG7QD4L8prNSdObNFe1atVKNdNZqynKHjZt2qSa2Bo0aIAnn3wSly9fNl3nTO+/NEGuWrVKNTUXpIX3P6nA71xxvuvlVLoqhIWFmW4jFX05tq5UcS3N6Y4Va02XLl1SJVfzN0/I5ePHj0PL9Ho9nn32WXTp0kX9kBs9+OCDqFmzpgo/hw4dUn1xpJlGmmvKOvnhlnK6fJFLs8Krr76KW2+9FUeOHFE/9J6entf8sMlnQa7TEulvk5iYqPoZOcP7XpDx/Szs/73xOjmVH31z7u7u6sdBa58HaX6W93vo0KH5jpc5fvx4tG7dWr1maY6SsC//bz744AOUddIMK01vtWrVwunTp/Hiiy+ib9++6gfdzc3Nqd5/aWaU/mgFu51o4f3XF/I7V5zvejkt7PvBeJ2lMdiRRUgfBAk05n3MhHkfEvmLRTqX9+zZU3351alTp0zvffniNmrevLkKehJmli1bpjrQO4svv/xS7QsJcc7wvtP1SeXigQceUINJPvvss3zXSd9j8/8v8mP4+OOPq87p9p6p/2YNGTIk3+ddXp98zqWKJ597ZyL966T1QgYPau39H3ud3zlHw6ZYC5JmJ/nrrOBoGLlcqVIlaNXTTz+tOgNv3LgR1apVK/K2En5EREQEtEb+Yqtfv756bfJ+SxOlVLK0/FmIjo7Gn3/+idGjRzvt+258P4v6fy+nBQdQSTOUjJTUyufBGOrkMyGdzM2rddf7TMg+iIqKgtZI1wz5PTB+3p3h/RdbtmxRlfkbfR+Uxff/6ev8zhXnu15OC/t+MF5naQx2FiR/gbRp0wbr16/PV7qVy506dYLWyF/l8mFfsWIFNmzYoJohbuTgwYPqVCo4WiNTF0hFSl6bfA48PDzyfRbkC0/64Gnps7Bw4ULVxCQjvpz1fZfPvXw5m7/X0ndG+k4Z32s5lS9+6Y9jJP9n5PvBGHq1EOqkz6kEfelHdSPymZA+ZgWbKLXg33//VX3sjJ93rb//5tV7+e6TEbRaef8NN/idK853vZwePnw4X7g3/vHTuHFjq2w0WdCSJUvUaLivvvpKjYQaM2aMISgoKN9oGK148sknDeXKlTNs2rTJEBsba1rS09PV9REREYbXXnvNsHfvXkNkZKTh559/NtSuXdvQtWtXgxZMnDhRvXZ5bdu2bTP06tXLEBoaqkZNiSeeeMJQo0YNw4YNG9Q+6NSpk1q0QkZ8y+ubPHlyvvVafN9TUlIMBw4cUIt8bX7wwQfqvHHU51tvvaX+n8trPXTokBoVWKtWLUNGRobpMfr06WNo1aqVYdeuXYatW7ca6tWrZxg6dKihrL/+7Oxsw8CBAw3VqlUzHDx4MN93gXHE3/bt29WISLn+9OnThu+++85QoUIFw/Dhww1l/fXLdZMmTVIjIOXz/ueffxpat26t3t/MzEzNv/9GSUlJBl9fXzXas6Cy/P4/eYPfueJ81+fm5hqaNm1quOOOO9Q+WLNmjXr9U6dOtco2M9hZwSeffKLeZE9PTzX9yc6dOw1aJP/BC1sWLlyoro+JiVE/5sHBwSrs1q1b1/D888+rLwAtGDx4sKFy5crqfa5ataq6LKHGSH7Un3rqKUP58uXVF97dd9+tvhC0Yu3ater9PnHiRL71WnzfN27cWOhnXaa5ME55Mm3aNENYWJh6zT179rxmv1y+fFn9kPv7+6tpDh555BH1g1nWX7+Emet9F8j9xL59+wwdOnRQP5De3t6GRo0aGd588818waesvn75gZcfbPmhlmkvZFqPxx577Jo/5rX6/hvNnz/f4OPjo6b/KKgsv/+4we9ccb/ro6KiDH379lX7SAoAUhjIycmxyja7XN1wIiIiIirj2MeOiIiISCMY7IiIiIg0gsGOiIiISCMY7IiIiIg0gsGOiIiISCMY7IiIiIg0gsGOiIiISCMY7IiIiIg0gsGOiMiONm3aBBcXl2sOIk5EVBoMdkREREQawWBHREREpBEMdkTk1PR6PWbNmoVatWrBx8cHLVq0wPLly/M1k65atQrNmzeHt7c3OnbsiCNHjuR7jB9//BFNmjSBl5cXwsPD8f777+e7PisrC5MnT0b16tXVberWrYsvv/wy32327duHtm3bwtfXF507d8aJEyds8OqJSGsY7IjIqUmo++abbzBv3jz8888/eO655/DQQw9h8+bNpts8//zzKqzt2bMHFSpUwIABA5CTk2MKZA888ACGDBmCw4cP45VXXsG0adPw1Vdfme4/fPhwfP/99/j4449x7NgxzJ8/H/7+/vm246WXXlLPsXfvXri7u+PRRx+14V4gIq1wMRgMBntvBBGRPUglLTg4GH/++Sc6depkWj969Gikp6djzJgxuO2227BkyRIMHjxYXZeQkIBq1aqp4CaBbtiwYbh48SL++OMP0/1feOEFVeWToHjy5Ek0aNAA69atQ69eva7ZBqkKynPINvTs2VOtW716Nfr374+MjAxVJSQiKi5W7IjIaUVERKgAd/vtt6sKmnGRCt7p06dNtzMPfRIEJahJ5U3IaZcuXfI9rlw+deoUdDodDh48CDc3N3Tr1q3IbZGmXqPKlSur0/j4eIu9ViJyDu723gAiIntJTU1Vp1Jdq1q1ar7rpC+cebgrLem3VxweHh6m89Kvz9j/j4ioJFixIyKn1bhxYxXgYmJi1IAG80UGOhjt3LnTdP7KlSuqebVRo0bqspxu27Yt3+PK5fr166tKXbNmzVRAM++zR0RkLazYEZHTCggIwKRJk9SACQlft9xyC5KSklQwCwwMRM2aNdXtXnvtNYSEhCAsLEwNcggNDcWgQYPUdRMnTkS7du0wc+ZM1Q9vx44dmDNnDj799FN1vYySHTFihBoMIYMnZNRtdHS0amaVPnpERJbEYEdETk0CmYx0ldGxZ86cQVBQEFq3bo0XX3zR1BT61ltv4ZlnnlH95lq2bIlff/0Vnp6e6jq57bJlyzB9+nT1WNI/ToLgyJEjTc/x2Wefqcd76qmncPnyZdSoUUNdJiKyNI6KJSK6DuOIVWl+lcBHROTo2MeOiIiISCMY7IiIiIg0gk2xRERERBrBih0RERGRRjDYEREREWkEgx0RERGRRjDYEREREWkEgx0RERGRRjDYEREREWkEgx0RERGRRjDYEREREWkEgx0RERERtOH/yuyhRsH475sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "TARGET = \"AMT\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) 데이터 로드/정리\n",
    "# -------------------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "for c in [\"DAY\", \"HOUR\", \"TEMP\", \"RAIN\", TARGET]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "df = df[df[\"DAY\"].between(1,7)]\n",
    "df = df[df[\"HOUR\"].between(1,10)]\n",
    "\n",
    "# (옵션) AMT 너무 큰 값 때문에 학습 불안정하면 로그 타겟이 더 잘 먹힘\n",
    "# y = np.log1p(df[TARGET].values)  # <- 이거 켜면 아래 inverse도 해야 함\n",
    "y = df[TARGET].astype(float).values\n",
    "\n",
    "X = df[[\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"]].copy()\n",
    "\n",
    "# -------------------------\n",
    "# 2) 전처리: DONG 원핫 + 나머지 스케일\n",
    "# -------------------------\n",
    "cat_cols = [\"DONG\"]\n",
    "num_cols = [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 전처리 fit/transform\n",
    "X_train_t = pre.fit_transform(X_train)\n",
    "X_test_t  = pre.transform(X_test)\n",
    "\n",
    "# sparse -> dense (Keras는 dense가 편함)\n",
    "# (피처 수가 너무 많으면 dense가 무거울 수 있음. 그때는 OrdinalEncoder로 바꿔줄게.)\n",
    "X_train_t = X_train_t.toarray() if hasattr(X_train_t, \"toarray\") else np.asarray(X_train_t)\n",
    "X_test_t  = X_test_t.toarray()  if hasattr(X_test_t, \"toarray\")  else np.asarray(X_test_t)\n",
    "\n",
    "print(\"X_train shape:\", X_train_t.shape, \"X_test shape:\", X_test_t.shape)\n",
    "\n",
    "# -------------------------\n",
    "# 3) 모델 만들기 (가벼운 MLP)\n",
    "# -------------------------\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_t.shape[1],)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)  # 회귀\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# EarlyStopping: 너무 오래 안 돌게 + 최고 성능 가중치 복원\n",
    "cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 4) 학습 (스샷처럼 로그 출력)\n",
    "# -------------------------\n",
    "hist = model.fit(\n",
    "    X_train_t, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,      # 스샷처럼 1000도 가능하지만, 보통 earlystop이면 200이면 충분\n",
    "    batch_size=256,\n",
    "    verbose=2,       # ✅ 스샷처럼 epoch 로그 출력\n",
    "    callbacks=[cb]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 5) 평가 + 그래프 (스샷처럼 loss/mae)\n",
    "# -------------------------\n",
    "test_loss, test_mae = model.evaluate(X_test_t, y_test, verbose=0)\n",
    "print(f\"[TEST] loss(mse)={test_loss:.4f}  mae={test_mae:.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"mae\"], label=\"mae\")\n",
    "if \"val_loss\" in hist.history:\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "if \"val_mae\" in hist.history:\n",
    "    plt.plot(hist.history[\"val_mae\"], label=\"val_mae\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Curve (loss / mae)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb61621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (310466, 48) X_test shape: (133057, 48)\n",
      "Epoch 1/200\n",
      "971/971 - 3s - loss: 94040942968832.0000 - mae: 4174123.2500 - val_loss: 78039396384768.0000 - val_mae: 3591751.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 2/200\n",
      "971/971 - 3s - loss: 69663639732224.0000 - mae: 3630542.2500 - val_loss: 75851118936064.0000 - val_mae: 3565985.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "971/971 - 3s - loss: 68011402723328.0000 - mae: 3583165.0000 - val_loss: 74627934060544.0000 - val_mae: 3491969.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 4/200\n",
      "971/971 - 3s - loss: 67041604141056.0000 - mae: 3556980.5000 - val_loss: 73726804623360.0000 - val_mae: 3492851.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "971/971 - 3s - loss: 66365935321088.0000 - mae: 3544139.7500 - val_loss: 73321542582272.0000 - val_mae: 3460527.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 6/200\n",
      "971/971 - 3s - loss: 65310908481536.0000 - mae: 3510669.2500 - val_loss: 70964377288704.0000 - val_mae: 3418663.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 7/200\n",
      "971/971 - 3s - loss: 61223605370880.0000 - mae: 3253038.5000 - val_loss: 64789829124096.0000 - val_mae: 3020240.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "971/971 - 3s - loss: 55217341071360.0000 - mae: 2914112.0000 - val_loss: 59739782250496.0000 - val_mae: 2751044.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "971/971 - 3s - loss: 51028149927936.0000 - mae: 2708886.2500 - val_loss: 56152486313984.0000 - val_mae: 2569608.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "971/971 - 3s - loss: 48109891616768.0000 - mae: 2567058.7500 - val_loss: 53307921924096.0000 - val_mae: 2464414.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "971/971 - 3s - loss: 45449444589568.0000 - mae: 2453846.2500 - val_loss: 50745034407936.0000 - val_mae: 2382117.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "971/971 - 3s - loss: 43162093486080.0000 - mae: 2362331.2500 - val_loss: 48383733530624.0000 - val_mae: 2299055.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "971/971 - 3s - loss: 41107459145728.0000 - mae: 2277354.7500 - val_loss: 46138379993088.0000 - val_mae: 2210894.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "971/971 - 3s - loss: 39151298674688.0000 - mae: 2189489.2500 - val_loss: 44406103080960.0000 - val_mae: 2131320.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "971/971 - 3s - loss: 37221964972032.0000 - mae: 2089767.3750 - val_loss: 42075294793728.0000 - val_mae: 2055635.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "971/971 - 3s - loss: 35448726487040.0000 - mae: 2001123.3750 - val_loss: 40692021723136.0000 - val_mae: 1907195.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "971/971 - 3s - loss: 33852374384640.0000 - mae: 1922897.0000 - val_loss: 39202448211968.0000 - val_mae: 1922740.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 18/200\n",
      "971/971 - 3s - loss: 32618661806080.0000 - mae: 1867222.6250 - val_loss: 37675541200896.0000 - val_mae: 1810645.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "971/971 - 3s - loss: 31584975585280.0000 - mae: 1814942.5000 - val_loss: 36565787082752.0000 - val_mae: 1766823.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "971/971 - 3s - loss: 30457110462464.0000 - mae: 1770725.2500 - val_loss: 36120096145408.0000 - val_mae: 1728265.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "971/971 - 3s - loss: 29726175395840.0000 - mae: 1740512.2500 - val_loss: 34896642834432.0000 - val_mae: 1692366.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "971/971 - 3s - loss: 28447254511616.0000 - mae: 1695704.3750 - val_loss: 33666501705728.0000 - val_mae: 1681037.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "971/971 - 3s - loss: 27463446953984.0000 - mae: 1654909.6250 - val_loss: 32707834806272.0000 - val_mae: 1601353.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "971/971 - 3s - loss: 26747321974784.0000 - mae: 1610480.7500 - val_loss: 32271698493440.0000 - val_mae: 1591369.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "971/971 - 3s - loss: 26277870305280.0000 - mae: 1591710.2500 - val_loss: 31669748760576.0000 - val_mae: 1546413.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "971/971 - 3s - loss: 25862160252928.0000 - mae: 1563732.5000 - val_loss: 31481504202752.0000 - val_mae: 1544152.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "971/971 - 3s - loss: 25545557409792.0000 - mae: 1549689.5000 - val_loss: 30937301647360.0000 - val_mae: 1497801.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "971/971 - 3s - loss: 25198862532608.0000 - mae: 1529275.1250 - val_loss: 30965428649984.0000 - val_mae: 1558509.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 29/200\n",
      "971/971 - 3s - loss: 24901071142912.0000 - mae: 1516883.1250 - val_loss: 30404673273856.0000 - val_mae: 1483603.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "971/971 - 3s - loss: 24666309656576.0000 - mae: 1507964.7500 - val_loss: 30455527112704.0000 - val_mae: 1466966.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "971/971 - 3s - loss: 24563704397824.0000 - mae: 1500496.2500 - val_loss: 30052796334080.0000 - val_mae: 1478443.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "971/971 - 3s - loss: 24331985879040.0000 - mae: 1490627.5000 - val_loss: 30194775621632.0000 - val_mae: 1479533.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "971/971 - 3s - loss: 24232098529280.0000 - mae: 1484130.7500 - val_loss: 30042383974400.0000 - val_mae: 1455621.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "971/971 - 3s - loss: 24077964148736.0000 - mae: 1469198.5000 - val_loss: 30402349629440.0000 - val_mae: 1440978.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 35/200\n",
      "971/971 - 3s - loss: 23991798464512.0000 - mae: 1455344.3750 - val_loss: 29876172095488.0000 - val_mae: 1428734.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "971/971 - 3s - loss: 23908552015872.0000 - mae: 1456762.2500 - val_loss: 29819930673152.0000 - val_mae: 1469606.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "971/971 - 3s - loss: 23954448187392.0000 - mae: 1457905.7500 - val_loss: 29800760606720.0000 - val_mae: 1433992.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "971/971 - 3s - loss: 23740037464064.0000 - mae: 1447582.6250 - val_loss: 29504059736064.0000 - val_mae: 1426182.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "971/971 - 3s - loss: 23707877638144.0000 - mae: 1440201.7500 - val_loss: 29459577044992.0000 - val_mae: 1423399.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "971/971 - 3s - loss: 23617677033472.0000 - mae: 1435769.2500 - val_loss: 29223016202240.0000 - val_mae: 1393747.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "971/971 - 3s - loss: 23636358463488.0000 - mae: 1431862.7500 - val_loss: 29329176133632.0000 - val_mae: 1390040.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "971/971 - 3s - loss: 23512349671424.0000 - mae: 1426147.7500 - val_loss: 29306736607232.0000 - val_mae: 1464326.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "971/971 - 3s - loss: 23372893257728.0000 - mae: 1411337.3750 - val_loss: 29219434266624.0000 - val_mae: 1378909.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "971/971 - 3s - loss: 23418504216576.0000 - mae: 1415589.5000 - val_loss: 29462773104640.0000 - val_mae: 1422545.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "971/971 - 3s - loss: 23339898765312.0000 - mae: 1406989.8750 - val_loss: 29719269474304.0000 - val_mae: 1413907.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "971/971 - 3s - loss: 23186190106624.0000 - mae: 1402355.0000 - val_loss: 29226786881536.0000 - val_mae: 1420227.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "971/971 - 3s - loss: 23321508839424.0000 - mae: 1406272.1250 - val_loss: 29303527964672.0000 - val_mae: 1492783.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "971/971 - 3s - loss: 23130479263744.0000 - mae: 1405657.1250 - val_loss: 29049548177408.0000 - val_mae: 1436626.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "971/971 - 3s - loss: 23113284714496.0000 - mae: 1396194.5000 - val_loss: 28900063182848.0000 - val_mae: 1367059.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "971/971 - 3s - loss: 23140910497792.0000 - mae: 1398253.6250 - val_loss: 28726708404224.0000 - val_mae: 1391214.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "971/971 - 3s - loss: 23053408927744.0000 - mae: 1396428.7500 - val_loss: 29290338975744.0000 - val_mae: 1464916.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "971/971 - 3s - loss: 23097656737792.0000 - mae: 1390122.7500 - val_loss: 28775637057536.0000 - val_mae: 1360525.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "971/971 - 3s - loss: 23061657026560.0000 - mae: 1389443.1250 - val_loss: 28813723435008.0000 - val_mae: 1359414.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "971/971 - 3s - loss: 23066679705600.0000 - mae: 1391002.2500 - val_loss: 29018952826880.0000 - val_mae: 1470164.3750 - 3s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "971/971 - 3s - loss: 22984095956992.0000 - mae: 1387801.8750 - val_loss: 28764499083264.0000 - val_mae: 1359736.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "971/971 - 3s - loss: 22932979974144.0000 - mae: 1381434.8750 - val_loss: 29478789054464.0000 - val_mae: 1400527.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "971/971 - 3s - loss: 22972018458624.0000 - mae: 1383216.6250 - val_loss: 28896726614016.0000 - val_mae: 1354471.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "971/971 - 3s - loss: 23016622784512.0000 - mae: 1377592.1250 - val_loss: 28642956541952.0000 - val_mae: 1381293.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "971/971 - 3s - loss: 22886035226624.0000 - mae: 1379630.2500 - val_loss: 29240250597376.0000 - val_mae: 1362114.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "971/971 - 3s - loss: 22809411584000.0000 - mae: 1374041.0000 - val_loss: 28753398857728.0000 - val_mae: 1419039.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "971/971 - 3s - loss: 22861783760896.0000 - mae: 1374770.6250 - val_loss: 28728128176128.0000 - val_mae: 1354802.2500 - 3s/epoch - 4ms/step\n",
      "Epoch 62/200\n",
      "971/971 - 3s - loss: 22810049118208.0000 - mae: 1370444.7500 - val_loss: 28624413523968.0000 - val_mae: 1344373.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "971/971 - 3s - loss: 22843945385984.0000 - mae: 1382121.3750 - val_loss: 28516439556096.0000 - val_mae: 1374058.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "971/971 - 3s - loss: 22759744733184.0000 - mae: 1369947.7500 - val_loss: 28599746822144.0000 - val_mae: 1349220.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "971/971 - 4s - loss: 22769303552000.0000 - mae: 1377531.2500 - val_loss: 28716704989184.0000 - val_mae: 1337173.3750 - 4s/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "971/971 - 4s - loss: 22802788777984.0000 - mae: 1374408.7500 - val_loss: 29228789661696.0000 - val_mae: 1495382.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 67/200\n",
      "971/971 - 3s - loss: 22730172792832.0000 - mae: 1365462.0000 - val_loss: 28517534269440.0000 - val_mae: 1414503.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 68/200\n",
      "971/971 - 3s - loss: 22707922010112.0000 - mae: 1368569.1250 - val_loss: 28755573604352.0000 - val_mae: 1383725.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "971/971 - 3s - loss: 22735570862080.0000 - mae: 1364986.1250 - val_loss: 28613797740544.0000 - val_mae: 1430033.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 70/200\n",
      "971/971 - 3s - loss: 22661935661056.0000 - mae: 1358637.3750 - val_loss: 28595808370688.0000 - val_mae: 1373866.7500 - 3s/epoch - 3ms/step\n",
      "Epoch 71/200\n",
      "971/971 - 3s - loss: 22675862847488.0000 - mae: 1366947.3750 - val_loss: 28601898500096.0000 - val_mae: 1358408.1250 - 3s/epoch - 3ms/step\n",
      "Epoch 72/200\n",
      "971/971 - 3s - loss: 22748506095616.0000 - mae: 1365461.2500 - val_loss: 28211951960064.0000 - val_mae: 1366268.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 73/200\n",
      "971/971 - 3s - loss: 22679633526784.0000 - mae: 1363071.3750 - val_loss: 28223654068224.0000 - val_mae: 1319630.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "971/971 - 3s - loss: 22697859874816.0000 - mae: 1364685.7500 - val_loss: 28470505635840.0000 - val_mae: 1394847.6250 - 3s/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "971/971 - 3s - loss: 22572395659264.0000 - mae: 1360150.3750 - val_loss: 28865233682432.0000 - val_mae: 1352845.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "971/971 - 3s - loss: 22698627432448.0000 - mae: 1358441.8750 - val_loss: 28674132803584.0000 - val_mae: 1355713.8750 - 3s/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "971/971 - 3s - loss: 22626076459008.0000 - mae: 1361688.3750 - val_loss: 28706626076672.0000 - val_mae: 1376141.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "971/971 - 3s - loss: 22647360454656.0000 - mae: 1358187.0000 - val_loss: 28783971139584.0000 - val_mae: 1343203.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "971/971 - 3s - loss: 22592673021952.0000 - mae: 1361917.5000 - val_loss: 28693481127936.0000 - val_mae: 1370850.3750 - 3s/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "971/971 - 3s - loss: 22613501935616.0000 - mae: 1352236.6250 - val_loss: 28921225543680.0000 - val_mae: 1376840.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "971/971 - 3s - loss: 22619688534016.0000 - mae: 1357215.3750 - val_loss: 28701253173248.0000 - val_mae: 1386206.2500 - 3s/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "971/971 - 3s - loss: 22613487255552.0000 - mae: 1359679.6250 - val_loss: 28713798336512.0000 - val_mae: 1323023.1250 - 3s/epoch - 3ms/step\n",
      "[TEST] loss(mse)=23656732295168.0000  mae=1376968.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "TARGET = \"AMT\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) 데이터 로드/정리\n",
    "# -------------------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "for c in [\"DAY\", \"HOUR\", \"TEMP\", \"RAIN\", TARGET]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "df = df[df[\"DAY\"].between(1,7)]\n",
    "df = df[df[\"HOUR\"].between(1,10)]\n",
    "\n",
    "# (옵션) AMT 너무 큰 값 때문에 학습 불안정하면 로그 타겟이 더 잘 먹힘\n",
    "# y = np.log1p(df[TARGET].values)  # <- 이거 켜면 아래 inverse도 해야 함\n",
    "y = df[TARGET].astype(float).values\n",
    "\n",
    "X = df[[\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"]].copy()\n",
    "\n",
    "# -------------------------\n",
    "# 2) 전처리: DONG 원핫 + 나머지 스케일\n",
    "# -------------------------\n",
    "cat_cols = [\"DONG\"]\n",
    "num_cols = [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 전처리 fit/transform\n",
    "X_train_t = pre.fit_transform(X_train)\n",
    "X_test_t  = pre.transform(X_test)\n",
    "\n",
    "# sparse -> dense (Keras는 dense가 편함)\n",
    "# (피처 수가 너무 많으면 dense가 무거울 수 있음. 그때는 OrdinalEncoder로 바꿔줄게.)\n",
    "X_train_t = X_train_t.toarray() if hasattr(X_train_t, \"toarray\") else np.asarray(X_train_t)\n",
    "X_test_t  = X_test_t.toarray()  if hasattr(X_test_t, \"toarray\")  else np.asarray(X_test_t)\n",
    "\n",
    "print(\"X_train shape:\", X_train_t.shape, \"X_test shape:\", X_test_t.shape)\n",
    "\n",
    "# -------------------------\n",
    "# 3) 모델 만들기 (가벼운 MLP)\n",
    "# -------------------------\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_t.shape[1],)),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)  # 회귀\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# EarlyStopping: 너무 오래 안 돌게 + 최고 성능 가중치 복원\n",
    "cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 4) 학습 (스샷처럼 로그 출력)\n",
    "# -------------------------\n",
    "hist = model.fit(\n",
    "    X_train_t, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,      # 스샷처럼 1000도 가능하지만, 보통 earlystop이면 200이면 충분\n",
    "    batch_size=256,\n",
    "    verbose=2,       # ✅ 스샷처럼 epoch 로그 출력\n",
    "    callbacks=[cb]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 5) 평가 + 그래프 (스샷처럼 loss/mae)\n",
    "# -------------------------\n",
    "test_loss, test_mae = model.evaluate(X_test_t, y_test, verbose=0)\n",
    "print(f\"[TEST] loss(mse)={test_loss:.4f}  mae={test_mae:.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"mae\"], label=\"mae\")\n",
    "if \"val_loss\" in hist.history:\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "if \"val_mae\" in hist.history:\n",
    "    plt.plot(hist.history[\"val_mae\"], label=\"val_mae\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Curve (loss / mae)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef9938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DONE ===\n",
      "Test range: 2025-10-02 ~ 2025-10-31\n",
      "  Model           MAE          RMSE     MAPE(%)  Accuracy%(=100-MAPE)  \\\n",
      "0  DEEP  3.836357e+06  1.095833e+07  676.871089                   0.0   \n",
      "\n",
      "         R2  \n",
      "0  0.406113  \n",
      "Saved: C:/ai/source/10_1stProject/compare_models_amt\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# =========================\n",
    "# 경로 설정(너 환경에 맞게 수정)\n",
    "# =========================\n",
    "DATA_CSV   = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "RF_PATH    = r\"C:/ai/source/10_1stProject/models_weather_C/rf_amt.joblib\"            # 없으면 \"\"로 두기\n",
    "HGB_PATH   = r\"C:/ai/source/10_1stProject/models_weather_C_fast/hgb_amt.joblib\"      # 없으면 \"\"로 두기\n",
    "OUT_DIR    = r\"C:/ai/source/10_1stProject/compare_models_amt\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET   = \"AMT\"\n",
    "FEATURES = [\"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"]\n",
    "\n",
    "# 딥러닝 학습 설정(가볍게)\n",
    "DEEP_EPOCHS = 80\n",
    "DEEP_BATCH  = 256\n",
    "DEEP_VERBOSE = 0  # 비교평가라 로그 끄는게 편함(원하면 2로)\n",
    "\n",
    "# =========================\n",
    "# metrics (Accuracy = 100 - MAPE)\n",
    "# =========================\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    denom = np.maximum(np.abs(y_true), 1.0)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "def acc100(y_true, y_pred):\n",
    "    return float(max(0.0, 100.0 - mape(y_true, y_pred)))\n",
    "\n",
    "def metrics_all(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"RMSE\": rmse(y_true, y_pred),\n",
    "        \"MAPE(%)\": float(mape(y_true, y_pred)),\n",
    "        \"Accuracy%(=100-MAPE)\": float(acc100(y_true, y_pred)),\n",
    "        \"R2\": float(r2_score(y_true, y_pred)) if len(y_true) >= 2 else np.nan\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# data load + clean + time split\n",
    "# =========================\n",
    "def load_clean():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "    for c in [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "    df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "    df = df[df[\"DAY\"].between(1,7)]\n",
    "    df = df[df[\"HOUR\"].between(1,10)]\n",
    "    return df\n",
    "\n",
    "def time_split(df, test_days=30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "    train_df = df[df[\"DATE\"] <= cutoff].copy()\n",
    "    test_df  = df[df[\"DATE\"] >  cutoff].copy()\n",
    "    return train_df, test_df, cutoff, max_date\n",
    "\n",
    "# =========================\n",
    "# deep model (학습 후 예측)\n",
    "# =========================\n",
    "def build_pre_for_deep():\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"dong\", OneHotEncoder(handle_unknown=\"ignore\"), [\"DONG\"]),\n",
    "            (\"num\", StandardScaler(), [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"]),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "def train_and_predict_deep(X_train_df, y_train, X_test_df, seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    pre = build_pre_for_deep()\n",
    "    Xtr = pre.fit_transform(X_train_df)\n",
    "    Xte = pre.transform(X_test_df)\n",
    "\n",
    "    Xtr = Xtr.toarray() if hasattr(Xtr, \"toarray\") else np.asarray(Xtr)\n",
    "    Xte = Xte.toarray() if hasattr(Xte, \"toarray\") else np.asarray(Xte)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(Xtr.shape[1],)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    model.fit(Xtr, y_train, epochs=DEEP_EPOCHS, batch_size=DEEP_BATCH, verbose=DEEP_VERBOSE)\n",
    "\n",
    "    pred = model.predict(Xte, verbose=0).reshape(-1)\n",
    "    # (옵션) 딥러닝 모델 저장하고 싶으면 아래 주석 해제\n",
    "    # model.save(os.path.join(OUT_DIR, \"deep_amt.keras\"))\n",
    "    return pred\n",
    "\n",
    "# =========================\n",
    "# plot helpers\n",
    "# =========================\n",
    "def save_bar_compare(df_metrics, metric_name, path):\n",
    "    plt.figure()\n",
    "    plt.bar(df_metrics[\"Model\"], df_metrics[metric_name].astype(float))\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"Model Comparison - {metric_name} (AMT)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# main compare\n",
    "# =========================\n",
    "def run_compare(test_days=30):\n",
    "    df = load_clean()\n",
    "    train_df, test_df, cutoff, max_date = time_split(df, test_days=test_days)\n",
    "\n",
    "    X_train = train_df[FEATURES]\n",
    "    y_train = train_df[TARGET].astype(float).values\n",
    "    X_test  = test_df[FEATURES]\n",
    "    y_test  = test_df[TARGET].astype(float).values\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RF (joblib Pipeline)\n",
    "    if RF_PATH and os.path.exists(RF_PATH):\n",
    "        rf = joblib.load(RF_PATH)\n",
    "        pred_rf = rf.predict(X_test)\n",
    "        met = metrics_all(y_test, pred_rf)\n",
    "        met[\"Model\"] = \"RF\"\n",
    "        results.append(met)\n",
    "\n",
    "    # HGB (joblib Pipeline)\n",
    "    if HGB_PATH and os.path.exists(HGB_PATH):\n",
    "        hgb = joblib.load(HGB_PATH)\n",
    "        pred_hgb = hgb.predict(X_test)\n",
    "        met = metrics_all(y_test, pred_hgb)\n",
    "        met[\"Model\"] = \"HGB\"\n",
    "        results.append(met)\n",
    "\n",
    "    # Deep (직접 학습 후 예측)\n",
    "    pred_deep = train_and_predict_deep(X_train, y_train, X_test)\n",
    "    met = metrics_all(y_test, pred_deep)\n",
    "    met[\"Model\"] = \"DEEP\"\n",
    "    results.append(met)\n",
    "\n",
    "    dfm = pd.DataFrame(results)[[\"Model\",\"MAE\",\"RMSE\",\"MAPE(%)\",\"Accuracy%(=100-MAPE)\",\"R2\"]]\n",
    "    dfm.to_csv(os.path.join(OUT_DIR, \"compare_metrics_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 그래프 저장(대표 3개)\n",
    "    save_bar_compare(dfm, \"Accuracy%(=100-MAPE)\", os.path.join(OUT_DIR, \"compare_accuracy_amt.png\"))\n",
    "    save_bar_compare(dfm, \"RMSE\", os.path.join(OUT_DIR, \"compare_rmse_amt.png\"))\n",
    "    save_bar_compare(dfm, \"MAE\", os.path.join(OUT_DIR, \"compare_mae_amt.png\"))\n",
    "\n",
    "    print(\"=== DONE ===\")\n",
    "    print(\"Test range:\", str((cutoff + pd.Timedelta(days=1)).date()), \"~\", str(max_date.date()))\n",
    "    print(dfm)\n",
    "    print(\"Saved:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_compare(test_days=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdec66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "1683/1683 - 2s - loss: 142774124937216.0000 - mae: 5036396.0000 - 2s/epoch - 1ms/step\n",
      "Epoch 2/120\n",
      "1683/1683 - 2s - loss: 134863743090688.0000 - mae: 4563122.0000 - 2s/epoch - 959us/step\n",
      "Epoch 3/120\n",
      "1683/1683 - 2s - loss: 122210903654400.0000 - mae: 4211324.5000 - 2s/epoch - 984us/step\n",
      "Epoch 4/120\n",
      "1683/1683 - 2s - loss: 112090559807488.0000 - mae: 4257539.0000 - 2s/epoch - 956us/step\n",
      "Epoch 5/120\n",
      "1683/1683 - 2s - loss: 105000206336000.0000 - mae: 4386031.0000 - 2s/epoch - 966us/step\n",
      "Epoch 6/120\n",
      "1683/1683 - 2s - loss: 99269872713728.0000 - mae: 4336654.5000 - 2s/epoch - 965us/step\n",
      "Epoch 7/120\n",
      "1683/1683 - 2s - loss: 93619977453568.0000 - mae: 4141418.0000 - 2s/epoch - 1ms/step\n",
      "Epoch 8/120\n",
      "1683/1683 - 2s - loss: 88230397476864.0000 - mae: 3952798.7500 - 2s/epoch - 996us/step\n",
      "Epoch 9/120\n",
      "1683/1683 - 2s - loss: 83584182386688.0000 - mae: 3835465.2500 - 2s/epoch - 995us/step\n",
      "Epoch 10/120\n",
      "1683/1683 - 2s - loss: 79767810342912.0000 - mae: 3772150.2500 - 2s/epoch - 986us/step\n",
      "Epoch 11/120\n",
      "1683/1683 - 2s - loss: 76754588794880.0000 - mae: 3722015.7500 - 2s/epoch - 983us/step\n",
      "Epoch 12/120\n",
      "1683/1683 - 2s - loss: 74568542715904.0000 - mae: 3682944.7500 - 2s/epoch - 965us/step\n",
      "Epoch 13/120\n",
      "1683/1683 - 2s - loss: 73110535536640.0000 - mae: 3651294.7500 - 2s/epoch - 965us/step\n",
      "Epoch 14/120\n",
      "1683/1683 - 2s - loss: 72216561582080.0000 - mae: 3637414.2500 - 2s/epoch - 966us/step\n",
      "Epoch 15/120\n",
      "1683/1683 - 2s - loss: 71682542796800.0000 - mae: 3624936.2500 - 2s/epoch - 993us/step\n",
      "Epoch 16/120\n",
      "1683/1683 - 2s - loss: 71350957899776.0000 - mae: 3620030.5000 - 2s/epoch - 969us/step\n",
      "Epoch 17/120\n",
      "1683/1683 - 2s - loss: 71125463728128.0000 - mae: 3616251.5000 - 2s/epoch - 981us/step\n",
      "Epoch 18/120\n",
      "1683/1683 - 2s - loss: 70958555594752.0000 - mae: 3614957.7500 - 2s/epoch - 953us/step\n",
      "Epoch 19/120\n",
      "1683/1683 - 2s - loss: 70818507784192.0000 - mae: 3610570.0000 - 2s/epoch - 966us/step\n",
      "Epoch 20/120\n",
      "1683/1683 - 2s - loss: 70691713974272.0000 - mae: 3610487.2500 - 2s/epoch - 970us/step\n",
      "Epoch 21/120\n",
      "1683/1683 - 2s - loss: 70571748491264.0000 - mae: 3606735.2500 - 2s/epoch - 977us/step\n",
      "Epoch 22/120\n",
      "1683/1683 - 2s - loss: 70451850117120.0000 - mae: 3604357.0000 - 2s/epoch - 993us/step\n",
      "Epoch 23/120\n",
      "1683/1683 - 2s - loss: 70335093276672.0000 - mae: 3603721.5000 - 2s/epoch - 1ms/step\n",
      "Epoch 24/120\n",
      "1683/1683 - 2s - loss: 70217422077952.0000 - mae: 3599423.2500 - 2s/epoch - 1ms/step\n",
      "Epoch 25/120\n",
      "1683/1683 - 2s - loss: 70094575108096.0000 - mae: 3597096.0000 - 2s/epoch - 956us/step\n",
      "Epoch 26/120\n",
      "1683/1683 - 2s - loss: 69970838945792.0000 - mae: 3595954.5000 - 2s/epoch - 969us/step\n",
      "Epoch 27/120\n",
      "1683/1683 - 2s - loss: 69842862342144.0000 - mae: 3592890.5000 - 2s/epoch - 960us/step\n",
      "Epoch 28/120\n",
      "1683/1683 - 2s - loss: 69716345356288.0000 - mae: 3591098.2500 - 2s/epoch - 966us/step\n",
      "Epoch 29/120\n",
      "1683/1683 - 2s - loss: 69587869630464.0000 - mae: 3586779.2500 - 2s/epoch - 975us/step\n",
      "Epoch 30/120\n",
      "1683/1683 - 2s - loss: 69461222621184.0000 - mae: 3585896.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 31/120\n",
      "1683/1683 - 2s - loss: 69335104094208.0000 - mae: 3581878.7500 - 2s/epoch - 965us/step\n",
      "Epoch 32/120\n",
      "1683/1683 - 2s - loss: 69209820233728.0000 - mae: 3582033.5000 - 2s/epoch - 987us/step\n",
      "Epoch 33/120\n",
      "1683/1683 - 2s - loss: 69088915226624.0000 - mae: 3576877.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 34/120\n",
      "1683/1683 - 2s - loss: 68970237394944.0000 - mae: 3575785.2500 - 2s/epoch - 975us/step\n",
      "Epoch 35/120\n",
      "1683/1683 - 2s - loss: 68858572439552.0000 - mae: 3572995.0000 - 2s/epoch - 997us/step\n",
      "Epoch 36/120\n",
      "1683/1683 - 2s - loss: 68749562478592.0000 - mae: 3571783.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 37/120\n",
      "1683/1683 - 2s - loss: 68641684979712.0000 - mae: 3568041.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 38/120\n",
      "1683/1683 - 2s - loss: 68538119225344.0000 - mae: 3566589.2500 - 2s/epoch - 1ms/step\n",
      "Epoch 39/120\n",
      "1683/1683 - 2s - loss: 68437426569216.0000 - mae: 3564105.2500 - 2s/epoch - 970us/step\n",
      "Epoch 40/120\n",
      "1683/1683 - 2s - loss: 68339569262592.0000 - mae: 3563220.7500 - 2s/epoch - 977us/step\n",
      "Epoch 41/120\n",
      "1683/1683 - 2s - loss: 68242722783232.0000 - mae: 3560314.7500 - 2s/epoch - 970us/step\n",
      "Epoch 42/120\n",
      "1683/1683 - 2s - loss: 68149097529344.0000 - mae: 3558252.7500 - 2s/epoch - 972us/step\n",
      "Epoch 43/120\n",
      "1683/1683 - 2s - loss: 68054700523520.0000 - mae: 3555308.2500 - 2s/epoch - 968us/step\n",
      "Epoch 44/120\n",
      "1683/1683 - 2s - loss: 67961867993088.0000 - mae: 3553813.7500 - 2s/epoch - 977us/step\n",
      "Epoch 45/120\n",
      "1683/1683 - 2s - loss: 67872160219136.0000 - mae: 3550136.2500 - 2s/epoch - 963us/step\n",
      "Epoch 46/120\n",
      "1683/1683 - 2s - loss: 67787535941632.0000 - mae: 3551752.2500 - 2s/epoch - 974us/step\n",
      "Epoch 47/120\n",
      "1683/1683 - 2s - loss: 67706875281408.0000 - mae: 3545879.2500 - 2s/epoch - 967us/step\n",
      "Epoch 48/120\n",
      "1683/1683 - 2s - loss: 67630337622016.0000 - mae: 3547705.2500 - 2s/epoch - 962us/step\n",
      "Epoch 49/120\n",
      "1683/1683 - 2s - loss: 67555439935488.0000 - mae: 3543657.7500 - 2s/epoch - 970us/step\n",
      "Epoch 50/120\n",
      "1683/1683 - 2s - loss: 67480135401472.0000 - mae: 3542895.2500 - 2s/epoch - 995us/step\n",
      "Epoch 51/120\n",
      "1683/1683 - 2s - loss: 67407678799872.0000 - mae: 3540932.7500 - 2s/epoch - 988us/step\n",
      "Epoch 52/120\n",
      "1683/1683 - 2s - loss: 67337789112320.0000 - mae: 3539639.0000 - 2s/epoch - 969us/step\n",
      "Epoch 53/120\n",
      "1683/1683 - 2s - loss: 67271938539520.0000 - mae: 3535738.2500 - 2s/epoch - 999us/step\n",
      "Epoch 54/120\n",
      "1683/1683 - 2s - loss: 67207484669952.0000 - mae: 3536498.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 55/120\n",
      "1683/1683 - 2s - loss: 67143030800384.0000 - mae: 3532976.2500 - 2s/epoch - 1ms/step\n",
      "Epoch 56/120\n",
      "1683/1683 - 2s - loss: 67082456662016.0000 - mae: 3532942.7500 - 2s/epoch - 990us/step\n",
      "Epoch 57/120\n",
      "1683/1683 - 2s - loss: 67023509913600.0000 - mae: 3533614.0000 - 2s/epoch - 973us/step\n",
      "Epoch 58/120\n",
      "1683/1683 - 2s - loss: 66962893832192.0000 - mae: 3529873.0000 - 2s/epoch - 974us/step\n",
      "Epoch 59/120\n",
      "1683/1683 - 2s - loss: 66906744684544.0000 - mae: 3530342.0000 - 2s/epoch - 971us/step\n",
      "Epoch 60/120\n",
      "1683/1683 - 2s - loss: 66850561982464.0000 - mae: 3527566.0000 - 2s/epoch - 966us/step\n",
      "Epoch 61/120\n",
      "1683/1683 - 2s - loss: 66794677075968.0000 - mae: 3527911.0000 - 2s/epoch - 1ms/step\n",
      "Epoch 62/120\n",
      "1683/1683 - 2s - loss: 66743875665920.0000 - mae: 3523852.2500 - 2s/epoch - 987us/step\n",
      "Epoch 63/120\n",
      "1683/1683 - 2s - loss: 66689521680384.0000 - mae: 3525115.7500 - 2s/epoch - 979us/step\n",
      "Epoch 64/120\n",
      "1683/1683 - 2s - loss: 66637587808256.0000 - mae: 3523219.7500 - 2s/epoch - 976us/step\n",
      "Epoch 65/120\n",
      "1683/1683 - 2s - loss: 66582474653696.0000 - mae: 3522597.5000 - 2s/epoch - 972us/step\n",
      "Epoch 66/120\n",
      "1683/1683 - 2s - loss: 66528972111872.0000 - mae: 3522391.7500 - 2s/epoch - 967us/step\n",
      "Epoch 67/120\n",
      "1683/1683 - 2s - loss: 66471619198976.0000 - mae: 3518827.0000 - 2s/epoch - 979us/step\n",
      "Epoch 68/120\n",
      "1683/1683 - 2s - loss: 66414278868992.0000 - mae: 3518171.0000 - 2s/epoch - 1ms/step\n",
      "Epoch 69/120\n",
      "1683/1683 - 2s - loss: 66352605822976.0000 - mae: 3517898.0000 - 2s/epoch - 995us/step\n",
      "Epoch 70/120\n",
      "1683/1683 - 2s - loss: 66286549729280.0000 - mae: 3515998.5000 - 2s/epoch - 1ms/step\n",
      "Epoch 71/120\n",
      "1683/1683 - 2s - loss: 66218694279168.0000 - mae: 3512073.0000 - 2s/epoch - 992us/step\n",
      "Epoch 72/120\n",
      "1683/1683 - 2s - loss: 66141443588096.0000 - mae: 3512905.2500 - 2s/epoch - 992us/step\n",
      "Epoch 73/120\n",
      "1683/1683 - 2s - loss: 66060871008256.0000 - mae: 3507744.0000 - 2s/epoch - 984us/step\n",
      "Epoch 74/120\n",
      "1683/1683 - 2s - loss: 65970974490624.0000 - mae: 3506697.5000 - 2s/epoch - 1ms/step\n",
      "Epoch 75/120\n",
      "1683/1683 - 2s - loss: 65872991354880.0000 - mae: 3503392.5000 - 2s/epoch - 1ms/step\n",
      "Epoch 76/120\n",
      "1683/1683 - 2s - loss: 65762999926784.0000 - mae: 3497586.2500 - 2s/epoch - 984us/step\n",
      "Epoch 77/120\n",
      "1683/1683 - 2s - loss: 65642979917824.0000 - mae: 3495955.0000 - 2s/epoch - 975us/step\n",
      "Epoch 78/120\n",
      "1683/1683 - 2s - loss: 65509684936704.0000 - mae: 3490020.2500 - 2s/epoch - 956us/step\n",
      "Epoch 79/120\n",
      "1683/1683 - 2s - loss: 65357834354688.0000 - mae: 3483668.2500 - 2s/epoch - 967us/step\n",
      "Epoch 80/120\n",
      "1683/1683 - 2s - loss: 65187142959104.0000 - mae: 3476753.0000 - 2s/epoch - 958us/step\n",
      "Epoch 81/120\n",
      "1683/1683 - 2s - loss: 64998290227200.0000 - mae: 3468576.7500 - 2s/epoch - 956us/step\n",
      "Epoch 82/120\n",
      "1683/1683 - 2s - loss: 64787169935360.0000 - mae: 3457576.2500 - 2s/epoch - 1ms/step\n",
      "Epoch 83/120\n",
      "1683/1683 - 2s - loss: 64546148450304.0000 - mae: 3447860.7500 - 2s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/120\n",
      "1683/1683 - 2s - loss: 64277822046208.0000 - mae: 3434244.2500 - 2s/epoch - 1000us/step\n",
      "Epoch 85/120\n",
      "1683/1683 - 2s - loss: 63980265537536.0000 - mae: 3417740.2500 - 2s/epoch - 963us/step\n",
      "Epoch 86/120\n",
      "1683/1683 - 2s - loss: 63645153230848.0000 - mae: 3401781.2500 - 2s/epoch - 966us/step\n",
      "Epoch 87/120\n",
      "1683/1683 - 2s - loss: 63272757755904.0000 - mae: 3375211.5000 - 2s/epoch - 968us/step\n",
      "Epoch 88/120\n",
      "1683/1683 - 2s - loss: 62861367836672.0000 - mae: 3355037.5000 - 2s/epoch - 972us/step\n",
      "Epoch 89/120\n",
      "1683/1683 - 2s - loss: 62422312288256.0000 - mae: 3327648.0000 - 2s/epoch - 997us/step\n",
      "Epoch 90/120\n",
      "1683/1683 - 2s - loss: 61960615886848.0000 - mae: 3294739.7500 - 2s/epoch - 971us/step\n",
      "Epoch 91/120\n",
      "1683/1683 - 2s - loss: 61476370907136.0000 - mae: 3260662.0000 - 2s/epoch - 971us/step\n",
      "Epoch 92/120\n",
      "1683/1683 - 2s - loss: 60978066620416.0000 - mae: 3227271.7500 - 2s/epoch - 970us/step\n",
      "Epoch 93/120\n",
      "1683/1683 - 2s - loss: 60468160888832.0000 - mae: 3187829.2500 - 2s/epoch - 975us/step\n",
      "Epoch 94/120\n",
      "1683/1683 - 2s - loss: 59963770667008.0000 - mae: 3149368.2500 - 2s/epoch - 985us/step\n",
      "Epoch 95/120\n",
      "1683/1683 - 2s - loss: 59476145078272.0000 - mae: 3114722.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 96/120\n",
      "1683/1683 - 2s - loss: 59013362352128.0000 - mae: 3078840.7500 - 2s/epoch - 1ms/step\n",
      "Epoch 97/120\n",
      "1683/1683 - 2s - loss: 58571748278272.0000 - mae: 3050136.5000 - 2s/epoch - 975us/step\n",
      "Epoch 98/120\n",
      "1683/1683 - 2s - loss: 58167299932160.0000 - mae: 3030136.0000 - 2s/epoch - 970us/step\n",
      "Epoch 99/120\n",
      "1683/1683 - 2s - loss: 57787992244224.0000 - mae: 3008305.2500 - 2s/epoch - 964us/step\n",
      "Epoch 100/120\n",
      "1683/1683 - 2s - loss: 57440083116032.0000 - mae: 2993133.0000 - 2s/epoch - 967us/step\n",
      "Epoch 101/120\n",
      "1683/1683 - 2s - loss: 57124763729920.0000 - mae: 2981854.0000 - 2s/epoch - 972us/step\n",
      "Epoch 102/120\n",
      "1683/1683 - 2s - loss: 56839911768064.0000 - mae: 2971002.7500 - 2s/epoch - 964us/step\n",
      "Epoch 103/120\n",
      "1683/1683 - 2s - loss: 56581584584704.0000 - mae: 2963300.5000 - 2s/epoch - 984us/step\n",
      "Epoch 104/120\n",
      "1683/1683 - 2s - loss: 56345185222656.0000 - mae: 2954888.2500 - 2s/epoch - 1ms/step\n",
      "Epoch 105/120\n",
      "1683/1683 - 2s - loss: 56128494895104.0000 - mae: 2949861.5000 - 2s/epoch - 971us/step\n",
      "Epoch 106/120\n",
      "1683/1683 - 2s - loss: 55923728973824.0000 - mae: 2942868.7500 - 2s/epoch - 975us/step\n",
      "Epoch 107/120\n",
      "1683/1683 - 2s - loss: 55729331372032.0000 - mae: 2936361.5000 - 2s/epoch - 966us/step\n",
      "Epoch 108/120\n",
      "1683/1683 - 2s - loss: 55547093057536.0000 - mae: 2932991.5000 - 2s/epoch - 1ms/step\n",
      "Epoch 109/120\n",
      "1683/1683 - 2s - loss: 55371561435136.0000 - mae: 2926789.0000 - 2s/epoch - 993us/step\n",
      "Epoch 110/120\n",
      "1683/1683 - 2s - loss: 55199657885696.0000 - mae: 2922080.7500 - 2s/epoch - 993us/step\n",
      "Epoch 111/120\n",
      "1683/1683 - 2s - loss: 55030627434496.0000 - mae: 2916757.5000 - 2s/epoch - 993us/step\n",
      "Epoch 112/120\n",
      "1683/1683 - 2s - loss: 54864977592320.0000 - mae: 2910462.5000 - 2s/epoch - 999us/step\n",
      "Epoch 113/120\n",
      "1683/1683 - 2s - loss: 54697771663360.0000 - mae: 2905560.2500 - 2s/epoch - 997us/step\n",
      "Epoch 114/120\n",
      "1683/1683 - 2s - loss: 54532495114240.0000 - mae: 2901738.2500 - 2s/epoch - 993us/step\n",
      "Epoch 115/120\n",
      "1683/1683 - 2s - loss: 54363259142144.0000 - mae: 2893460.2500 - 2s/epoch - 994us/step\n",
      "Epoch 116/120\n",
      "1683/1683 - 2s - loss: 54194509709312.0000 - mae: 2888740.7500 - 2s/epoch - 992us/step\n",
      "Epoch 117/120\n",
      "1683/1683 - 2s - loss: 54029623230464.0000 - mae: 2882509.0000 - 2s/epoch - 976us/step\n",
      "Epoch 118/120\n",
      "1683/1683 - 2s - loss: 53866087317504.0000 - mae: 2876374.2500 - 2s/epoch - 975us/step\n",
      "Epoch 119/120\n",
      "1683/1683 - 2s - loss: 53701716738048.0000 - mae: 2870741.7500 - 2s/epoch - 984us/step\n",
      "Epoch 120/120\n",
      "1683/1683 - 2s - loss: 53536767344640.0000 - mae: 2864296.5000 - 2s/epoch - 974us/step\n",
      "=== DONE ===\n",
      "Test range: 2025-10-02 ~ 2025-10-31\n",
      "Overall: {'N': 12826, 'MAE': 3092832.6238518762, 'RMSE': 9984162.247278167, 'MAPE(%)': 232.24288163077622, 'Accuracy%(=100-MAPE)': 0.0, 'R2': 0.5070097025264617}\n",
      "Combo rows: 8\n",
      "Saved: C:/ai/source/10_1stProject/deep_amt_weather_combo\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "DATA_CSV = r\"//192.168.0.230/data/수원시 한식 동별 데이터백업.csv\"\n",
    "OUT_DIR  = r\"C:/ai/source/10_1stProject/deep_amt_weather_combo\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET   = \"AMT\"\n",
    "FEATURES = [\"DONG\", \"DAY\", \"HOUR\", \"TEMP\", \"RAIN\"]\n",
    "\n",
    "TEST_DAYS = 30\n",
    "MIN_N = 80               # 조합별 최소 표본수\n",
    "RAIN_THRESHOLD = 0.0     # 0 초과면 비\n",
    "TEMP_BINS = [-50, 0, 5, 10, 15, 20, 25, 30, 50]  # 온도구간(원하면 수정)\n",
    "\n",
    "# 딥러닝 학습(가볍게)\n",
    "EPOCHS = 120\n",
    "BATCH  = 256\n",
    "VERBOSE = 2              # 2면 epoch 로그, 0이면 조용히\n",
    "\n",
    "# =========================\n",
    "# metrics\n",
    "# =========================\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    denom = np.maximum(np.abs(y_true), 1.0)  # 0 방지\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "def acc100(y_true, y_pred):\n",
    "    return float(max(0.0, 100.0 - mape(y_true, y_pred)))\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    _mape = mape(y_true, y_pred)\n",
    "    return {\n",
    "        \"N\": int(len(y_true)),\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"RMSE\": rmse(y_true, y_pred),\n",
    "        \"MAPE(%)\": float(_mape),\n",
    "        \"Accuracy%(=100-MAPE)\": float(max(0.0, 100.0 - _mape)),\n",
    "        \"R2\": float(r2_score(y_true, y_pred)) if len(y_true) >= 2 else np.nan,\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# data\n",
    "# =========================\n",
    "def load_clean():\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "    df[\"TA_YMD\"] = df[\"TA_YMD\"].astype(str)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    df[\"DONG\"] = df[\"DONG\"].astype(str).str.strip()\n",
    "    for c in [\"DAY\", \"HOUR\", \"TEMP\", \"RAIN\", TARGET]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"DATE\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]).copy()\n",
    "    df[\"DAY\"]  = df[\"DAY\"].astype(int)\n",
    "    df[\"HOUR\"] = df[\"HOUR\"].astype(int)\n",
    "    df = df[df[\"DAY\"].between(1,7)]\n",
    "    df = df[df[\"HOUR\"].between(1,10)]\n",
    "    return df\n",
    "\n",
    "def time_split(df, test_days=30):\n",
    "    max_date = df[\"DATE\"].max()\n",
    "    cutoff = max_date - pd.Timedelta(days=test_days)\n",
    "    train_df = df[df[\"DATE\"] <= cutoff].copy()\n",
    "    test_df  = df[df[\"DATE\"] >  cutoff].copy()\n",
    "    return train_df, test_df, cutoff, max_date\n",
    "\n",
    "# =========================\n",
    "# weather combo\n",
    "# =========================\n",
    "def add_weather_combo(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"RAIN_FLAG\"] = np.where(out[\"RAIN\"] > RAIN_THRESHOLD, \"RAINY\", \"NO_RAIN\")\n",
    "    out[\"TEMP_BIN\"] = pd.cut(out[\"TEMP\"], bins=TEMP_BINS, include_lowest=True).astype(str)\n",
    "    out[\"WEATHER_COMBO\"] = out[\"TEMP_BIN\"] + \"_\" + out[\"RAIN_FLAG\"]\n",
    "    return out\n",
    "\n",
    "def eval_by_combo(df: pd.DataFrame, min_n=80) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for k, g in df.groupby(\"WEATHER_COMBO\"):\n",
    "        if len(g) < min_n:\n",
    "            continue\n",
    "        met = compute_metrics(g[TARGET].values, g[\"PRED\"].values)\n",
    "        met[\"WEATHER_COMBO\"] = k\n",
    "        rows.append(met)\n",
    "    out = pd.DataFrame(rows)\n",
    "    if len(out) == 0:\n",
    "        return out\n",
    "    return out.sort_values(\"Accuracy%(=100-MAPE)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# deep: preprocess + model\n",
    "# =========================\n",
    "def build_preprocessor():\n",
    "    # DONG 원핫 + 숫자 스케일\n",
    "    cat = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    num = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
    "        (\"sc\", StandardScaler())\n",
    "    ])\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", cat, [\"DONG\"]),\n",
    "        (\"num\", num, [\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\"])\n",
    "    ])\n",
    "    return pre\n",
    "\n",
    "def train_predict_deep(X_train_df, y_train, X_test_df, seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    pre = build_preprocessor()\n",
    "    Xtr = pre.fit_transform(X_train_df)\n",
    "    Xte = pre.transform(X_test_df)\n",
    "\n",
    "    Xtr = Xtr.toarray() if hasattr(Xtr, \"toarray\") else np.asarray(Xtr)\n",
    "    Xte = Xte.toarray() if hasattr(Xte, \"toarray\") else np.asarray(Xte)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(Xtr.shape[1],)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    model.fit(Xtr, y_train, epochs=EPOCHS, batch_size=BATCH, verbose=VERBOSE)\n",
    "\n",
    "    pred = model.predict(Xte, verbose=0).reshape(-1)\n",
    "    return pred\n",
    "\n",
    "# =========================\n",
    "# plot\n",
    "# =========================\n",
    "def save_bar_rank(df, path, title, top_n=25, ascending=False):\n",
    "    d = df.sort_values(\"Accuracy%(=100-MAPE)\", ascending=ascending).head(top_n).copy()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(d[\"WEATHER_COMBO\"].astype(str), d[\"Accuracy%(=100-MAPE)\"].astype(float))\n",
    "    plt.xticks(rotation=70, ha=\"right\")\n",
    "    plt.xlabel(\"WEATHER_COMBO (TEMP bin x RAIN)\")\n",
    "    plt.ylabel(\"Accuracy% (100 - MAPE)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# main\n",
    "# =========================\n",
    "def run():\n",
    "    df = load_clean()\n",
    "    train_df, test_df, cutoff, max_date = time_split(df, test_days=TEST_DAYS)\n",
    "\n",
    "    X_train = train_df[FEATURES]\n",
    "    y_train = train_df[TARGET].astype(float).values\n",
    "    X_test  = test_df[FEATURES]\n",
    "    y_test  = test_df[TARGET].astype(float).values\n",
    "\n",
    "    # 딥러닝 예측\n",
    "    y_pred = train_predict_deep(X_train, y_train, X_test)\n",
    "\n",
    "    # 결과 테이블\n",
    "    out = test_df[[\"DATE\",\"TA_YMD\",\"DONG\",\"DAY\",\"HOUR\",\"TEMP\",\"RAIN\",TARGET]].copy()\n",
    "    out[\"PRED\"] = y_pred\n",
    "    out = add_weather_combo(out)\n",
    "\n",
    "    overall = compute_metrics(out[TARGET].values, out[\"PRED\"].values)\n",
    "    by_combo = eval_by_combo(out, min_n=MIN_N)\n",
    "\n",
    "    # 저장\n",
    "    pd.DataFrame([overall]).to_csv(os.path.join(OUT_DIR, \"overall_deep_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    out.to_csv(os.path.join(OUT_DIR, \"pred_table_deep_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    by_combo.to_csv(os.path.join(OUT_DIR, \"by_weather_combo_deep_amt.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 그래프(상위/하위)\n",
    "    if len(by_combo) > 0:\n",
    "        save_bar_rank(by_combo, os.path.join(OUT_DIR, \"top_accuracy_combo_deep.png\"),\n",
    "                      \"TOP Weather Combo Accuracy% (DEEP, AMT) [100-MAPE]\", top_n=25, ascending=False)\n",
    "        save_bar_rank(by_combo, os.path.join(OUT_DIR, \"worst_accuracy_combo_deep.png\"),\n",
    "                      \"WORST Weather Combo Accuracy% (DEEP, AMT) [100-MAPE]\", top_n=25, ascending=True)\n",
    "\n",
    "    print(\"=== DONE ===\")\n",
    "    print(\"Test range:\", str((cutoff + pd.Timedelta(days=1)).date()), \"~\", str(max_date.date()))\n",
    "    print(\"Overall:\", overall)\n",
    "    print(\"Combo rows:\", len(by_combo))\n",
    "    print(\"Saved:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe2daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
