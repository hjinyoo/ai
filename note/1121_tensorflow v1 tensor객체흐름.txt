※ tensorflow v2.xx에서 v1사용하기
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior() # tensorflow v2 비활성화하고 v1 활성화


Tensorflow
데이터 흐름 그래프(tensor 객체의 흐름)을 사용하는 수치 계산 라이브러리
그래프는 node(연산)와 edge로 구성]
sess = tf.Session()을 이용해서 실행 환경
sess.run()을 통해서 실행결과를 확인
그래프/세션: 그래프는 노드(연산)와 엣지(데이터)로 구성되며, tf.Session()을 이용하여 실행 환경을 만들고 sess.run()으로 실행 결과를 확인
Tensor: tf.constant, tf.cast, tf.reduce_mean 등의 함수를 사용하여 텐서를 정의하고 연산을 수행

1단계 : tensor(상수) 정의
ex)
변수명 = tf.constant('...., .....')

그래프 정의할 경우
변수명1 = tf.constant(n1, dtype=tf.float16)
변수명2 = tf.constant(n2, dtype=tf.float16)
변수명3 = tf.add(변수명1,변수명2)

2단계 : 세션(연산을 실행하는 환경) 생성
ex)
sess = tf.Session()
그래프 세션 실행 & 결과
print(sess.run([변수명1,변수명2,변수명3]))

3단계 : 실제 실행 및 출력
print(sess.run(변수명)) - TensorFlow는 문자열을 바이트 시퀀스로 읽어서 b가 붙어서 출력
출력값 - b'...., ......'
print(sess.run(변수명).decode()) - 일반적인 string으로 변환하여 출력
출력값 - '...., ......'


타입변경
import numpy as np
변수명1 = tf.constant(np.array([n1,n2,n3]), dtype=tf.int16)
변수명2 = tf.cast(변수명1, dtype=tf.float32)
sess = tf.Session()
print(sess.run([변수명1,변수명2]))

평균값 계산 : tf.reduce_mean()
data = np.array([n1.,n2.,n3.,n4.])
m = tf.reduce_mean(data)
sess = tf.Session()
print(sess.run(m))

tf.random_normal([size]) : 평균이 0이고 표준편차가 1인 난수 size개 발생 
w = tf.random_normal([n]) - n:size
sess = tf.Session()
sess.run(w)

변수 노드
w = tf.Variable(tf.random_normal([n])) - n:size
sess = tf.Session()
sess.run(tf.global_variables_initializer()) # 변수 초기화
sess.run(w)


Tensorflow v1을 이용한 회귀분석 구현

독립변수 x가 1개, 타겟(종속)변수 y가 1개

선형 회귀는 독립변수x와 종속변수y 사이의 선형 관계를 모델링 
목표 데이터의 가장 잘 맞는 직선을 찾아냄
Hat, Hypothesis : 결과는 numpy 배열
H = w * x + b

cost function (손실함수 : mse) : 평균제곱 오차
cost = tf.reduce_mean(tf.square(H-y))

학습목적 : cost가 취소되는 w,b를 찾는것
cost함수는 2차함수이므로 곡선 그래프, 곡선위 미분값이 0이 되는 방향
(경사강하법GradientDescent)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train = optimizer.minimize(cost)
- cost함수 그래프에서 w와 b 지점에서의 기울기를 계산하고 그 기울기가 낮아지는 방향으로 조금씩 업데이트

for step in range(n): - n번 학습
    sess.run([train, cost, w, b])


# 최종적으로 나온 회귀식 H = W*x + b
sess.run([w,b])



predict을 위한 placeholder 이용
placeholder : 외부에서 데이터를 입력받을 수 있는 노드(외부에서 데이터를 받아올 수 있는 공간을 정의)
H와 cost를 노드를 연결하여 계산흐름을 그래프화
sess.run([x,H], feed_dict={x : np.array([n1,n2])}) - feed_dict를 사용하여 플레이스홀더에 실제 데이터를 주입


scale이 다른 데이터들의 회귀분석 구현(scale 조정o)
scale 조정 방법: 모든 데이터를 일정범위내로 조정
normalization(정규화) : 모든 데이터를 0~1 사이로 조정 
                               X - Xmin
   normalization = ────────  * 라이브러리 추천(sklearn.preprocessing.MinMaxScaler
                            Xmax - Xmin
standardization(표준화) : 데이터의 평균을 0, 표준편차를 1로 조정 
                              X - Xmean
  standardization = ────────  * 라이브러리 추천(sklearn.preprocessing.StandardScaler)
                             Xstd(표준편차)









